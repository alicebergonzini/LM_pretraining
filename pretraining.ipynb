{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd41ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263daf17",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING\n",
    "\n",
    "Per ottenere un dataset che possa essere utilizzato come training del nostro language model partiamo dai file conllu che contengono i testi annotati di wikipedia italiana. Da questi file vogliamo ottenere una struttura dati che per ogni frase riporti id, testo e indice di Gulpease (per ora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5090422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/conllu\\\\chat.conllu', 'data/conllu\\\\text_all.conllu']\n"
     ]
    }
   ],
   "source": [
    "#si ottengono i path di ogni file per il pretraining e si salvano in una lista\n",
    "ds_directory = \"data/conllu\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(ds_directory):\n",
    "    file_path = os.path.join(ds_directory, file_name)\n",
    "    ds_files.append(file_path)\n",
    "print(ds_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a4027dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef comp_gulpease(ns, nw, nl):\\n    g_value = 89 + ((300*ns - 10*nl)/nw) #è corretta questa formula?\\n    return g_value\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#funzione che calcola gulpease - io in teoria userò read-it\n",
    "'''\n",
    "def comp_gulpease(ns, nw, nl):\n",
    "    g_value = 89 + ((300*ns - 10*nl)/nw) #è corretta questa formula?\n",
    "    return g_value\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b46c94a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_readit_scores(file_path):\\n    readit_list = []\\n    for line in open(file_path, \\'r\\', encoding = \"utf-8\"): \\n        print(line)\\n        if line.startswith(\"# text\"):\\n            current_sent = line[9:].rstrip(\\'\\n\\')\\n            sent_id = load_document(current_sent)\\n            r_score = get_sent_readability(sent_id)\\n            readit_list.append(r_score)\\n    return readit_list\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Qui il codice per ottenere l'indicie di leggibilità\n",
    "\n",
    "SERVER_PATH = \"http://api.italianlp.it\"\n",
    "\n",
    "#con una post si carica il documento nel db del server e si caclcola la leggibiità \n",
    "def load_document(text):\n",
    "    r = requests.post(SERVER_PATH + '/documents/',           # carica il documento nel database del server\n",
    "                      data={'text': text,                    # durante il caricamento viene eseguita un'analisi linguistica necessaria per calcolare la leggibilita'\n",
    "                          'lang': 'IT',\n",
    "                          'extra_tasks': [\"readability\"]     # chiede al server di calcolare anche la leggibilità del docuemnto\n",
    "                  })\n",
    "    doc_id = r.json()['id']                                  # id del documento nel database del server, che serve per richiedere i risultati delle analisi\n",
    "    return doc_id\n",
    "\n",
    "#si fa una get per ottenere i risultati, in questo caso siamo interessati solo alla leggibilità globale\n",
    "def get_sent_readability(doc_id):\n",
    "    r = requests.get(SERVER_PATH + '/documents/details/%s' % doc_id)\n",
    "    result = r.json()\n",
    "    sent_dict = result['sentences']['data'][0]\n",
    "    sent_readability = sent_dict[\"readability_score_all\"]        #prendiamo la leggibilità globale\n",
    "    return sent_readability\n",
    "\n",
    "def get_random_score():\n",
    "    rand_score = random.randint(0,100)\n",
    "    return rand_score\n",
    "\n",
    "#funzione per iterare su ciascuna frase \n",
    "'''def get_readit_scores(file_path):\n",
    "    readit_list = []\n",
    "    for line in open(file_path, 'r', encoding = \"utf-8\"): \n",
    "        print(line)\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            sent_id = load_document(current_sent)\n",
    "            r_score = get_sent_readability(sent_id)\n",
    "            readit_list.append(r_score)\n",
    "    return readit_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "748967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che legge i file conllu riga per riga, estraendo id, testo e indice di complessità di ciascuna frase \n",
    "def extract(file_path, n_file):\n",
    "    id_list = []\n",
    "    text_list = []\n",
    "    readit_list = []\n",
    "    current_id=\"\"\n",
    "    current_sent=\"\"\n",
    "    for line in open(file_path, 'r', encoding='utf-8'):\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            #gulp = comp_gulpease(1, len(words), sum(len(word) for word in words))\n",
    "            print(current_sent)\n",
    "            #sent_id = load_document(current_sent)\n",
    "            #r_score = get_sent_readability(sent_id)\n",
    "            r_score = get_random_score()\n",
    "            readit_list.append(r_score)\n",
    "            text_list.append(current_sent)\n",
    "            #gulp_list.append(gulp)\n",
    "        elif line.startswith(\"# sent_id\"):\n",
    "            current_id = re.sub(r'\\D', '', line)\n",
    "            id_list.append(f'{current_id}_{str(n_file)}') #per avere id univoco ho aggiunto numero del file\n",
    "    return id_list, text_list, readit_list\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b4cff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Prima Guerra Mondiale, conosciuta anche come la Grande Guerra, fu un conflitto globale che ebbe luogo principalmente in Europa dal 28 luglio 1914 al 11 novembre 1918.\n",
      "Coinvolse le principali potenze mondiali dell'epoca, divise in due alleanze contrapposte:\n",
      "gli Alleati, guidati da Francia, Regno Unito, Russia (successivamente sostituita dall'Impero britannico e dagli Stati Uniti), e l'Intesa Centrale, composta da Germania, Austria-Ungheria, Impero Ottomano e Bulgaria.\n",
      "Le cause della guerra possono essere attribuite a una serie di fattori, tra cui tensioni politiche, rivalità coloniali, nazionalismo, militarismo e sistemi di alleanze che resero il conflitto inevitabile dopo l'assassinio dell'arciduca Francesco Ferdinando d'Austria, erede al trono austro-ungarico, a Sarajevo nel giugno 1914.\n",
      "La guerra fu caratterizzata da una serie di nuove tattiche e tecnologie militari, tra cui trincee, mitragliatrici, gas tossici e bombardamenti aerei, che portarono a un conflitto di logoramento su vasta scala.\n",
      "Le battaglie più significative includono la Battaglia della Marna, la Battaglia di Verdun, la Battaglia di Gallipoli e la Battaglia della Somme.\n",
      "Durante il conflitto, il fronte occidentale si stabilizzò in una linea di trincee che si estendeva dalla Svizzera al Mare del Nord, mentre sul fronte orientale ci furono movimenti più ampi delle truppe.\n",
      "Gli Stati Uniti entrarono in guerra nel 1917 a fianco degli Alleati, contribuendo a sbilanciare ulteriormente il conflitto.\n",
      "La guerra ebbe un costo umano devastante, con milioni di morti e feriti da entrambe le parti, sia militari che civili.\n",
      "Alla fine, la pressione economica, sociale e politica sull'Impero tedesco e sull'Intesa Centrale portò alla sconfitta di quest'ultima.\n",
      "Il 11 novembre 1918, l'Armistizio di Compiègne pose fine alle ostilità, segnando la vittoria degli Alleati.\n",
      "Il Trattato di Versailles, firmato nel 1919, pose fine formalmente al conflitto e impose pesanti riparazioni e restrizioni all'Impero tedesco, segnando l'inizio di un periodo di instabilità politica ed economica che avrebbe contribuito allo scoppio della Seconda Guerra Mondiale due decenni dopo.\n",
      "La Prima Guerra Mondiale è considerata una delle più grandi catastrofi del XX secolo, con conseguenze che hanno plasmato il corso della storia mondiale.\n",
      "Le guerre puniche furono una serie di conflitti tra la Repubblica Romana e l'antica città-stato di Cartagine, situata nell'attuale Tunisia.\n",
      "Questi conflitti ebbero luogo durante il periodo compreso tra il 264 a.C. e il 146 a.C.\n",
      "La Prima Guerra Punica, dal 264 al 241 a.C., fu combattuta principalmente per il controllo della Sicilia.\n",
      "La guerra vide Roma emergere vittoriosa dopo una lunga serie di battaglie navali e terrestri.\n",
      "Una delle battaglie più famose fu la Battaglia delle Isole Lipari nel 260 a.C., dove Roma sconfisse la flotta cartaginese, consolidando il proprio dominio marittimo nel Mediterraneo occidentale.\n",
      "La guerra si concluse con il Trattato di Lutazio nel 241 a.C., che vide Cartagine cedere la Sicilia a Roma.\n",
      "La Seconda Guerra Punica, dal 218 al 201 a.C., fu combattuta principalmente da Roma contro il leggendario generale cartaginese Annibale.\n",
      "Annibale attraversò le Alpi con il suo esercito e inflisse pesanti sconfitte alle forze romane, inclusa la famosa vittoria nella Battaglia di Canne nel 216 a.C. Tuttavia, Roma alla fine prevalse sotto la guida dei generali Scipione l'Africano e Publio Cornelio Scipione, che condussero la guerra in Africa e sconfissero le forze cartaginesi nella Battaglia di Zama nel 202 a.C. Il risultato fu il Trattato di Pace di Siface nel 201 a.C., che pose fine alla Seconda Guerra Punica e vide Cartagine cedere la Spagna e pagare pesanti riparazioni a Roma.\n",
      "La Terza Guerra Punica, dal 149 al 146 a.C., fu provocata dalle crescenti preoccupazioni romane riguardo alla potenza di Cartagine.\n",
      "Roma, guidata dal console Publio Cornelio Scipione Emiliano, assediò e distrusse Cartagine dopo una lunga e devastante campagna militare.\n",
      "La città venne rasa al suolo e la sua popolazione venne ridotta in schiavitù, segnando la fine definitiva della potenza cartaginese nel Mediterraneo.\n",
      "La RAM è una memoria volatile, il che significa che i dati in essa contenuti vengono persi quando il computer viene spento o riavviato.\n",
      "La RAM funge da area di lavoro per il processore del computer, consentendo il caricamento temporaneo di dati e istruzioni utilizzati attivamente durante l'esecuzione dei programmi.\n",
      "Questo include il sistema operativo, le applicazioni software e i dati generati dall'utente.\n",
      "L'agricoltura in Italia è molto importante perché fornisce cibo per le persone e materia prima per molte industrie.\n",
      "In Italia, ci sono diverse regioni che producono vari tipi di cibo grazie a terreni diversi e un clima vario.\n",
      "Nel nord Italia, ci sono molte aree pianeggianti e collinari che sono ottime per la coltivazione di cereali come grano e mais, così come frutta come mele e pere.\n",
      "Alcune zone, come la pianura padana, sono famose per i loro risi, che vengono coltivati in risaie.\n",
      "Nelle regioni centrali e meridionali, dove il clima è più caldo, si coltivano molte verdure come pomodori, zucchine, melanzane e peperoni.\n",
      "In queste zone si trovano anche molti uliveti per la produzione di olio d'oliva, e vigneti per la produzione di vino.\n",
      "L'Italia è famosa per i suoi vini, come il Chianti in Toscana e il Barolo in Piemonte.\n",
      "L'agricoltura in Italia è spesso di tipo familiare, con molte piccole aziende agricole gestite da famiglie.\n",
      "Tuttavia, ci sono anche aziende agricole più grandi che producono cibo su larga scala.\n",
      "Gli esseri umani respirano attraverso un processo chiamato respirazione.\n",
      "La respirazione coinvolge l'assunzione di ossigeno dall'ambiente circostante e l'espulsione di anidride carbonica, un prodotto di scarto del metabolismo, dall'organismo.\n",
      "I Pokémon sono una popolare serie di creature immaginarie introdotte da Nintendo, Game Freak e Creatures Inc. nel 1996.\n",
      "Sono diventati noti attraverso i videogiochi, i cartoni animati, i film, i giocattoli e molti altri prodotti.\n",
      "La parola \"Pokémon\" è una contrazione di \"Pocket Monsters\" (mostri tascabili), poiché i giocatori possono \"catturare\" e \"allenare\" queste creature nel mondo immaginario dei giochi.\n",
      "In breve, i Pokémon sono esseri fantastici che vivono in un mondo immaginario, ognuno con un aspetto, abilità e personalità unici.\n",
      "I giocatori assumono il ruolo di Allenatori Pokémon, il cui obiettivo principale è catturare, allenare e fare combattere i Pokémon tra loro.\n",
      "Ogni Pokémon ha una o più abilità speciali e può apprendere mosse diverse durante il gioco.\n",
      "Ci sono centinaia di specie di Pokémon, ognuna appartenente a uno o più \"tipi\" (come acqua, fuoco, erba, ecc.), che possono avere vantaggi o svantaggi nei confronti di altri tipi.\n",
      "I Pokémon sono diventati una delle franchigie di intrattenimento più famose e influenti al mondo, con milioni di fan in tutto il globo.\n",
      "Oltre ai videogiochi, la serie Pokémon include anche una serie animata televisiva, una vasta gamma di giocattoli e oggetti da collezione, film, fumetti e molto altro ancora.\n",
      "La serie ha contribuito a creare una cultura popolare unica e continua ad avere un impatto significativo sulla cultura di massa.\n",
      "L'allunaggio è la discesa di un veicolo sulla Luna.\n",
      "Si distingue tra allunaggio duro, cioè un impatto che comporta la distruzione del veicolo, e allunaggio morbido, che permette al veicolo di arrivare intatto sulla superficie lunare.\n",
      "Il programma Luna, partito nel 1959 con la sonda Luna 2, inviò il primo veicolo riuscito ad impattare con il satellite.\n",
      "Luna 9, il 3 febbraio 1966, eseguì il primo atterraggio morbido sulla Luna.\n",
      "Il primo allunaggio di un essere umano, il 20 luglio 1969, fu quello di Neil Armstrong, comandante della missione Apollo 11, e di Buzz Aldrin, mentre il loro compagno Michael Collins, rimasto in orbita, controllava il modulo di comando Columbia.\n",
      "La prima missione verso la Luna dopo il periodo aureo, conclusosi nel 1976 con Luna 24, ultima missione automatica sovietica, fu organizzata dal Giappone con la sonda Hiten-Hagoromo lanciata il 24 gennaio 1990, che collaudò una nuova rotta lunare molto più economica ma anche molto più lenta;\n",
      "il rilascio della sonda Hagoromo fallì per l'interruzione dei contatti radio e alla fine Hiten entrò a sua volta in orbita lunare il 2 ottobre 1991;\n",
      "esaurito il combustibile la sonda fu fatta precipitare sul suolo lunare il 10 aprile 1993.\n",
      "La sonda spaziale SMART-1, dell'Agenzia spaziale europea (ESA) fu lanciata il 27 settembre 2003, ed arrivò nei pressi della Luna ad inizio 2005 (il motivo di un tempo così lungo è da trovarsi nel suo motore a ioni, un nuovo tipo di propulsione spaziale molto economico ma piuttosto lento).\n",
      "SMART-1 effettuò una ricognizione completa della Luna e produsse una mappa a raggi X della sua superficie[1].\n",
      "La sonda si schiantò sulla Luna il 3 settembre 2006.\n",
      "L'India ha fatto scendere sul suolo lunare il modulo Aditya (Moon Impact Probe), alle 15:04 UTC del 14 novembre 2008; il modulo era stato sganciato dalla sonda Chandrayaan-1 lanciata il 22 ottobre dalla base di Srihakot ed entrata in orbita intorno alla Luna il 4 novembre.\n",
      "L'India è quindi quinta nella lista dei paesi o enti spaziali che hanno raggiunto la superficie lunare.\n",
      "La Cina ha lanciato verso la Luna la sonda Chang'e 1, che il 1º marzo 2009 ha concluso la missione schiantandosi sul suolo lunare.\n",
      "L'allunaggio è la discesa di un veicolo sulla Luna.\n",
      "Si distingue tra allunaggio duro, cioè un impatto che comporta la distruzione del veicolo, e allunaggio morbido, che permette al veicolo di arrivare intatto sulla superficie lunare.\n",
      "Il programma Luna, partito nel 1959 con la sonda Luna 2, inviò il primo veicolo riuscito ad impattare con il satellite.\n",
      "Luna 9, il 3 febbraio 1966, eseguì il primo atterraggio morbido sulla Luna.\n",
      "Il primo allunaggio di un essere umano, il 20 luglio 1969, fu quello di Neil Armstrong, comandante della missione Apollo 11, e di Buzz Aldrin, mentre il loro compagno Michael Collins, rimasto in orbita, controllava il modulo di comando Columbia.\n",
      "La prima missione verso la Luna dopo il periodo aureo, conclusosi nel 1976 con Luna 24, ultima missione automatica sovietica, fu organizzata dal Giappone con la sonda Hiten-Hagoromo lanciata il 24 gennaio 1990, che collaudò una nuova rotta lunare molto più economica ma anche molto più lenta;\n",
      "il rilascio della sonda Hagoromo fallì per l'interruzione dei contatti radio e alla fine Hiten entrò a sua volta in orbita lunare il 2 ottobre 1991;\n",
      "esaurito il combustibile la sonda fu fatta precipitare sul suolo lunare il 10 aprile 1993.\n",
      "La sonda spaziale SMART-1, dell'Agenzia spaziale europea (ESA) fu lanciata il 27 settembre 2003, ed arrivò nei pressi della Luna ad inizio 2005 (il motivo di un tempo così lungo è da trovarsi nel suo motore a ioni, un nuovo tipo di propulsione spaziale molto economico ma piuttosto lento).\n",
      "SMART-1 effettuò una ricognizione completa della Luna e produsse una mappa a raggi X della sua superficie[1].\n",
      "La sonda si schiantò sulla Luna il 3 settembre 2006.\n",
      "L'India ha fatto scendere sul suolo lunare il modulo Aditya (Moon Impact Probe), alle 15:04 UTC del 14 novembre 2008; il modulo era stato sganciato dalla sonda Chandrayaan-1 lanciata il 22 ottobre dalla base di Srihakot ed entrata in orbita intorno alla Luna il 4 novembre.\n",
      "L'India è quindi quinta nella lista dei paesi o enti spaziali che hanno raggiunto la superficie lunare.\n",
      "La Cina ha lanciato verso la Luna la sonda Chang'e 1, che il 1º marzo 2009 ha concluso la missione schiantandosi sul suolo lunare.\n",
      "Va osservato che tutte queste sonde hanno realizzato un allunaggio distruttivo e non morbido, non disponendo dei retrorazzi necessari per rallentare il veicolo ed evitarne la distruzione.\n",
      "Tuttavia, il 2 dicembre 2013, la Cina ha lanciato la navicella Chang'e 3 contenente la sonda Yutu (il cui nome significa \"coniglio di giada\"), la quale, il 14 dicembre, si è sganciata da Chang'e 3 ed ha effettuato un allunaggio morbido.\n",
      "In questo modo la Cina è divenuta il terzo paese ad aver compiuto questo tipo di allunaggio dopo Unione Sovietica e Stati Uniti.\n",
      "La Russia, in un primo momento, aveva programmato per il 2012 il lancio di una sonda lunare, Luna-Glob 1.\n",
      "Successivamente si è deciso di rimandare al 2024.\n",
      "L'Agenzia spaziale europea e la Repubblica Popolare Cinese hanno entrambe piani per esplorare la Luna, la prima mediante sonde, mentre la seconda con un programma di esplorazione umana.\n",
      "La Cina, oltre all'esplorazione umana, sta considerando la possibilità di sfruttare minerariamente la Luna, in particolare per l'isotopo Elio-3, da usare come possibile futura fonte d'energia per la fusione nucleare sulla Terra.\n",
      "tuttavia, sia Tertulliano[7] sia, più tardi, Papa Leone I[8] attestano il fastidio e la riprovazione dei vertici della Chiesa nei confronti dei cristiani che, perpetuando le usanze pagane, manifestavano una venerazione nei confronti del Sole.\n"
     ]
    }
   ],
   "source": [
    "#si estraggono id e testo tramite le funzioni sopra definite\n",
    "n_file = 1\n",
    "id_list = []\n",
    "text_list = []\n",
    "readit_list = []\n",
    "for item in ds_files:\n",
    "    item_ids, item_texts, item_readit = extract(item, n_file)\n",
    "    id_list = id_list + item_ids\n",
    "    text_list = text_list + item_texts\n",
    "    readit_list = readit_list + item_readit\n",
    "    n_file += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9dedfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readit_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>La Prima Guerra Mondiale, conosciuta anche com...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1</td>\n",
       "      <td>Coinvolse le principali potenze mondiali dell'...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_1</td>\n",
       "      <td>gli Alleati, guidati da Francia, Regno Unito, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_1</td>\n",
       "      <td>Le cause della guerra possono essere attribuit...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_1</td>\n",
       "      <td>La guerra fu caratterizzata da una serie di nu...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  readit_index\n",
       "0  1_1  La Prima Guerra Mondiale, conosciuta anche com...            81\n",
       "1  2_1  Coinvolse le principali potenze mondiali dell'...            14\n",
       "2  3_1  gli Alleati, guidati da Francia, Regno Unito, ...             3\n",
       "3  4_1  Le cause della guerra possono essere attribuit...            94\n",
       "4  5_1  La guerra fu caratterizzata da una serie di nu...            35"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si crea un dataframe con una riga per frase, attributi: id, testo e indice di gulpease\n",
    "ds_df = pd.DataFrame(columns=[\"id\", \"text\", \"readit_index\"])\n",
    "\n",
    "ds_df[\"id\"] = id_list\n",
    "ds_df[\"text\"] = text_list\n",
    "ds_df[\"readit_index\"]  = readit_list\n",
    "\n",
    "ds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7023f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setto il device da usare\n",
    "#torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7563c918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Divido in training e test set\n",
    "dataset = Dataset.from_pandas(ds_df)\n",
    "split_set = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_ds = split_set[\"train\"]\n",
    "test_ds = split_set[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9bd3",
   "metadata": {},
   "source": [
    "### TOKENIZATION\n",
    "\n",
    "In questa sezione si importa il tokenizzatore col quale si tokenizza ciascuna frase nel formato necessario per Bert, alla fine si otterrà un dataset nel formato corretto con tutte le features necessarie per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc991e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0317bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/vocab.txt from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\e386d7030c11abe3c82da83b0aa728f3c09ab3a6728e325fe78bb5a0c67d7c71.83ca512ab51c5bc2809e83002a054b84ab85a200b98d5c0eb036d7611ee4362e\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\534fa05777338ca7e2b068a37beb83688543de270a20252296be3eadd10caca1.6391beef2ceed2cdba47401eb12680200856c97d2f2b56143e515d7c0f36a66a\n",
      "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\4641bcb7c4ac61788587ad50d2f1598c64a1c28a71631929524c234bcf1e422e.6ec690b98e01c56d26601258d2be34c3e5a76b949465ed58983cff81e5f9fa88\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-italian-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#si importa il tokenizzatore già configurato (in questo caso: bert-base-italian-cased)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6a74b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ffc6d76622448385a39fa87b75267c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf0ae4aacd446ecbf3c7bdf09cfdc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#facciamo l'encoding di tutto il dataset tokenizzando frase per frase\n",
    "def encode(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=True, truncation=True, max_length=512, return_special_tokens_mask=True)\n",
    "\n",
    "train_set = train_ds.map(encode, batched=True)\n",
    "test_set = test_ds.map(encode, batched=True)\n",
    "train_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n",
    "test_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "643587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'readit_index', 'input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'],\n",
       "    num_rows: 75\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95290375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'readit_index', 'input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'],\n",
       "    num_rows: 9\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def829e",
   "metadata": {},
   "source": [
    "### TRAINING DI BERT\n",
    "\n",
    "Si procede al training di Bert. Il modello dovrà partire da uno stato iniziale con pesi random, per questo non si importa il modello già addestrato, ma si configura semplicemente l'architettura la sua architettura per poi addestrarlo da zero. Si definisce poi una strategia di training e i suoi argomenti per poi addestrare il modello sul trask di Language Modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93b20d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, TrainerCallback, BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54c37d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"prajjwal1/bert-mini\"\n",
    "model_config = BertConfig.from_pretrained(model_name)\n",
    "\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2348df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(31102, 256)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM(model_config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "abd13ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 31102\n",
       "}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "09353207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usiamo il datacollator per fare le batch per il training\n",
    "datacollator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.2, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc554e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizer(name_or_path='dbmdz/bert-base-italian-cased', vocab_size=31102, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.2, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90322bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza del dataset: 75\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lunghezza del dataset: {len(train_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "95a4059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco una funzione di callback per verificare l'ordinamento dei dati per ogni epoca\n",
    "from transformers.trainer_callback import TrainerControl, TrainerState\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "\n",
    "class check_ds_order(TrainerCallback):\n",
    "    def on_epoch_begin(self, args, state, control, train_dataloader, **kwargs):\n",
    "        f = open(f\"train_check.txt\", \"a\")\n",
    "        f.write(f\"\\n------------------------ ORDINE DEI DATI ALL'INIZI DELL'EPOCA {int(state.epoch+1)} ------------------------\")\n",
    "        f.write(str(train_dataloader.dataset[\"input_ids\"][:5]))\n",
    "        f.write(\"-----------------------------------------------------------------------------------\")\n",
    "\n",
    "class check_weights(TrainerCallback):\n",
    "    def on_train_begin(self, args, state, control, model, **kwargs):\n",
    "        init_weights = model.state_dict()\n",
    "        for key, value in init_weights.items():\n",
    "            print(f\"\\n{key}:\\n\")\n",
    "            print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c0a3b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "#argomenti provvisori, da definire meglio\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"my_pretrained_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "662c1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ad9e34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('train_check.txt', 'w').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a14c39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=datacollator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    callbacks=[check_ds_order, check_weights], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0fc08b00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\bergo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 75\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bert.embeddings.position_ids:\n",
      "\n",
      "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "         504, 505, 506, 507, 508, 509, 510, 511]])\n",
      "\n",
      "bert.embeddings.word_embeddings.weight:\n",
      "\n",
      "tensor([[ 0.0059,  0.0044, -0.0057,  ..., -0.0060,  0.0051, -0.0059],\n",
      "        [ 0.0134,  0.0080, -0.0361,  ..., -0.0190, -0.0160, -0.0436],\n",
      "        [ 0.0053,  0.0058, -0.0378,  ...,  0.0103,  0.0021, -0.0198],\n",
      "        ...,\n",
      "        [-0.0167, -0.0014,  0.0057,  ..., -0.0296,  0.0171,  0.0228],\n",
      "        [-0.0108,  0.0360, -0.0266,  ..., -0.0060, -0.0037,  0.0164],\n",
      "        [-0.0002, -0.0251, -0.0371,  ..., -0.0160, -0.0234, -0.0275]])\n",
      "\n",
      "bert.embeddings.position_embeddings.weight:\n",
      "\n",
      "tensor([[ 0.0066, -0.0270, -0.0075,  ...,  0.0033, -0.0113, -0.0210],\n",
      "        [-0.0338, -0.0159, -0.0152,  ..., -0.0011,  0.0002, -0.0050],\n",
      "        [ 0.0094,  0.0316, -0.0001,  ..., -0.0020,  0.0242, -0.0434],\n",
      "        ...,\n",
      "        [-0.0543,  0.0244, -0.0092,  ...,  0.0070,  0.0382, -0.0298],\n",
      "        [-0.0144, -0.0128, -0.0171,  ...,  0.0260, -0.0030,  0.0090],\n",
      "        [ 0.0156, -0.0101, -0.0053,  ..., -0.0150, -0.0115, -0.0002]])\n",
      "\n",
      "bert.embeddings.token_type_embeddings.weight:\n",
      "\n",
      "tensor([[-2.0978e-02, -1.7446e-02,  2.6202e-02,  5.8318e-03, -2.8689e-03,\n",
      "          2.9665e-02, -2.1800e-02,  2.6896e-02, -1.3218e-02, -3.0340e-02,\n",
      "          3.0208e-03,  3.4520e-02,  1.1314e-02,  3.8123e-04, -1.7300e-02,\n",
      "         -1.0963e-03, -3.0617e-02, -1.5115e-02,  1.4514e-03,  3.9252e-02,\n",
      "          2.8368e-02,  4.6785e-04, -3.8461e-02,  4.7282e-02, -2.0579e-02,\n",
      "         -1.3041e-02,  2.4486e-02,  1.9607e-03,  2.5172e-03, -3.3198e-02,\n",
      "         -6.6608e-03,  6.6732e-03,  1.7345e-02, -1.5735e-02, -1.6923e-02,\n",
      "          1.7769e-02,  3.1345e-02, -1.8300e-02, -2.7278e-02,  6.3332e-03,\n",
      "         -3.9111e-02,  2.7320e-02, -8.6863e-03, -6.2295e-03,  3.7378e-03,\n",
      "         -5.7613e-03,  2.7009e-02, -3.3470e-03, -1.1155e-02,  5.5409e-04,\n",
      "         -1.9053e-02,  4.2859e-02, -2.0362e-02, -2.1980e-02,  1.1110e-02,\n",
      "         -1.1208e-02, -7.2814e-03,  1.1296e-03, -7.7963e-03,  2.6237e-02,\n",
      "         -1.2663e-02, -2.0351e-03, -3.3061e-02,  9.1719e-03,  1.5467e-02,\n",
      "         -2.6284e-02,  4.2571e-02,  1.1976e-02,  1.0744e-02, -1.1727e-02,\n",
      "         -7.8901e-03, -6.2402e-03, -3.9771e-02,  2.0635e-02, -2.9899e-02,\n",
      "          4.2487e-02,  5.6818e-03, -3.4793e-02,  9.7710e-03, -3.3245e-02,\n",
      "         -1.0586e-03,  1.4498e-02,  1.7942e-02,  1.9112e-02, -2.1355e-03,\n",
      "          4.7683e-03, -3.2995e-02, -1.1672e-02,  1.3465e-02, -4.1246e-02,\n",
      "         -1.1107e-02,  1.0387e-02,  1.4799e-02,  7.3225e-03, -1.9200e-02,\n",
      "         -2.6196e-02,  3.6559e-02,  1.5140e-02, -2.0285e-02, -3.5089e-03,\n",
      "         -3.5308e-02,  1.0581e-02, -3.0806e-03, -5.2842e-03, -1.3900e-02,\n",
      "         -6.7528e-03,  3.0978e-03, -1.1151e-02, -1.2489e-02, -1.0445e-02,\n",
      "          3.4085e-02, -2.1289e-02,  4.9665e-03,  5.8999e-03,  2.4169e-04,\n",
      "          5.7273e-03,  8.1635e-03,  7.0721e-03, -6.9915e-03, -8.7570e-05,\n",
      "         -2.7073e-03,  3.0290e-02, -1.0884e-02,  2.5223e-03,  1.6843e-02,\n",
      "          2.9221e-02, -1.0577e-02,  4.3283e-03, -7.9353e-03,  2.5383e-03,\n",
      "         -9.9024e-03, -1.1454e-02,  1.9219e-02, -2.3800e-02, -3.2843e-03,\n",
      "         -5.3302e-03, -1.6311e-02,  3.7039e-03, -8.8872e-04, -2.2620e-02,\n",
      "          6.2140e-03, -3.9734e-03, -1.9477e-03, -1.7565e-02,  8.0267e-03,\n",
      "         -2.7398e-02,  3.4366e-02, -1.3128e-02, -5.9845e-03,  2.3837e-02,\n",
      "         -1.7360e-02, -4.2468e-03, -5.3224e-02,  2.7717e-02,  2.5328e-02,\n",
      "          1.9052e-02,  1.2155e-02,  9.8583e-04, -3.4686e-02, -2.3969e-02,\n",
      "          1.0629e-02, -1.6648e-02,  2.6937e-02,  9.5878e-03,  9.2436e-03,\n",
      "         -1.5205e-02,  5.5487e-03,  1.1567e-02, -7.9103e-04, -1.4038e-02,\n",
      "         -2.2856e-02, -1.9065e-02, -2.9342e-02,  6.0099e-03, -3.8443e-02,\n",
      "          1.0182e-02,  1.1939e-02,  4.1316e-02,  2.8335e-02,  1.0950e-03,\n",
      "         -3.7176e-03,  4.5686e-02,  2.4730e-02,  9.0518e-03, -6.2077e-03,\n",
      "          2.5213e-02,  6.1082e-05, -2.2272e-02,  1.6150e-02, -1.7770e-02,\n",
      "          1.8660e-02,  4.8179e-03,  1.4735e-02,  8.9531e-03,  6.0384e-03,\n",
      "          1.7087e-02, -9.2201e-03, -4.5775e-03,  2.7990e-02,  1.6215e-02,\n",
      "         -1.1486e-02,  8.0322e-03,  2.8970e-02, -3.7937e-02,  3.2514e-02,\n",
      "          3.1002e-02,  1.7898e-02,  3.2070e-02,  3.8680e-03, -7.7260e-05,\n",
      "          4.5790e-02, -5.4620e-03,  1.0445e-02,  5.2672e-02, -1.8155e-02,\n",
      "          6.1329e-03, -6.3589e-03,  1.8292e-02, -8.5503e-03,  1.6951e-03,\n",
      "         -1.8053e-02, -3.6078e-02,  1.2855e-03, -3.1498e-04, -1.1063e-02,\n",
      "          1.2488e-02, -2.1084e-03, -2.4465e-03,  2.7784e-03, -1.8336e-02,\n",
      "         -2.3057e-02, -1.8709e-04, -1.5378e-02, -1.0778e-02,  2.6928e-02,\n",
      "         -2.0338e-02,  1.8920e-02, -4.6617e-02,  1.3904e-02,  2.7438e-02,\n",
      "          3.7930e-03,  5.5123e-02, -4.3077e-02, -3.3975e-02,  3.5232e-02,\n",
      "          1.9961e-02, -3.5147e-02,  1.6690e-02,  2.4376e-03, -2.0067e-02,\n",
      "         -4.6620e-03,  2.4650e-04, -3.3581e-02, -1.2650e-02, -2.1920e-02,\n",
      "         -2.3661e-02],\n",
      "        [ 1.9411e-02, -1.6663e-02,  5.7760e-03, -8.1088e-03,  1.7065e-02,\n",
      "          5.1349e-03,  1.4407e-02,  8.5141e-03,  3.4571e-03,  1.5300e-02,\n",
      "          1.6405e-02,  6.4702e-03,  1.5214e-02,  1.8898e-03,  3.1003e-02,\n",
      "          1.3514e-02,  7.8186e-03,  4.6438e-06,  2.3440e-02, -3.2370e-02,\n",
      "         -1.5747e-02,  2.3318e-02,  2.0400e-02, -1.7222e-02, -9.0588e-03,\n",
      "         -5.0251e-03,  1.4981e-03,  1.5590e-02,  1.3761e-02,  3.4257e-02,\n",
      "          3.6627e-02, -4.1173e-02,  2.7805e-02, -3.5836e-02,  9.2428e-03,\n",
      "          1.7786e-02,  9.5954e-03,  8.5798e-03, -1.1175e-02,  3.2796e-02,\n",
      "         -4.8334e-03, -1.1644e-02,  7.4140e-03,  2.9904e-02,  1.8000e-02,\n",
      "         -1.9562e-02, -1.5843e-02, -2.4940e-03,  4.4829e-03,  1.4059e-02,\n",
      "          8.5259e-03, -3.1491e-02,  6.8701e-03,  4.2448e-02, -9.5143e-03,\n",
      "          5.0964e-03, -3.3873e-02,  4.7328e-03,  2.4351e-03, -2.5396e-02,\n",
      "          2.6616e-03, -8.3671e-03,  1.0036e-02, -7.2120e-03, -1.4839e-03,\n",
      "          9.6663e-03, -5.3764e-03, -1.2483e-02,  9.8625e-03, -1.7806e-02,\n",
      "          1.8799e-02,  1.1470e-02,  2.3538e-02, -1.1410e-02, -4.0480e-03,\n",
      "         -3.6297e-02,  1.2503e-02, -1.1303e-02, -1.3963e-02,  1.2992e-03,\n",
      "          1.4112e-02,  5.0658e-03, -1.5367e-02, -7.8464e-03,  2.9037e-02,\n",
      "         -1.7274e-02, -1.0817e-02, -1.9201e-02, -3.1435e-02, -5.7682e-03,\n",
      "          1.0690e-02,  2.2345e-02, -2.1949e-02,  1.1806e-02, -3.2211e-03,\n",
      "          4.0572e-02, -2.0587e-02,  3.4584e-02,  5.8349e-02,  1.1274e-02,\n",
      "         -2.8570e-02,  5.8332e-03,  2.3256e-02,  1.7903e-03,  9.6168e-03,\n",
      "         -5.1550e-03, -1.1978e-02, -7.6655e-03, -1.8089e-02, -1.0163e-03,\n",
      "          6.4821e-03, -9.4291e-03, -2.7553e-02,  3.9077e-03, -1.5789e-02,\n",
      "          2.3832e-02,  7.4544e-03,  2.1219e-02,  1.0591e-02, -2.1970e-02,\n",
      "          1.1760e-02, -1.4146e-02,  9.0529e-03,  1.1205e-02, -2.9624e-02,\n",
      "          6.1132e-03, -2.4471e-02, -3.8483e-03,  1.7566e-02, -9.3588e-03,\n",
      "         -1.3721e-03,  4.2718e-02,  7.9191e-03,  2.8076e-04,  2.0738e-02,\n",
      "         -1.3558e-03, -9.4408e-03, -3.4278e-03,  1.1410e-02, -4.5712e-03,\n",
      "         -2.7038e-02, -8.3895e-03, -7.8318e-03,  2.0734e-03,  3.1591e-02,\n",
      "          1.5577e-02, -1.1125e-02, -1.5472e-02,  4.8994e-03,  8.2033e-03,\n",
      "          5.2097e-03, -1.9632e-03,  1.5489e-03,  1.5732e-02,  4.9822e-03,\n",
      "          4.5486e-02,  2.7672e-02,  3.0571e-03, -7.4561e-03, -6.2347e-03,\n",
      "          2.4890e-02, -3.4320e-02, -2.5630e-02,  2.7293e-02,  1.4232e-02,\n",
      "          2.9700e-02,  3.0164e-02, -7.9826e-03,  1.4918e-02, -1.4118e-02,\n",
      "         -2.0656e-02, -8.2345e-03, -2.7458e-02,  3.3123e-02,  1.9004e-02,\n",
      "         -2.8394e-02,  1.7143e-02,  1.8743e-02,  6.6182e-03,  7.0568e-03,\n",
      "          1.5259e-02,  2.0486e-02,  7.6290e-03,  2.9567e-03,  1.5077e-02,\n",
      "          1.8620e-02,  8.2187e-03,  2.2282e-02, -4.1882e-02, -4.8438e-02,\n",
      "         -1.2515e-02,  2.5327e-02,  9.0893e-04, -1.8091e-02,  1.5758e-03,\n",
      "         -1.7905e-02, -9.0322e-03,  1.3879e-02, -3.1193e-02,  1.5183e-02,\n",
      "         -2.7611e-02, -1.5085e-02,  2.1465e-02,  1.1374e-02,  4.1281e-03,\n",
      "          2.9811e-02, -1.8992e-03,  4.0993e-02,  2.0624e-02,  7.0758e-03,\n",
      "         -2.4109e-02, -2.6616e-02,  9.0565e-03,  2.7951e-02, -1.9213e-02,\n",
      "          2.0157e-02, -2.0973e-03, -2.2842e-02, -2.4564e-02,  2.8181e-02,\n",
      "         -1.6717e-02, -6.8991e-03,  1.0795e-03,  1.4169e-02, -1.7287e-02,\n",
      "         -2.6931e-02,  4.5241e-04,  1.1566e-02, -2.9218e-02,  1.1510e-02,\n",
      "         -2.5393e-03, -2.3387e-02, -3.3654e-02,  1.6873e-03, -3.2063e-02,\n",
      "          1.3946e-02, -8.9774e-03,  1.8257e-02, -7.8205e-03, -7.2124e-03,\n",
      "          1.0177e-02,  1.0531e-03,  4.1534e-02, -1.5646e-03,  4.5237e-03,\n",
      "          8.1464e-03,  1.8559e-02,  5.1355e-03,  1.6063e-02,  3.0315e-02,\n",
      "          3.4670e-02,  1.0843e-02,  2.3655e-02, -1.6233e-02, -1.7346e-02,\n",
      "          3.2961e-03]])\n",
      "\n",
      "bert.embeddings.LayerNorm.weight:\n",
      "\n",
      "tensor([1.0003, 1.0003, 1.0006, 0.9996, 1.0016, 1.0002, 0.9988, 1.0005, 0.9976,\n",
      "        0.9997, 0.9999, 1.0004, 0.9997, 0.9979, 1.0013, 0.9993, 1.0003, 1.0006,\n",
      "        1.0031, 0.9994, 1.0005, 1.0025, 1.0003, 1.0010, 1.0001, 1.0017, 1.0027,\n",
      "        1.0028, 1.0031, 0.9983, 0.9999, 1.0002, 1.0016, 1.0003, 1.0010, 1.0000,\n",
      "        0.9985, 0.9990, 1.0010, 0.9995, 1.0005, 1.0010, 1.0016, 1.0000, 0.9973,\n",
      "        0.9979, 1.0025, 0.9989, 0.9978, 1.0000, 1.0001, 1.0005, 0.9998, 0.9998,\n",
      "        0.9988, 0.9995, 1.0019, 1.0005, 1.0012, 0.9986, 0.9995, 0.9977, 0.9998,\n",
      "        1.0004, 1.0018, 1.0005, 1.0009, 0.9966, 1.0020, 1.0018, 1.0002, 0.9998,\n",
      "        0.9990, 0.9999, 1.0025, 1.0017, 0.9990, 0.9998, 1.0023, 0.9986, 0.9980,\n",
      "        1.0017, 1.0002, 0.9997, 0.9999, 1.0012, 1.0013, 1.0007, 0.9984, 1.0009,\n",
      "        0.9991, 0.9995, 0.9967, 1.0012, 0.9987, 1.0019, 1.0003, 1.0008, 0.9995,\n",
      "        1.0011, 1.0010, 1.0011, 0.9977, 0.9975, 1.0011, 1.0018, 0.9983, 1.0003,\n",
      "        0.9996, 0.9996, 1.0009, 0.9983, 1.0015, 0.9997, 1.0001, 0.9993, 1.0004,\n",
      "        1.0012, 1.0016, 0.9971, 1.0009, 1.0003, 1.0004, 1.0008, 0.9997, 0.9983,\n",
      "        1.0010, 0.9978, 0.9982, 1.0009, 1.0014, 1.0016, 0.9995, 1.0016, 0.9974,\n",
      "        0.9990, 0.9987, 0.9988, 1.0007, 0.9975, 1.0009, 1.0019, 0.9966, 0.9989,\n",
      "        0.9973, 0.9976, 1.0015, 1.0007, 1.0011, 0.9997, 1.0009, 1.0002, 0.9998,\n",
      "        0.9976, 1.0020, 1.0017, 0.9995, 0.9994, 1.0007, 1.0008, 1.0009, 0.9969,\n",
      "        1.0029, 1.0016, 1.0006, 0.9998, 0.9982, 1.0010, 1.0006, 1.0003, 1.0006,\n",
      "        0.9986, 1.0001, 1.0011, 1.0009, 0.9996, 1.0001, 1.0007, 0.9987, 0.9993,\n",
      "        1.0005, 1.0005, 0.9988, 1.0022, 0.9990, 1.0001, 1.0002, 0.9987, 1.0010,\n",
      "        1.0023, 0.9999, 1.0000, 0.9984, 1.0019, 0.9974, 1.0025, 0.9988, 1.0019,\n",
      "        1.0011, 1.0009, 0.9960, 0.9997, 0.9968, 0.9981, 0.9996, 1.0000, 1.0008,\n",
      "        1.0002, 0.9980, 0.9983, 0.9997, 1.0008, 0.9980, 1.0008, 0.9990, 1.0000,\n",
      "        0.9982, 0.9994, 0.9988, 0.9983, 1.0008, 1.0006, 0.9992, 0.9990, 0.9981,\n",
      "        0.9982, 1.0003, 1.0001, 0.9993, 1.0013, 1.0000, 0.9997, 1.0002, 1.0011,\n",
      "        1.0030, 0.9997, 0.9985, 1.0000, 0.9997, 0.9992, 1.0011, 0.9998, 0.9976,\n",
      "        0.9990, 0.9994, 0.9991, 1.0002, 0.9965, 1.0001, 0.9992, 1.0010, 0.9975,\n",
      "        1.0000, 0.9999, 1.0017, 1.0008])\n",
      "\n",
      "bert.embeddings.LayerNorm.bias:\n",
      "\n",
      "tensor([-3.0812e-04, -1.0704e-03,  2.7274e-04,  1.5013e-05,  3.0659e-04,\n",
      "         3.3030e-04, -2.5670e-04,  1.0890e-03,  1.1102e-03, -1.8984e-03,\n",
      "        -6.8172e-04,  8.6310e-04,  1.0092e-04, -3.2150e-04, -1.1493e-03,\n",
      "        -1.5839e-03, -1.0722e-03,  5.7338e-04, -4.5994e-04,  1.3287e-04,\n",
      "        -8.1937e-04, -1.0511e-03, -8.6649e-04,  1.3063e-03, -1.2382e-03,\n",
      "         6.4348e-05,  2.6350e-03,  1.1882e-04,  1.3190e-03,  8.4195e-04,\n",
      "         4.2935e-04,  6.6456e-04,  9.4783e-04, -1.6329e-04, -3.2014e-04,\n",
      "         2.9442e-04, -9.7482e-04,  2.7114e-04, -1.3682e-03,  7.1827e-04,\n",
      "        -1.7414e-03,  2.3319e-03,  1.4489e-03, -1.0384e-03,  1.5345e-04,\n",
      "        -1.1126e-05,  2.6108e-03,  7.1756e-04,  4.8865e-04,  6.6833e-04,\n",
      "        -1.4115e-03,  7.4982e-04, -1.9107e-04, -7.0271e-04, -1.7904e-04,\n",
      "        -1.2754e-03,  1.3330e-03, -1.1908e-03,  2.0297e-04,  3.1955e-04,\n",
      "        -4.5155e-04, -3.0462e-04, -1.8851e-03, -8.7488e-04,  1.3373e-03,\n",
      "         9.3199e-04,  7.5193e-04,  2.0231e-03,  1.5093e-04, -1.8175e-03,\n",
      "        -4.4784e-04, -1.3193e-03,  6.2461e-04, -1.3736e-03, -7.5465e-04,\n",
      "        -3.6209e-04,  1.3418e-03, -6.5177e-04,  1.4301e-03,  4.3252e-05,\n",
      "         1.5231e-03,  1.6082e-03,  7.7192e-05, -2.8807e-04,  1.2648e-03,\n",
      "         1.4147e-03, -1.4771e-03, -1.2373e-03, -5.2515e-04, -5.8516e-04,\n",
      "         4.4190e-06,  1.4773e-03, -9.4894e-04, -2.2914e-04,  1.4677e-03,\n",
      "        -1.4897e-03,  8.1024e-04,  2.4362e-05,  5.1376e-04, -1.2925e-03,\n",
      "        -1.5450e-03, -8.7152e-04, -7.3128e-04, -1.1983e-03,  4.8514e-04,\n",
      "         1.1110e-04, -1.1854e-03, -1.2661e-03, -6.4618e-04, -6.4272e-04,\n",
      "         1.3381e-03,  1.1567e-03,  1.2158e-03,  1.0627e-03,  1.0201e-03,\n",
      "        -8.1707e-04, -4.0009e-04,  1.6892e-04, -1.7414e-03, -1.8259e-04,\n",
      "         2.8969e-04,  3.0746e-04, -5.0267e-04,  1.3845e-03,  3.5577e-04,\n",
      "        -7.2923e-04, -2.3374e-05, -1.3339e-03,  7.3800e-04, -5.9964e-04,\n",
      "         5.9211e-04, -8.9912e-04, -1.6303e-04, -9.6444e-04,  1.4889e-03,\n",
      "        -8.6526e-04,  1.1200e-03, -7.2461e-04, -4.2216e-04,  2.0333e-04,\n",
      "         1.8547e-03, -3.0240e-04, -1.1392e-03, -7.5550e-04, -9.1441e-05,\n",
      "        -1.0369e-04,  1.5080e-03, -9.7749e-04,  3.1497e-04,  1.4468e-03,\n",
      "        -4.4653e-04,  1.0617e-03, -5.7746e-04,  2.0148e-03,  1.5192e-03,\n",
      "        -2.9577e-04, -9.8868e-05, -8.5061e-05,  6.5459e-05, -1.0666e-03,\n",
      "         3.6103e-04,  3.0072e-04,  7.6072e-04,  6.2914e-04, -1.4134e-03,\n",
      "        -7.1946e-04,  1.3264e-03,  6.8941e-04, -1.3058e-03, -1.0801e-03,\n",
      "         1.0876e-03, -4.2535e-04, -1.4121e-03,  3.1647e-04, -1.4286e-03,\n",
      "         2.2916e-04,  2.0975e-03,  1.4315e-03,  6.4647e-04, -2.5986e-04,\n",
      "        -4.3153e-04,  7.4861e-04, -1.2316e-03,  2.4647e-03,  2.5820e-04,\n",
      "        -7.5840e-04, -6.3092e-04, -1.0928e-04,  5.8965e-04, -1.4399e-03,\n",
      "         3.8221e-04,  1.2253e-04,  8.0937e-04,  9.1793e-06,  1.7433e-03,\n",
      "         1.0457e-03, -4.5062e-05,  2.6796e-04,  2.4709e-03,  4.5387e-04,\n",
      "         9.7766e-04, -4.0434e-04,  4.3677e-04,  9.7647e-04, -1.3798e-03,\n",
      "         1.4428e-05, -9.8622e-05,  1.1365e-03, -5.3446e-04,  8.7448e-04,\n",
      "        -7.7739e-06, -6.9475e-04, -4.4068e-04,  1.2792e-04, -8.3218e-04,\n",
      "        -5.5720e-04,  4.5067e-04, -6.9054e-06, -8.4572e-04, -5.3349e-04,\n",
      "        -1.3748e-03, -1.1127e-03, -1.4214e-03, -4.4954e-04,  1.3028e-03,\n",
      "        -5.0580e-04,  1.6610e-03, -2.7228e-06,  4.7549e-04,  1.2871e-03,\n",
      "        -5.4921e-04, -1.0775e-04, -1.8896e-03,  1.1545e-03,  5.3833e-05,\n",
      "         8.6831e-04,  5.1600e-04,  8.1657e-04, -6.1164e-04, -1.1623e-03,\n",
      "         1.8704e-04,  4.0981e-04, -1.2774e-03, -1.0169e-03,  4.8237e-04,\n",
      "         1.3787e-03, -9.1844e-04, -6.5648e-05,  1.2471e-03, -5.8192e-04,\n",
      "        -5.9695e-05,  2.0558e-03, -4.8077e-04,  3.0627e-04, -1.5287e-03,\n",
      "        -1.1864e-03])\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight:\n",
      "\n",
      "tensor([[-0.0156,  0.0221, -0.0075,  ..., -0.0070, -0.0199,  0.0104],\n",
      "        [ 0.0032, -0.0306, -0.0072,  ..., -0.0006, -0.0036, -0.0094],\n",
      "        [ 0.0100,  0.0181,  0.0049,  ..., -0.0136, -0.0202, -0.0250],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0100, -0.0120,  ..., -0.0402, -0.0356,  0.0375],\n",
      "        [-0.0071,  0.0044,  0.0035,  ...,  0.0388, -0.0180,  0.0047],\n",
      "        [-0.0442,  0.0149, -0.0414,  ...,  0.0092, -0.0375,  0.0169]])\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.bias:\n",
      "\n",
      "tensor([-8.5276e-04,  1.3676e-03,  1.4493e-03,  1.0185e-03, -5.7569e-04,\n",
      "         4.4045e-04,  1.3020e-04,  1.2516e-03, -8.7522e-04, -4.5985e-04,\n",
      "         2.1896e-03,  3.1588e-03,  8.2203e-04, -1.4720e-03,  1.2430e-03,\n",
      "         9.6493e-04,  1.8478e-03, -4.1372e-04, -1.3978e-03, -1.5077e-03,\n",
      "        -8.0647e-04, -1.3101e-03, -1.4300e-03, -3.1259e-03, -1.0148e-03,\n",
      "         8.7545e-04,  7.4437e-04, -1.0581e-03,  2.4710e-03,  1.3210e-03,\n",
      "         4.7331e-04,  1.3898e-04,  8.5997e-04, -2.1689e-03, -1.1700e-03,\n",
      "        -2.3451e-03, -4.5638e-04, -4.3429e-04, -5.5299e-04,  2.5219e-03,\n",
      "        -2.4961e-03, -2.2144e-03,  2.4486e-03, -1.5635e-03, -2.6718e-04,\n",
      "        -1.1994e-04,  2.0312e-04, -4.1598e-04,  1.6088e-04, -1.2008e-03,\n",
      "         2.2724e-03,  2.2002e-03, -5.7160e-05, -1.4363e-03, -6.6006e-05,\n",
      "         3.7186e-04, -1.9649e-03,  4.9118e-04, -2.0810e-03, -2.2118e-03,\n",
      "         2.6215e-03,  5.2318e-04,  7.8815e-04, -1.4373e-03, -1.1452e-03,\n",
      "         2.5031e-04,  2.4657e-03, -8.5133e-04, -1.8126e-03,  1.4626e-04,\n",
      "         1.0415e-03, -2.8288e-03, -1.2543e-03, -1.7949e-03,  2.4292e-03,\n",
      "         2.2772e-03,  1.4721e-03, -7.6050e-04, -2.7481e-04, -8.9177e-04,\n",
      "        -2.7497e-04,  6.6357e-04,  1.9879e-03, -1.3659e-03, -1.6289e-03,\n",
      "        -3.5837e-04, -8.4491e-04,  4.1701e-03, -1.4140e-03,  9.6398e-04,\n",
      "         1.5091e-03,  1.4903e-03,  8.1849e-04,  1.5120e-03,  6.6746e-04,\n",
      "         2.0956e-04,  1.3120e-04,  3.2187e-03,  2.8759e-03, -3.5131e-03,\n",
      "        -2.4453e-03, -1.8170e-03,  1.4586e-03, -7.5133e-04,  2.9132e-03,\n",
      "        -3.1709e-03,  3.6144e-03,  1.2563e-03,  3.8318e-03, -1.3443e-03,\n",
      "         2.6986e-04, -3.4026e-03,  1.4944e-03, -8.9028e-04,  5.2841e-04,\n",
      "         8.2893e-04,  9.9122e-04,  8.6386e-04, -8.4882e-05, -1.3786e-03,\n",
      "         2.3513e-04,  3.7902e-03,  1.4446e-03, -5.5237e-04, -8.6998e-04,\n",
      "         1.5901e-03,  2.1932e-03,  3.0882e-04,  1.5726e-03,  4.0310e-04,\n",
      "        -2.5416e-03, -1.2313e-03,  5.6391e-04,  4.0423e-04,  1.2854e-03,\n",
      "         2.0348e-03,  2.0835e-03,  1.5875e-03, -4.2558e-04, -1.3317e-03,\n",
      "         3.4457e-03,  6.9144e-05, -2.0153e-03,  1.4155e-03,  1.6173e-03,\n",
      "         5.4214e-06,  3.7753e-04,  2.7035e-03, -6.9844e-04, -2.6744e-03,\n",
      "        -6.2737e-04,  2.2043e-03,  1.2009e-03,  5.6630e-04, -2.0900e-04,\n",
      "         7.0530e-04, -1.9542e-04, -3.6049e-04, -1.2239e-03, -1.3845e-03,\n",
      "        -8.1832e-04,  1.2252e-03, -1.9566e-03,  1.0587e-03,  1.4590e-03,\n",
      "        -2.5668e-04, -9.8041e-04,  1.0511e-03,  2.6401e-03, -3.8489e-04,\n",
      "         2.0666e-03, -1.3910e-03, -8.3892e-05,  7.7886e-04, -3.5913e-04,\n",
      "         2.3787e-03, -1.0205e-03,  1.8294e-03, -3.2679e-04,  2.6607e-03,\n",
      "         3.0392e-03, -9.7200e-04, -7.4271e-04,  3.8898e-04,  1.0799e-03,\n",
      "        -1.2601e-03, -1.7472e-03,  6.3010e-04, -2.3171e-03,  1.1656e-03,\n",
      "        -1.8569e-03, -1.2290e-04,  4.7308e-04, -1.1256e-03,  2.5847e-03,\n",
      "        -9.0032e-04, -1.9033e-03, -7.8336e-04, -1.8755e-03, -7.1638e-05,\n",
      "        -2.3550e-03, -2.2320e-04, -8.4421e-04,  8.6895e-04, -2.4529e-03,\n",
      "        -4.3753e-04, -1.2585e-03,  8.5987e-04,  8.5404e-04, -9.7688e-04,\n",
      "        -8.5169e-04,  6.0863e-04, -1.9257e-04, -1.1627e-03,  8.0283e-04,\n",
      "        -2.7631e-04,  1.8873e-03,  4.8986e-04,  2.3382e-03,  1.0544e-03,\n",
      "         3.1312e-04, -9.8751e-04, -7.9917e-04,  8.6350e-04, -4.8756e-04,\n",
      "         3.9531e-04,  2.2286e-03, -1.9201e-03, -2.0195e-03, -9.2695e-04,\n",
      "        -2.9985e-03, -5.3407e-04,  6.3586e-04, -5.5057e-04,  2.3361e-03,\n",
      "         1.4123e-03,  4.0178e-04, -1.0841e-03, -3.0618e-04, -8.0604e-04,\n",
      "        -2.5294e-03, -6.2379e-04, -2.2781e-03,  1.8624e-03, -2.5415e-03,\n",
      "         5.2024e-04,  1.0498e-03, -1.2011e-03, -1.4827e-03,  3.8388e-04,\n",
      "        -1.8605e-03,  3.2155e-03,  9.7782e-04,  2.7940e-03,  1.0980e-04,\n",
      "        -2.0178e-03])\n",
      "\n",
      "bert.encoder.layer.0.attention.self.key.weight:\n",
      "\n",
      "tensor([[-0.0298, -0.0139,  0.0063,  ...,  0.0130, -0.0090, -0.0546],\n",
      "        [ 0.0284,  0.0022, -0.0232,  ..., -0.0048, -0.0309,  0.0064],\n",
      "        [-0.0262,  0.0181, -0.0003,  ...,  0.0199, -0.0058, -0.0210],\n",
      "        ...,\n",
      "        [-0.0459, -0.0123,  0.0011,  ...,  0.0120,  0.0106, -0.0201],\n",
      "        [ 0.0310,  0.0563, -0.0232,  ..., -0.0052,  0.0117,  0.0237],\n",
      "        [-0.0043, -0.0155,  0.0094,  ...,  0.0251, -0.0228, -0.0029]])\n",
      "\n",
      "bert.encoder.layer.0.attention.self.key.bias:\n",
      "\n",
      "tensor([-1.5776e-09,  9.9651e-09,  5.2323e-09,  1.4016e-08,  5.0463e-09,\n",
      "         9.2683e-09,  2.8262e-09,  5.3693e-09, -5.1976e-09, -1.0737e-08,\n",
      "         1.2437e-08,  7.2680e-09, -5.1315e-09,  2.3711e-09,  2.7779e-09,\n",
      "        -3.5302e-09, -2.8351e-09, -7.2760e-10, -8.1719e-09, -5.1214e-09,\n",
      "        -1.5631e-10, -9.5736e-09, -5.2270e-09, -1.1349e-09, -2.1167e-09,\n",
      "         9.7436e-09, -7.6727e-09, -1.4739e-08,  1.9018e-08, -1.3636e-09,\n",
      "        -7.0762e-09,  6.0513e-10, -5.8709e-09,  9.4136e-11, -6.3345e-09,\n",
      "        -3.3282e-09, -2.0883e-09, -4.8534e-09, -1.0870e-10,  7.8822e-10,\n",
      "        -5.5598e-09, -6.4027e-09,  2.7945e-09, -3.9169e-09,  1.8840e-09,\n",
      "        -2.4955e-09, -5.3454e-09, -7.5651e-09,  4.3111e-09, -1.1375e-08,\n",
      "         3.8354e-09,  8.6513e-09,  1.9136e-09, -9.6385e-09, -5.1281e-09,\n",
      "        -1.1759e-08,  3.3401e-09, -4.4938e-09, -1.1507e-08, -1.1720e-08,\n",
      "         3.3966e-09,  1.7255e-09,  1.5490e-08, -4.5410e-09,  7.1286e-09,\n",
      "        -5.9514e-10, -2.1692e-09,  1.6441e-10,  1.8361e-09,  5.7054e-09,\n",
      "         6.0966e-09,  3.0897e-09,  1.3378e-08,  1.4241e-08, -1.9124e-08,\n",
      "        -4.5403e-09, -7.8077e-09, -3.7261e-10, -4.1300e-09,  1.4387e-09,\n",
      "         6.5262e-10,  2.2094e-09, -7.3089e-09,  3.9016e-09, -5.6888e-09,\n",
      "        -2.2568e-09, -3.7106e-09, -1.1012e-08, -5.2828e-09, -3.6171e-11,\n",
      "        -5.2453e-09,  6.2473e-09,  1.7816e-09,  8.6943e-09, -6.5331e-09,\n",
      "        -3.4092e-09,  4.6302e-09, -1.2510e-08, -3.6326e-09,  1.4429e-08,\n",
      "         9.8205e-09,  4.3586e-09, -4.3748e-09,  3.9498e-09, -1.0493e-08,\n",
      "        -1.7754e-09, -1.8123e-08, -5.5607e-09, -1.3713e-08, -1.1748e-09,\n",
      "         7.7740e-09,  7.9006e-09, -9.1519e-09,  9.5486e-09, -6.3614e-09,\n",
      "         2.0228e-09, -5.7229e-09, -5.4975e-09,  3.1878e-09,  2.7042e-09,\n",
      "        -5.6132e-09, -3.9237e-09,  1.9705e-09, -3.0766e-09,  3.5080e-09,\n",
      "        -3.0085e-09, -5.8909e-09,  7.1578e-09, -9.9764e-09, -3.9414e-09,\n",
      "        -3.7718e-09, -6.9843e-09, -1.2038e-08,  1.8768e-09,  8.5462e-10,\n",
      "        -3.8068e-09, -5.8683e-10,  4.0423e-09, -4.7445e-09,  2.4565e-09,\n",
      "         5.7784e-09, -1.0722e-09, -1.4228e-09, -3.2792e-09, -1.5032e-09,\n",
      "         2.7743e-09, -4.9469e-09,  3.3475e-09, -5.0925e-09,  7.0787e-09,\n",
      "        -9.2718e-09,  5.5895e-09,  2.2413e-09,  5.6603e-09,  6.9244e-09,\n",
      "         4.1839e-09, -6.8181e-10, -6.0374e-09,  2.9382e-09, -5.5314e-09,\n",
      "        -8.9292e-09, -1.7821e-08, -9.1083e-09,  3.6497e-09,  2.6381e-09,\n",
      "         9.3481e-09,  3.6620e-09,  1.0870e-09, -4.0044e-09,  2.5237e-10,\n",
      "        -1.7695e-10, -4.1427e-09,  5.6581e-09, -1.8763e-09, -4.8648e-09,\n",
      "         1.0325e-08,  4.3930e-09,  2.6175e-09,  3.3908e-09,  6.5274e-10,\n",
      "        -1.6326e-09, -1.3698e-09, -1.4958e-08,  8.3416e-09, -1.0522e-09,\n",
      "         4.8801e-09,  4.6938e-09, -3.1292e-09, -8.0698e-09,  3.7612e-09,\n",
      "         9.7549e-09, -5.9782e-09,  1.7505e-09,  5.2729e-10,  2.3040e-09,\n",
      "         5.2459e-09,  3.6407e-09, -5.7948e-09, -5.4027e-09, -6.0863e-10,\n",
      "        -2.0572e-11, -9.0756e-10, -5.4235e-09,  1.7592e-09, -8.6777e-09,\n",
      "        -4.1663e-10,  2.3816e-09, -9.5414e-10,  2.7550e-10,  1.3284e-09,\n",
      "        -2.5156e-12,  1.8113e-09,  3.7590e-09,  1.1522e-09, -3.5957e-09,\n",
      "         1.8152e-09,  4.2053e-10, -1.0890e-09,  4.7679e-09,  9.7824e-10,\n",
      "         1.1992e-08, -5.1397e-10, -4.9580e-09, -2.4085e-09, -8.6187e-10,\n",
      "        -1.7217e-09,  5.2517e-09, -2.6504e-10,  7.4364e-10,  2.2160e-09,\n",
      "        -1.9214e-09, -4.1829e-09, -4.3401e-09,  4.3489e-11, -4.4122e-10,\n",
      "        -1.9175e-09,  4.7424e-09, -5.7802e-09, -4.0375e-09, -2.6200e-10,\n",
      "         4.9710e-10, -4.5673e-10, -1.6507e-08,  2.7001e-09, -6.8919e-09,\n",
      "         7.9694e-09, -7.3933e-09,  1.5878e-09, -2.1013e-09,  3.1112e-09,\n",
      "         4.0801e-10,  3.3323e-09,  6.6244e-09,  5.6288e-09,  1.2005e-09,\n",
      "        -3.9957e-09])\n",
      "\n",
      "bert.encoder.layer.0.attention.self.value.weight:\n",
      "\n",
      "tensor([[-0.0028, -0.0092,  0.0001,  ...,  0.0046, -0.0243,  0.0284],\n",
      "        [ 0.0033, -0.0203, -0.0463,  ..., -0.0115,  0.0157, -0.0601],\n",
      "        [ 0.0158,  0.0070,  0.0015,  ...,  0.0148,  0.0061, -0.0171],\n",
      "        ...,\n",
      "        [ 0.0125, -0.0188,  0.0049,  ..., -0.0391, -0.0014, -0.0217],\n",
      "        [ 0.0123,  0.0230,  0.0028,  ...,  0.0139,  0.0150, -0.0340],\n",
      "        [-0.0287,  0.0122,  0.0032,  ..., -0.0156,  0.0174, -0.0010]])\n",
      "\n",
      "bert.encoder.layer.0.attention.self.value.bias:\n",
      "\n",
      "tensor([-1.1321e-04,  7.5655e-04,  3.9472e-04, -1.0773e-03, -1.3834e-03,\n",
      "        -8.2621e-04,  4.1505e-04, -1.3508e-03,  3.1050e-05,  1.1668e-04,\n",
      "        -4.3231e-04, -4.3344e-04,  5.1773e-06,  2.2852e-03, -1.5887e-03,\n",
      "         6.5070e-04, -9.5466e-04, -6.7544e-04, -6.0786e-04,  1.4368e-03,\n",
      "         7.6657e-04, -6.3035e-04,  8.9542e-05, -9.5585e-04,  2.4403e-03,\n",
      "         1.4121e-03,  8.8313e-04, -1.0688e-03,  2.2391e-04,  1.7095e-03,\n",
      "         7.7554e-04, -2.1652e-03, -1.6684e-03, -1.1846e-03, -1.4279e-03,\n",
      "         2.8352e-05,  1.4446e-04,  1.3468e-03,  1.2126e-04, -1.4886e-04,\n",
      "         2.1184e-05, -8.6474e-04, -8.3841e-04,  6.3704e-04, -2.1503e-03,\n",
      "        -2.8636e-04, -1.0894e-03, -2.4240e-04,  1.1257e-03, -1.8038e-04,\n",
      "         1.1034e-03, -1.0132e-03,  8.6912e-04, -9.0775e-05, -1.5433e-03,\n",
      "         6.1950e-04, -6.6111e-04, -1.4455e-03,  9.2147e-04,  1.2114e-03,\n",
      "        -4.6922e-04,  8.5444e-04, -6.2564e-04, -6.8750e-04,  1.2493e-03,\n",
      "        -4.5008e-04,  5.7177e-05,  8.5530e-04, -1.4363e-03, -4.2849e-04,\n",
      "         8.6901e-05, -1.7549e-03, -4.5941e-04, -1.2488e-03,  7.1165e-04,\n",
      "        -1.0558e-03, -7.0120e-04,  1.0501e-03, -1.9150e-03,  1.0724e-03,\n",
      "         1.4082e-03, -1.5524e-03,  1.2773e-04,  8.6408e-04, -8.5023e-04,\n",
      "        -2.5893e-04,  1.4560e-03,  1.0280e-03, -1.3276e-03,  1.5196e-03,\n",
      "         2.5334e-03, -6.1201e-04, -1.0359e-03, -1.5516e-03, -1.3405e-05,\n",
      "        -9.4446e-04,  7.3018e-05,  1.6871e-04, -5.1344e-05,  6.4600e-04,\n",
      "         2.4700e-04, -6.6235e-04,  7.9188e-04, -1.8414e-03,  4.5404e-04,\n",
      "         1.1145e-03,  4.2545e-04, -1.7218e-03, -1.4692e-04,  6.1367e-04,\n",
      "         1.9754e-04,  1.3647e-03,  1.8527e-03,  8.2204e-04, -1.2649e-03,\n",
      "         1.5369e-03, -3.7355e-04, -1.6897e-04, -4.4863e-04, -4.7026e-04,\n",
      "         2.4241e-04, -4.3469e-04, -6.4453e-04, -3.6167e-04,  8.8804e-04,\n",
      "        -1.1584e-03, -1.0225e-03,  4.8687e-04,  1.7361e-03, -4.8742e-04,\n",
      "        -5.4272e-04,  1.8314e-03, -1.4919e-03, -1.9456e-03, -8.1115e-05,\n",
      "        -1.2369e-03,  1.4411e-03,  4.5951e-04,  9.5626e-05,  5.9030e-05,\n",
      "        -1.5806e-03, -6.2764e-04, -2.1744e-04, -5.1036e-04, -1.4973e-03,\n",
      "        -1.4557e-04,  6.0860e-04,  7.2949e-04,  5.5813e-04, -7.2428e-04,\n",
      "        -3.7087e-04, -5.9559e-04, -6.8775e-05, -1.0186e-03, -8.3982e-04,\n",
      "         1.0894e-03, -2.6871e-05,  2.1590e-03, -2.6373e-03,  2.2997e-03,\n",
      "         3.8033e-04, -3.5996e-04, -1.1467e-03, -6.6762e-04,  1.7959e-03,\n",
      "        -2.5161e-03, -1.0240e-03, -7.3937e-04,  8.2001e-04,  1.8416e-03,\n",
      "        -2.7034e-04,  1.7021e-04,  4.4919e-04, -1.1626e-03,  1.6802e-03,\n",
      "        -1.0644e-03, -9.6519e-06,  5.7070e-04, -1.3752e-03, -1.5952e-03,\n",
      "         1.6915e-04,  9.4326e-04,  1.8093e-03,  1.1038e-03, -7.0185e-05,\n",
      "         1.8367e-03,  1.0381e-03, -5.5217e-04,  1.7561e-03, -5.0450e-04,\n",
      "         1.3937e-04, -2.4521e-04, -7.5958e-05, -4.1287e-04, -4.8452e-04,\n",
      "        -1.4898e-03, -2.3931e-03, -7.8283e-04, -8.8358e-04,  3.1166e-04,\n",
      "        -3.9233e-04,  2.3740e-04, -2.8561e-04,  4.1875e-04, -9.5727e-04,\n",
      "        -4.3117e-04, -2.3608e-04, -7.6974e-04,  2.2364e-03,  1.2022e-03,\n",
      "        -2.0107e-04,  4.0202e-04,  6.0559e-04,  3.7147e-04, -1.4063e-03,\n",
      "        -5.2475e-04, -7.1896e-04, -8.1229e-04, -1.5102e-03, -1.0201e-03,\n",
      "        -3.7612e-04, -1.3226e-03,  1.6765e-03, -1.6585e-03, -7.6201e-04,\n",
      "        -1.5287e-03, -1.6304e-03,  3.0109e-04,  9.1990e-04, -3.2984e-04,\n",
      "         7.5477e-05,  1.3509e-03, -2.1245e-03,  8.6367e-04,  1.8125e-04,\n",
      "         1.0734e-03, -1.5139e-03, -2.4277e-04, -1.0840e-03, -3.2149e-04,\n",
      "         9.1113e-04,  9.7819e-04,  3.0206e-04,  1.5762e-03,  5.3570e-04,\n",
      "        -2.0431e-04,  1.2113e-03,  9.6113e-05, -1.9378e-03, -1.0683e-03,\n",
      "        -1.0793e-03, -4.0895e-04, -1.0907e-03,  1.4439e-03, -3.7380e-04,\n",
      "        -1.9720e-04])\n",
      "\n",
      "bert.encoder.layer.0.attention.output.dense.weight:\n",
      "\n",
      "tensor([[-0.0211,  0.0107,  0.0136,  ...,  0.0254, -0.0179,  0.0177],\n",
      "        [ 0.0129,  0.0110,  0.0025,  ..., -0.0586,  0.0224,  0.0100],\n",
      "        [-0.0035,  0.0064, -0.0330,  ...,  0.0008,  0.0079, -0.0169],\n",
      "        ...,\n",
      "        [ 0.0111, -0.0439, -0.0429,  ...,  0.0148,  0.0399,  0.0484],\n",
      "        [-0.0168,  0.0290,  0.0053,  ..., -0.0221,  0.0010,  0.0185],\n",
      "        [-0.0126,  0.0581, -0.0115,  ...,  0.0289, -0.0126, -0.0114]])\n",
      "\n",
      "bert.encoder.layer.0.attention.output.dense.bias:\n",
      "\n",
      "tensor([-2.6283e-04, -6.7982e-04, -1.1740e-04, -2.6316e-04,  7.0891e-04,\n",
      "         1.0095e-03, -8.5933e-04,  9.9316e-04,  4.2366e-04, -1.1235e-03,\n",
      "        -5.2810e-04,  4.4830e-04,  7.3110e-04,  1.7467e-04, -4.3321e-04,\n",
      "        -1.5067e-03, -1.5076e-03,  4.9112e-04, -8.0363e-04,  1.3479e-03,\n",
      "        -3.5660e-04, -4.5355e-04, -1.0233e-03,  2.0917e-03,  3.3285e-04,\n",
      "        -2.4004e-04,  1.2762e-03, -1.4822e-04,  1.2095e-03,  1.1581e-03,\n",
      "         2.0508e-05,  6.2882e-04, -2.3840e-04, -4.7749e-04, -4.6138e-04,\n",
      "         1.2917e-03, -5.6614e-04,  1.0889e-03, -1.7424e-03,  1.1350e-04,\n",
      "        -2.0623e-03,  1.9094e-03,  1.4200e-03, -1.1220e-03,  1.5802e-03,\n",
      "         5.2223e-04,  1.0339e-03,  6.1708e-04,  8.5166e-04,  1.2226e-03,\n",
      "        -2.4308e-03,  6.8210e-04, -7.3239e-04, -6.9872e-05, -4.6301e-04,\n",
      "        -1.3336e-03,  8.6931e-04, -9.0639e-04,  6.3312e-05,  6.5498e-04,\n",
      "        -7.2820e-04, -1.1880e-03, -1.5286e-03, -1.9217e-03,  7.8901e-04,\n",
      "         1.2294e-03,  1.1134e-03,  1.8605e-03,  7.3427e-04, -1.8285e-03,\n",
      "        -6.2590e-04, -1.9475e-03, -1.9744e-04, -4.6201e-04, -1.6375e-04,\n",
      "        -8.4280e-04,  8.6964e-04, -9.5245e-04, -4.5065e-04, -3.4679e-04,\n",
      "         1.4392e-03,  8.8615e-04,  6.9706e-04, -7.6829e-04,  6.2667e-04,\n",
      "         1.1506e-03, -1.0529e-03, -1.4522e-03, -1.4078e-04, -5.6979e-04,\n",
      "         2.3357e-04,  2.1243e-03, -1.4220e-03,  9.3444e-05,  4.9999e-04,\n",
      "        -1.5982e-03,  2.9269e-04, -8.5303e-04, -8.2298e-04,  8.2241e-04,\n",
      "        -1.5361e-03, -3.7513e-04, -1.1101e-03, -1.1193e-03,  1.2233e-03,\n",
      "         3.7631e-04, -6.5932e-05, -1.7603e-03, -9.7881e-04,  4.6791e-04,\n",
      "         9.8746e-04,  2.2631e-04,  9.8084e-04,  3.6228e-04, -6.7056e-04,\n",
      "        -6.6537e-04, -1.3853e-03,  1.6275e-03, -1.5031e-03, -1.0967e-03,\n",
      "         3.0209e-04, -8.6816e-04, -1.4405e-03,  6.2211e-04, -2.1220e-04,\n",
      "        -2.8494e-05, -1.5784e-03, -1.1160e-03,  1.3556e-03, -8.4301e-04,\n",
      "         9.0449e-04, -1.5289e-04,  7.9730e-05, -2.0300e-03,  7.9437e-04,\n",
      "        -1.1239e-03,  1.3101e-04, -6.7837e-04,  1.1778e-04,  3.7463e-04,\n",
      "         1.0267e-03,  5.0925e-04,  4.0139e-04, -6.8752e-04,  1.6039e-04,\n",
      "        -5.5980e-04,  1.8711e-03, -5.0241e-04, -8.8776e-04,  1.2849e-03,\n",
      "        -1.1050e-03,  9.0471e-04, -1.7626e-03,  1.5500e-03,  1.2033e-03,\n",
      "        -8.1871e-04, -2.6254e-04, -6.8410e-04, -4.1148e-04, -1.1801e-03,\n",
      "         1.2061e-03,  1.2217e-03,  1.3969e-03,  9.8939e-04, -1.1748e-03,\n",
      "        -7.5179e-04,  2.1719e-03,  2.5589e-04, -1.0016e-03, -1.3677e-03,\n",
      "         9.2624e-05, -3.3427e-04, -1.1887e-03, -8.8060e-04, -8.9010e-04,\n",
      "        -1.5022e-04,  1.6536e-03,  1.7546e-03,  7.7036e-04,  1.0567e-03,\n",
      "        -1.0410e-04,  9.7779e-04, -8.7080e-04,  2.4312e-03, -1.2896e-04,\n",
      "        -1.0621e-05,  3.7619e-04,  1.1495e-03,  6.9692e-04, -9.8385e-04,\n",
      "         6.1210e-04, -7.5399e-04,  1.4175e-03, -8.2107e-04,  1.3945e-03,\n",
      "         1.9403e-03, -3.5574e-04, -5.1976e-04,  1.4483e-03,  1.1583e-03,\n",
      "         1.1159e-03,  3.0385e-04, -1.2723e-03, -1.8545e-04, -3.7609e-05,\n",
      "         1.7279e-04,  2.5130e-04,  1.6398e-03,  1.4087e-03, -2.2506e-04,\n",
      "         2.7517e-04, -6.8197e-04, -4.4969e-04,  3.3337e-04, -3.4989e-04,\n",
      "         1.0041e-03,  1.5909e-03, -4.3182e-04, -1.0606e-03,  3.2064e-05,\n",
      "        -1.3224e-03, -1.3962e-03, -1.1766e-03,  6.9251e-04,  6.8185e-04,\n",
      "        -4.9446e-04,  8.7835e-04, -2.0470e-04,  9.8147e-04,  3.0103e-04,\n",
      "        -1.8545e-03,  1.1605e-03, -1.3826e-03,  3.5365e-04,  1.4044e-04,\n",
      "         1.0905e-03,  6.2780e-04,  4.4547e-04,  3.1369e-04, -4.6496e-04,\n",
      "        -1.0090e-04,  1.0585e-03,  4.9108e-04, -1.1501e-03, -4.3421e-04,\n",
      "         4.4861e-04, -1.7152e-03, -1.0237e-03,  1.7232e-03,  5.6174e-05,\n",
      "        -9.1716e-04,  1.5308e-03, -1.1222e-03,  1.5930e-03, -2.8020e-04,\n",
      "        -1.4536e-03])\n",
      "\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight:\n",
      "\n",
      "tensor([1.0002, 1.0002, 1.0005, 0.9996, 1.0015, 1.0001, 0.9987, 1.0003, 0.9976,\n",
      "        0.9995, 0.9998, 1.0001, 0.9997, 0.9978, 1.0010, 1.0000, 1.0002, 1.0004,\n",
      "        1.0033, 0.9995, 1.0006, 1.0025, 1.0002, 1.0011, 0.9999, 1.0016, 1.0029,\n",
      "        1.0024, 1.0031, 0.9982, 1.0000, 1.0002, 1.0017, 1.0003, 1.0009, 0.9999,\n",
      "        0.9986, 0.9990, 1.0010, 0.9995, 1.0007, 1.0014, 1.0019, 1.0000, 0.9971,\n",
      "        0.9980, 1.0025, 0.9990, 0.9978, 1.0001, 1.0001, 1.0004, 0.9997, 0.9996,\n",
      "        0.9989, 0.9999, 1.0018, 1.0003, 1.0011, 0.9988, 0.9994, 0.9982, 1.0002,\n",
      "        1.0005, 1.0020, 1.0004, 1.0010, 0.9974, 1.0019, 1.0020, 1.0002, 1.0000,\n",
      "        0.9990, 1.0001, 1.0024, 1.0014, 0.9995, 0.9999, 1.0021, 0.9987, 0.9980,\n",
      "        1.0017, 1.0002, 0.9994, 1.0000, 1.0012, 1.0014, 1.0007, 0.9983, 1.0009,\n",
      "        0.9992, 0.9997, 0.9968, 1.0010, 0.9988, 1.0019, 1.0004, 1.0010, 0.9994,\n",
      "        1.0011, 1.0010, 1.0013, 0.9977, 0.9973, 1.0012, 1.0018, 0.9982, 1.0003,\n",
      "        0.9996, 0.9995, 1.0008, 0.9984, 1.0014, 0.9999, 1.0001, 0.9993, 1.0004,\n",
      "        1.0014, 1.0017, 0.9972, 1.0009, 1.0002, 1.0005, 1.0007, 0.9998, 0.9982,\n",
      "        1.0009, 0.9975, 0.9983, 1.0008, 1.0012, 1.0017, 0.9995, 1.0017, 0.9974,\n",
      "        0.9995, 0.9985, 0.9987, 1.0006, 0.9974, 1.0008, 1.0019, 0.9963, 0.9989,\n",
      "        0.9974, 0.9975, 1.0015, 1.0007, 1.0011, 0.9996, 1.0008, 1.0005, 0.9997,\n",
      "        0.9984, 1.0019, 1.0018, 0.9994, 0.9994, 1.0007, 1.0007, 1.0009, 0.9964,\n",
      "        1.0026, 1.0017, 1.0008, 0.9998, 0.9985, 1.0010, 1.0006, 1.0005, 1.0010,\n",
      "        0.9986, 1.0002, 1.0013, 1.0009, 0.9997, 1.0002, 1.0008, 0.9989, 0.9993,\n",
      "        1.0005, 1.0006, 0.9988, 1.0023, 0.9990, 1.0000, 1.0002, 0.9987, 1.0010,\n",
      "        1.0022, 0.9999, 1.0000, 0.9986, 1.0018, 0.9977, 1.0025, 0.9987, 1.0018,\n",
      "        1.0011, 1.0010, 0.9960, 0.9997, 0.9966, 0.9977, 0.9996, 1.0001, 1.0012,\n",
      "        1.0002, 0.9979, 0.9983, 0.9997, 1.0008, 0.9979, 1.0009, 0.9991, 1.0001,\n",
      "        0.9981, 0.9994, 0.9987, 0.9981, 1.0008, 1.0007, 0.9994, 0.9991, 0.9982,\n",
      "        0.9982, 1.0004, 1.0001, 0.9992, 1.0011, 1.0000, 0.9997, 1.0002, 1.0011,\n",
      "        1.0023, 0.9998, 0.9985, 0.9999, 0.9995, 0.9992, 1.0013, 0.9994, 0.9973,\n",
      "        0.9992, 0.9993, 0.9992, 1.0003, 0.9966, 1.0002, 0.9993, 1.0010, 0.9973,\n",
      "        1.0000, 0.9998, 1.0017, 1.0010])\n",
      "\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias:\n",
      "\n",
      "tensor([-2.7393e-04, -1.0011e-03,  2.0594e-05,  3.0116e-04,  5.8644e-04,\n",
      "         1.1013e-03, -4.9879e-04,  1.1321e-03,  8.6265e-04, -1.2317e-03,\n",
      "        -3.9218e-04,  4.3337e-04,  3.1216e-04,  3.7467e-04, -5.7328e-04,\n",
      "        -1.3142e-03, -2.1894e-03,  1.0387e-03, -8.9502e-04,  8.7063e-04,\n",
      "        -5.1506e-04, -6.0576e-04, -1.1083e-03,  2.4045e-03,  2.3284e-04,\n",
      "        -6.3387e-04,  2.2031e-03, -1.7335e-04,  1.5615e-03,  5.7301e-04,\n",
      "         2.7201e-04,  4.9308e-04,  6.5591e-04, -6.4332e-04, -4.7928e-04,\n",
      "         8.5967e-04, -9.4091e-04, -2.6569e-05, -2.0648e-03,  5.6161e-04,\n",
      "        -1.1208e-03,  2.2987e-03,  1.5753e-03, -1.1025e-03,  3.8347e-04,\n",
      "         4.8569e-04,  1.6952e-03, -1.8677e-04,  6.3131e-04,  1.1833e-03,\n",
      "        -1.0279e-03,  1.0934e-03, -4.1571e-04, -2.4018e-04, -5.8510e-04,\n",
      "        -1.6141e-03,  9.0904e-04, -9.5343e-04,  9.5169e-05,  3.8463e-04,\n",
      "        -5.4407e-04, -4.1853e-04, -1.8617e-03, -1.5090e-03,  9.8176e-04,\n",
      "         5.1860e-04,  1.1987e-03,  1.6288e-03,  1.0805e-03, -1.5434e-03,\n",
      "        -5.7622e-04, -1.1811e-03, -1.0632e-03, -3.8872e-04, -2.8322e-04,\n",
      "        -6.4847e-04,  1.1945e-03, -1.2062e-03,  1.2735e-03,  3.0179e-04,\n",
      "         1.4163e-03,  1.2136e-03,  1.0462e-03, -7.8551e-04,  1.8701e-03,\n",
      "         1.7371e-03, -1.4577e-03, -1.1067e-03, -6.6034e-04, -6.9832e-04,\n",
      "        -1.9060e-04,  1.3045e-03, -9.6281e-04, -9.7153e-05,  6.0000e-04,\n",
      "        -1.8302e-03,  1.0065e-03, -2.6410e-04, -8.9029e-04, -2.3841e-04,\n",
      "        -1.6560e-03, -1.4306e-03, -7.4115e-04, -1.0949e-03,  1.2378e-03,\n",
      "        -7.0587e-05, -3.7661e-05, -1.8922e-03, -4.0993e-04,  3.6109e-04,\n",
      "         1.1441e-03,  6.2974e-04,  6.0889e-04,  9.4772e-04,  5.7279e-04,\n",
      "        -7.6607e-04, -1.3165e-03,  5.2976e-04, -1.4805e-03, -4.4376e-04,\n",
      "         1.1279e-04, -6.3703e-04, -8.2923e-04,  9.9336e-04,  3.0719e-04,\n",
      "        -9.6774e-05, -1.6063e-03, -1.3264e-03,  1.2500e-03, -4.8074e-04,\n",
      "         5.9279e-04, -2.4603e-04,  7.7980e-05, -2.0432e-03,  7.6730e-04,\n",
      "        -1.0157e-03,  7.1253e-04, -7.2194e-04, -5.2604e-05, -2.2210e-04,\n",
      "         1.6257e-03, -4.4983e-04,  9.9943e-04, -1.0293e-03, -3.1099e-04,\n",
      "        -2.5628e-04,  2.4819e-03, -4.9784e-04, -7.9150e-04,  1.4651e-03,\n",
      "        -6.6536e-04,  1.0006e-03, -1.3897e-03,  1.9544e-03,  1.6768e-03,\n",
      "        -5.6903e-04, -1.3364e-04, -6.5301e-04, -3.2743e-04, -1.1131e-03,\n",
      "         1.1581e-03,  6.9749e-04,  9.8996e-04,  8.4968e-04, -1.6812e-03,\n",
      "        -5.9597e-04,  1.2273e-03,  1.8815e-04, -1.3920e-03, -8.4218e-04,\n",
      "         1.0376e-03, -1.5148e-04, -1.1398e-03,  2.9605e-05, -1.0740e-03,\n",
      "         7.9170e-04,  1.9786e-03,  2.1334e-03,  8.2400e-04,  4.6209e-04,\n",
      "        -5.2322e-04,  6.8797e-04, -1.6681e-03,  2.0556e-03,  3.7710e-05,\n",
      "        -1.1929e-03, -1.7020e-04,  6.2046e-05,  6.3839e-04, -1.2543e-03,\n",
      "         6.4320e-04, -5.5440e-06,  1.3805e-03, -4.7417e-04,  1.8554e-03,\n",
      "         1.5396e-03,  7.7414e-05, -3.9147e-04,  1.2199e-03,  4.3876e-04,\n",
      "         8.6217e-04, -1.1546e-04, -1.5240e-04,  1.3181e-04, -6.7881e-04,\n",
      "         2.8006e-04,  4.5764e-04,  1.4053e-03,  1.5959e-03,  4.8897e-04,\n",
      "         1.9424e-04, -6.2299e-04, -9.0922e-05,  1.0425e-03, -4.6135e-04,\n",
      "         3.1875e-04,  1.2577e-03,  1.2390e-04, -9.6872e-04, -3.6701e-04,\n",
      "        -1.3142e-03, -1.7296e-03, -6.7700e-04,  4.5296e-04,  1.1208e-03,\n",
      "        -8.9058e-04,  1.3638e-04, -3.4839e-04,  6.9795e-04, -1.6628e-04,\n",
      "        -7.3541e-04,  7.2561e-04, -1.5983e-03,  7.6059e-04, -1.2713e-04,\n",
      "         1.2698e-03,  4.5097e-04,  1.0354e-03,  8.4364e-05, -1.0723e-03,\n",
      "         1.2302e-04,  4.3641e-04, -8.8386e-04, -1.1386e-03,  2.7594e-04,\n",
      "         1.1986e-03, -1.9061e-03, -1.2414e-03,  8.6492e-04, -1.7395e-04,\n",
      "        -9.5503e-04,  1.9422e-03, -9.1252e-04,  5.4096e-04, -1.5382e-03,\n",
      "        -1.2822e-03])\n",
      "\n",
      "bert.encoder.layer.0.intermediate.dense.weight:\n",
      "\n",
      "tensor([[ 0.0090,  0.0180,  0.0122,  ..., -0.0608,  0.0092, -0.0222],\n",
      "        [-0.0250, -0.0143, -0.0141,  ...,  0.0176,  0.0013,  0.0178],\n",
      "        [-0.0167,  0.0236,  0.0018,  ..., -0.0079, -0.0090,  0.0172],\n",
      "        ...,\n",
      "        [ 0.0124, -0.0253,  0.0007,  ...,  0.0185, -0.0110,  0.0051],\n",
      "        [-0.0089,  0.0082,  0.0234,  ...,  0.0094, -0.0139, -0.0089],\n",
      "        [ 0.0239,  0.0192, -0.0225,  ..., -0.0053,  0.0049,  0.0134]])\n",
      "\n",
      "bert.encoder.layer.0.intermediate.dense.bias:\n",
      "\n",
      "tensor([ 0.0016, -0.0007,  0.0016,  ...,  0.0023,  0.0017,  0.0008])\n",
      "\n",
      "bert.encoder.layer.0.output.dense.weight:\n",
      "\n",
      "tensor([[-0.0191,  0.0079, -0.0021,  ...,  0.0009,  0.0106, -0.0010],\n",
      "        [-0.0193,  0.0285,  0.0092,  ...,  0.0190,  0.0119,  0.0035],\n",
      "        [-0.0647, -0.0270, -0.0005,  ...,  0.0073,  0.0097, -0.0255],\n",
      "        ...,\n",
      "        [ 0.0088, -0.0004, -0.0213,  ...,  0.0290, -0.0217, -0.0170],\n",
      "        [ 0.0255, -0.0447, -0.0370,  ..., -0.0141,  0.0043,  0.0058],\n",
      "        [-0.0353,  0.0025, -0.0089,  ..., -0.0051, -0.0044,  0.0067]])\n",
      "\n",
      "bert.encoder.layer.0.output.dense.bias:\n",
      "\n",
      "tensor([ 2.1709e-04, -8.6349e-04, -3.1722e-04,  8.9106e-04,  3.2343e-04,\n",
      "         5.8725e-04, -8.8797e-04,  1.2911e-03,  9.9316e-04, -8.4213e-04,\n",
      "        -4.2516e-05,  2.8942e-04,  1.4109e-03,  4.4911e-04, -1.0269e-03,\n",
      "        -1.3317e-03, -2.1290e-03,  1.6748e-03, -1.1086e-03,  7.3827e-04,\n",
      "        -2.3242e-04, -4.5125e-04,  2.7411e-05,  2.3642e-03,  6.2531e-04,\n",
      "        -2.9886e-04,  8.8611e-05, -1.1639e-03,  9.7025e-04,  7.6772e-04,\n",
      "         3.3438e-05, -4.9429e-05,  6.3978e-04, -8.3029e-04, -1.0698e-03,\n",
      "         1.1724e-03, -1.6837e-03,  3.6995e-04, -1.9671e-03,  5.1199e-04,\n",
      "        -8.1865e-04,  9.1889e-04,  1.8517e-03, -1.6441e-03, -6.1520e-05,\n",
      "         7.8910e-04,  1.4880e-03, -1.5853e-03,  3.6282e-04,  1.1056e-03,\n",
      "        -1.0372e-03,  7.3115e-04, -5.2519e-04, -2.2199e-04, -3.8314e-05,\n",
      "        -2.2020e-03,  8.3237e-04, -1.3277e-03,  8.6418e-05, -3.2321e-04,\n",
      "        -1.0792e-03, -1.5023e-03, -2.4292e-03, -1.6163e-03,  6.3306e-04,\n",
      "         1.5002e-05,  1.8575e-03,  1.5159e-03,  4.9075e-04, -1.5444e-03,\n",
      "        -1.1510e-03, -8.6993e-04, -6.6463e-04,  1.0625e-03, -1.7725e-04,\n",
      "        -2.9244e-04,  6.7875e-04, -2.8028e-04,  2.0390e-03,  1.1640e-03,\n",
      "         1.6108e-03,  4.8485e-04,  1.2429e-03, -1.0687e-04,  1.8862e-03,\n",
      "         2.0256e-03, -4.6906e-04, -1.3160e-03, -7.2158e-04, -4.7473e-04,\n",
      "        -6.1998e-04,  8.9321e-04, -8.6207e-04,  6.9022e-04,  9.8593e-05,\n",
      "        -1.1856e-03,  6.4654e-04, -5.9918e-04, -9.4903e-04, -1.1883e-03,\n",
      "        -2.3273e-03, -2.6980e-03, -8.1799e-04, -1.0898e-03,  1.0378e-03,\n",
      "         1.7247e-04, -2.3264e-05, -1.7224e-03,  1.0906e-04,  6.2906e-04,\n",
      "         7.9869e-04,  1.1321e-03,  9.1336e-04,  1.0473e-03,  8.8081e-04,\n",
      "        -9.7739e-04, -9.2079e-04, -2.1323e-04, -1.3545e-03, -4.1953e-04,\n",
      "         1.7434e-04, -6.0353e-04, -5.0123e-04,  7.1452e-04,  3.8176e-04,\n",
      "         1.2926e-03, -1.6185e-03, -1.3861e-03,  1.2563e-03,  1.1292e-04,\n",
      "         6.6016e-04, -3.0054e-04,  3.6090e-04, -1.6848e-03, -7.2265e-05,\n",
      "        -2.1723e-03,  1.5826e-03, -8.1339e-04,  4.6625e-04, -6.2075e-04,\n",
      "         9.8780e-04, -1.1605e-03,  1.1461e-03, -1.3400e-03, -2.4993e-04,\n",
      "         5.7517e-04,  2.5550e-03, -3.6384e-04, -8.8415e-04,  1.4561e-03,\n",
      "        -2.5666e-04,  1.0768e-03, -1.5874e-03,  1.1063e-03,  7.9279e-04,\n",
      "         1.7093e-04, -1.0179e-03, -5.0667e-04, -6.6179e-05, -2.8872e-04,\n",
      "         8.6189e-04,  1.1541e-03,  9.3077e-04,  1.3426e-04, -1.6424e-03,\n",
      "        -4.7044e-04,  6.0185e-04,  4.0762e-04, -9.4286e-04, -1.2947e-05,\n",
      "         9.8151e-04, -3.1383e-04, -2.1964e-03,  3.1842e-04, -9.5103e-04,\n",
      "         9.6021e-04,  2.0178e-03,  2.4473e-03,  3.8070e-04,  7.0554e-04,\n",
      "        -9.8626e-04,  5.8252e-04, -1.1257e-03,  1.6192e-03, -2.6260e-05,\n",
      "        -1.5305e-03, -7.2347e-04,  2.2794e-05,  5.6089e-04, -7.9103e-04,\n",
      "        -1.4403e-03, -9.7746e-04,  1.2418e-03, -7.1874e-04,  1.9140e-03,\n",
      "         1.7486e-03, -5.5912e-04, -7.1507e-04,  9.4830e-04,  3.9707e-04,\n",
      "         1.9705e-04, -5.0222e-04, -2.7639e-04, -4.4581e-04, -1.0612e-03,\n",
      "        -1.9166e-04,  8.3593e-04,  1.3156e-03,  2.1422e-03,  1.9934e-04,\n",
      "         5.1692e-05, -5.7175e-04, -3.4792e-05,  8.5922e-04,  3.4771e-05,\n",
      "         1.6063e-03,  8.8186e-04, -4.2928e-05, -1.0837e-03,  2.1151e-04,\n",
      "        -4.5360e-04, -1.6640e-03,  4.2017e-04,  2.0179e-04,  9.0606e-04,\n",
      "        -1.4642e-03, -6.4311e-04, -3.3883e-04,  1.1654e-03, -9.3487e-04,\n",
      "        -1.4567e-03,  6.4759e-05, -1.5103e-03, -2.1681e-04, -8.6481e-04,\n",
      "         1.6530e-03,  3.0997e-04,  7.7940e-04,  3.5861e-04, -1.1177e-03,\n",
      "         6.0638e-04, -7.9442e-05, -6.6342e-04, -3.9467e-04,  2.1173e-04,\n",
      "         3.4994e-04, -1.5218e-03, -1.4868e-03,  6.6215e-06,  7.4430e-05,\n",
      "        -1.5057e-03,  1.6594e-03, -6.2803e-04,  6.1297e-04, -1.1860e-03,\n",
      "        -1.4364e-03])\n",
      "\n",
      "bert.encoder.layer.0.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9999, 1.0002, 1.0006, 0.9996, 1.0012, 1.0001, 0.9984, 1.0005, 0.9975,\n",
      "        0.9990, 0.9997, 0.9999, 0.9999, 0.9989, 1.0011, 1.0012, 1.0000, 1.0006,\n",
      "        1.0029, 0.9996, 1.0006, 1.0024, 0.9998, 1.0009, 1.0001, 1.0019, 1.0027,\n",
      "        1.0020, 1.0028, 0.9985, 0.9998, 1.0000, 1.0016, 1.0004, 1.0004, 1.0001,\n",
      "        0.9988, 0.9985, 1.0008, 0.9993, 1.0008, 1.0006, 1.0022, 1.0006, 0.9973,\n",
      "        0.9978, 1.0025, 0.9995, 0.9976, 1.0000, 1.0002, 1.0003, 0.9997, 0.9996,\n",
      "        0.9987, 1.0007, 1.0015, 1.0004, 1.0008, 0.9985, 0.9997, 0.9982, 1.0004,\n",
      "        1.0000, 1.0014, 1.0002, 1.0011, 0.9976, 1.0019, 1.0014, 1.0007, 1.0000,\n",
      "        0.9987, 1.0006, 1.0023, 1.0017, 0.9994, 0.9997, 1.0020, 0.9989, 0.9990,\n",
      "        1.0016, 0.9998, 0.9999, 0.9998, 1.0014, 1.0017, 1.0002, 0.9984, 1.0006,\n",
      "        0.9986, 0.9994, 0.9969, 1.0008, 0.9990, 1.0018, 1.0001, 1.0011, 0.9993,\n",
      "        1.0011, 1.0010, 1.0017, 0.9976, 0.9975, 1.0015, 1.0015, 0.9985, 1.0001,\n",
      "        0.9994, 0.9992, 1.0003, 0.9984, 1.0014, 0.9999, 1.0001, 0.9997, 1.0003,\n",
      "        1.0014, 1.0016, 0.9970, 1.0011, 1.0001, 1.0005, 1.0009, 0.9995, 0.9978,\n",
      "        1.0019, 0.9984, 0.9983, 1.0007, 1.0004, 1.0016, 0.9996, 1.0016, 0.9972,\n",
      "        0.9991, 0.9993, 0.9990, 1.0002, 0.9971, 1.0007, 1.0017, 0.9964, 0.9985,\n",
      "        0.9977, 0.9972, 1.0019, 1.0008, 1.0012, 0.9990, 1.0008, 1.0014, 0.9995,\n",
      "        0.9983, 1.0016, 1.0019, 0.9997, 0.9994, 1.0003, 1.0004, 1.0009, 0.9962,\n",
      "        1.0023, 1.0013, 1.0007, 1.0002, 0.9985, 1.0009, 1.0006, 0.9997, 1.0013,\n",
      "        0.9983, 1.0000, 1.0015, 1.0008, 0.9993, 1.0008, 1.0009, 0.9987, 0.9994,\n",
      "        1.0007, 1.0005, 0.9988, 1.0022, 0.9990, 1.0001, 1.0006, 0.9994, 1.0007,\n",
      "        1.0019, 0.9997, 1.0004, 0.9986, 1.0020, 0.9987, 1.0025, 0.9986, 1.0021,\n",
      "        1.0008, 1.0012, 0.9961, 0.9998, 0.9968, 0.9977, 0.9994, 1.0000, 1.0008,\n",
      "        1.0002, 0.9980, 0.9988, 0.9996, 1.0010, 0.9980, 1.0008, 0.9990, 1.0003,\n",
      "        0.9978, 0.9988, 0.9983, 0.9986, 1.0002, 1.0007, 0.9988, 0.9991, 0.9983,\n",
      "        0.9981, 1.0003, 1.0008, 0.9988, 1.0013, 1.0004, 0.9996, 1.0002, 1.0017,\n",
      "        1.0024, 0.9997, 0.9990, 0.9999, 0.9998, 0.9993, 1.0017, 0.9990, 0.9975,\n",
      "        0.9990, 0.9996, 0.9995, 1.0002, 0.9963, 1.0003, 0.9994, 1.0015, 0.9975,\n",
      "        0.9997, 0.9996, 1.0011, 1.0012])\n",
      "\n",
      "bert.encoder.layer.0.output.LayerNorm.bias:\n",
      "\n",
      "tensor([-4.9815e-05, -1.0785e-03,  6.7845e-05,  2.5449e-04,  4.8122e-04,\n",
      "         1.1511e-03, -4.2048e-04,  1.1466e-03,  8.0247e-04, -8.3631e-04,\n",
      "        -6.1235e-04,  3.6441e-04,  3.8274e-04,  4.2455e-04, -3.6960e-04,\n",
      "        -1.3051e-03, -2.0740e-03,  1.0291e-03, -8.5659e-04,  6.9074e-04,\n",
      "        -5.9950e-04, -7.2071e-04, -8.7897e-04,  2.2331e-03,  5.3332e-04,\n",
      "        -4.4675e-04,  1.6722e-03, -3.8709e-06,  1.3805e-03,  6.0599e-04,\n",
      "         9.0324e-05,  4.3139e-04,  8.7902e-04, -4.9308e-04, -3.8443e-04,\n",
      "         8.6211e-04, -9.0290e-04,  8.8737e-05, -1.8733e-03,  1.3552e-04,\n",
      "        -1.2242e-03,  1.9673e-03,  1.7095e-03, -1.3222e-03,  1.8752e-04,\n",
      "         4.6411e-04,  1.6693e-03, -4.1760e-04,  5.6759e-04,  1.0508e-03,\n",
      "        -9.0018e-04,  9.1914e-04, -3.9907e-04, -3.7713e-04,  1.0134e-04,\n",
      "        -1.6266e-03,  7.3287e-04, -1.1139e-03,  2.2683e-05,  1.4341e-04,\n",
      "        -4.1093e-04, -6.1260e-04, -1.9776e-03, -1.7814e-03,  8.5037e-04,\n",
      "         3.6785e-04,  1.2500e-03,  1.4204e-03,  1.3885e-03, -1.4559e-03,\n",
      "        -3.9119e-04, -1.2865e-03, -5.5719e-04, -4.0915e-04, -2.9895e-04,\n",
      "        -6.1521e-04,  1.1715e-03, -1.1584e-03,  1.3037e-03,  9.8954e-05,\n",
      "         1.2699e-03,  1.1710e-03,  8.9861e-04, -6.6383e-04,  1.7721e-03,\n",
      "         1.8931e-03, -1.5115e-03, -1.0596e-03, -6.1217e-04, -3.9944e-04,\n",
      "         1.3899e-04,  1.0105e-03, -1.0197e-03,  1.4432e-04,  4.8673e-04,\n",
      "        -1.7541e-03,  8.8592e-04, -2.8955e-04, -7.2579e-04, -3.1613e-04,\n",
      "        -1.5562e-03, -1.4104e-03, -7.2511e-04, -1.0928e-03,  1.2105e-03,\n",
      "         2.7964e-05,  1.7314e-04, -1.7190e-03, -3.5200e-04,  6.8466e-04,\n",
      "         5.0723e-04,  6.6844e-04,  7.5514e-04,  8.2184e-04,  9.2956e-05,\n",
      "        -3.4138e-04, -1.3272e-03,  4.1813e-04, -1.3592e-03, -3.9538e-04,\n",
      "         3.9232e-05, -5.4450e-04, -6.5883e-04,  9.9268e-04,  4.4766e-04,\n",
      "        -4.1217e-04, -1.5716e-03, -1.4413e-03,  1.1943e-03, -2.6956e-04,\n",
      "         4.2194e-04,  4.8679e-05,  3.0436e-05, -2.1350e-03,  7.0036e-04,\n",
      "        -5.7836e-04,  9.7092e-04, -8.0323e-04,  1.0623e-04, -2.4280e-04,\n",
      "         1.3720e-03, -3.2945e-04,  1.1123e-03, -9.1204e-04, -1.3868e-04,\n",
      "        -1.1373e-04,  2.6879e-03, -7.1102e-04, -6.7398e-04,  1.4461e-03,\n",
      "        -3.9524e-04,  8.7274e-04, -1.1921e-03,  1.8042e-03,  1.5333e-03,\n",
      "        -4.0944e-04, -1.8900e-04, -6.2306e-04, -3.5794e-04, -8.3018e-04,\n",
      "         1.1094e-03,  5.4317e-04,  7.9312e-04,  6.8059e-04, -1.4375e-03,\n",
      "        -8.4848e-04,  1.0194e-03, -1.5494e-04, -1.4443e-03, -5.6787e-04,\n",
      "         1.1025e-03, -2.7315e-04, -1.0108e-03, -1.1342e-04, -1.1465e-03,\n",
      "         7.7106e-04,  1.9228e-03,  2.0394e-03,  5.6726e-04,  5.2812e-04,\n",
      "        -9.9114e-04,  5.6635e-04, -1.6670e-03,  1.9583e-03,  1.5852e-04,\n",
      "        -1.2943e-03, -3.7467e-04, -7.6033e-05,  3.8822e-04, -1.0070e-03,\n",
      "         8.9984e-04, -4.9673e-05,  1.2982e-03, -3.7052e-04,  1.8900e-03,\n",
      "         1.6789e-03,  1.1058e-04, -3.0599e-04,  9.8184e-04,  3.9821e-04,\n",
      "         6.3979e-04, -1.6732e-04, -2.4686e-04,  1.5511e-04, -9.6077e-04,\n",
      "         3.3309e-05,  5.7594e-04,  1.3387e-03,  1.3828e-03,  2.0795e-04,\n",
      "         1.2172e-04, -5.7959e-04, -2.2025e-04,  8.0080e-04, -5.4092e-04,\n",
      "         1.6339e-04,  1.2113e-03, -1.0822e-04, -9.7417e-04, -4.9234e-04,\n",
      "        -9.6187e-04, -1.4778e-03, -6.4891e-04,  2.9534e-04,  1.1642e-03,\n",
      "        -8.6993e-04,  2.8370e-04, -7.5013e-04,  9.6832e-04,  4.0700e-04,\n",
      "        -8.1821e-04,  5.7491e-04, -1.5321e-03,  6.3333e-04, -2.8279e-04,\n",
      "         1.3662e-03,  4.8166e-04,  1.1021e-03,  5.7462e-05, -1.1503e-03,\n",
      "         2.6837e-04,  3.4809e-04, -7.4826e-04, -9.3173e-04,  2.5109e-04,\n",
      "         9.0421e-04, -1.8212e-03, -1.2752e-03,  1.1967e-03, -2.0972e-04,\n",
      "        -1.1060e-03,  1.9614e-03, -8.1934e-04,  2.7237e-04, -1.5198e-03,\n",
      "        -1.1084e-03])\n",
      "\n",
      "bert.encoder.layer.1.attention.self.query.weight:\n",
      "\n",
      "tensor([[ 0.0150,  0.0191, -0.0191,  ...,  0.0400,  0.0256,  0.0175],\n",
      "        [ 0.0090,  0.0057, -0.0086,  ..., -0.0522,  0.0205, -0.0201],\n",
      "        [ 0.0016,  0.0150,  0.0036,  ...,  0.0272,  0.0620,  0.0318],\n",
      "        ...,\n",
      "        [ 0.0089,  0.0155, -0.0242,  ..., -0.0059,  0.0205,  0.0322],\n",
      "        [ 0.0359, -0.0073,  0.0203,  ...,  0.0244, -0.0191,  0.0010],\n",
      "        [ 0.0244, -0.0223, -0.0361,  ...,  0.0453,  0.0076, -0.0100]])\n",
      "\n",
      "bert.encoder.layer.1.attention.self.query.bias:\n",
      "\n",
      "tensor([-8.3599e-04, -5.1369e-04, -9.4387e-04,  2.1450e-04, -1.3184e-03,\n",
      "        -1.9109e-03,  1.8997e-03, -1.1392e-03,  1.2362e-03,  5.3561e-04,\n",
      "         1.0097e-03, -1.6771e-04,  5.9432e-04,  1.1997e-03,  5.0782e-04,\n",
      "         2.1387e-03,  1.7731e-03, -1.4176e-03,  1.8913e-03, -1.0081e-03,\n",
      "        -2.2154e-03, -2.1099e-04, -1.9917e-03,  1.5536e-03,  1.4820e-03,\n",
      "        -1.4158e-03, -3.0958e-03, -2.3330e-04,  1.0382e-03,  2.8719e-04,\n",
      "        -4.7801e-04,  1.1036e-03,  1.6657e-03, -6.7338e-04,  9.5917e-04,\n",
      "         4.3401e-04, -1.3778e-03, -6.9631e-04, -8.7928e-04,  3.9721e-04,\n",
      "         9.2157e-04, -4.9021e-04, -2.0548e-03,  2.3926e-03,  1.8131e-03,\n",
      "         1.7018e-03,  1.3889e-03,  2.0406e-03, -2.1947e-03, -1.5071e-03,\n",
      "        -6.7742e-04, -5.0564e-05, -1.3947e-03, -2.2391e-03, -2.6308e-03,\n",
      "        -1.2126e-03, -9.0431e-04,  1.8221e-03,  1.4723e-04,  1.2982e-03,\n",
      "        -1.7872e-04, -2.8628e-04,  1.7670e-03, -1.1058e-03,  1.5891e-03,\n",
      "         1.4468e-03,  5.6004e-04, -1.9342e-03, -9.9390e-04,  2.6851e-04,\n",
      "         2.4715e-03, -1.9935e-03, -2.2824e-03, -2.5477e-03, -1.0431e-03,\n",
      "         2.0738e-04,  2.1218e-03, -1.8317e-03, -1.1993e-03,  1.5274e-03,\n",
      "        -1.5969e-03, -5.5060e-04,  1.0829e-03,  2.3145e-03,  3.4462e-04,\n",
      "        -2.3794e-03,  6.8523e-04, -9.1027e-04, -4.7035e-04, -1.1107e-03,\n",
      "        -9.9986e-04,  1.8234e-03, -2.7519e-04, -1.5896e-03,  1.3381e-03,\n",
      "        -1.5019e-03, -1.5708e-03, -1.2364e-03, -2.5279e-03, -3.3183e-03,\n",
      "        -1.4400e-03,  2.9832e-03, -1.2040e-03,  3.9649e-04,  1.2189e-03,\n",
      "        -9.8512e-04,  1.0062e-03,  2.8959e-03, -2.4465e-03,  1.4195e-03,\n",
      "         1.8424e-04, -1.4827e-03, -1.4347e-03,  3.5636e-03,  3.3322e-04,\n",
      "         1.2233e-03, -2.3648e-03, -2.4799e-03,  1.0728e-03, -2.8672e-03,\n",
      "         1.8305e-03, -1.1097e-03, -1.0969e-03, -1.8013e-03,  1.8160e-03,\n",
      "        -1.2438e-03,  1.9880e-03,  1.6615e-03, -4.0194e-04,  1.0444e-03,\n",
      "         2.1565e-04,  6.7553e-04, -1.6898e-03, -1.0038e-03, -6.8190e-04,\n",
      "         1.2972e-03,  1.4149e-03, -2.3972e-03, -3.2457e-03,  8.3893e-04,\n",
      "         2.3017e-03, -2.2528e-03,  5.5841e-05,  1.6994e-03,  2.1339e-04,\n",
      "         5.2423e-04, -1.8847e-03, -1.0274e-03, -6.2222e-04, -9.2625e-04,\n",
      "        -4.6020e-04, -6.0026e-04, -3.5959e-03,  1.2385e-03, -4.2910e-04,\n",
      "        -1.5694e-03,  1.1272e-03, -8.8943e-04, -1.1063e-04,  1.9094e-03,\n",
      "        -1.6337e-03,  4.2537e-04,  1.7070e-03,  3.0121e-04,  7.9623e-04,\n",
      "        -1.5441e-03,  2.8404e-04, -3.8771e-04, -1.6474e-04, -8.5498e-04,\n",
      "        -2.2060e-03, -2.2453e-03, -9.6099e-04, -3.0401e-03, -6.7821e-05,\n",
      "         1.2237e-04,  5.0430e-04,  7.4922e-04, -3.1919e-05,  2.1167e-03,\n",
      "        -8.6168e-05, -1.0422e-03, -1.2163e-03, -2.3780e-03,  9.2423e-04,\n",
      "         8.2373e-04, -1.6205e-03,  1.9159e-03,  1.3395e-03, -3.5956e-04,\n",
      "        -1.1365e-03,  2.0684e-03,  2.9334e-04, -1.7737e-03,  3.1575e-07,\n",
      "        -1.4871e-05,  8.8058e-05,  1.9556e-03,  1.2266e-03,  1.7712e-03,\n",
      "        -2.0760e-03,  2.4626e-04, -2.0847e-03,  5.6972e-05,  8.0530e-04,\n",
      "        -2.8058e-03,  1.0388e-04, -3.4634e-04, -7.1931e-04, -1.9860e-03,\n",
      "        -5.3596e-04, -6.2961e-04,  2.8451e-03,  1.2012e-03,  2.4897e-03,\n",
      "        -8.4620e-04,  1.4538e-03,  4.0594e-04, -3.4091e-04, -3.6048e-04,\n",
      "         4.0745e-04,  3.6325e-05,  1.5990e-03, -7.2787e-04, -7.3882e-04,\n",
      "         1.2116e-03,  3.7414e-04,  1.1841e-03,  1.4902e-03,  2.6384e-04,\n",
      "        -1.8918e-03, -4.5416e-03, -1.2362e-04, -1.7179e-03,  1.9735e-04,\n",
      "         2.5776e-03,  1.1773e-03, -4.2711e-04, -1.4436e-04,  3.7587e-04,\n",
      "        -1.2083e-03, -2.0282e-03, -1.4012e-03, -3.3300e-04,  1.1326e-03,\n",
      "         2.6368e-04,  2.0733e-03, -9.6188e-04,  2.9883e-03,  1.4884e-03,\n",
      "         1.4250e-03, -7.9000e-04,  2.0810e-03,  8.6211e-04,  1.2446e-03,\n",
      "         3.0186e-03])\n",
      "\n",
      "bert.encoder.layer.1.attention.self.key.weight:\n",
      "\n",
      "tensor([[-4.1159e-02, -1.2084e-02,  1.3935e-02,  ..., -3.4522e-03,\n",
      "          1.5756e-02,  6.7102e-03],\n",
      "        [-1.1242e-02, -1.8113e-02,  2.9032e-03,  ...,  9.2906e-03,\n",
      "          3.0785e-02,  1.7992e-02],\n",
      "        [-2.8591e-03, -4.2730e-02,  2.4191e-02,  ..., -1.1793e-02,\n",
      "         -3.2220e-03, -2.3125e-02],\n",
      "        ...,\n",
      "        [-2.1117e-02,  4.7066e-03,  8.3747e-04,  ..., -2.3585e-02,\n",
      "          2.4335e-02, -5.5307e-02],\n",
      "        [ 1.0438e-02, -1.8556e-02, -3.0990e-03,  ...,  1.6969e-03,\n",
      "         -2.1557e-02, -1.3510e-02],\n",
      "        [ 2.3475e-02,  2.4383e-02, -4.9895e-05,  ..., -3.4072e-03,\n",
      "          2.7244e-02,  3.2956e-03]])\n",
      "\n",
      "bert.encoder.layer.1.attention.self.key.bias:\n",
      "\n",
      "tensor([-1.6803e-09,  5.3621e-09, -5.6727e-09, -2.7217e-10, -1.4817e-09,\n",
      "        -5.2341e-09, -3.6250e-09, -1.5009e-09, -4.2107e-09, -4.5602e-09,\n",
      "        -1.2614e-09, -1.2468e-09,  1.1077e-09,  1.3760e-09, -8.7561e-10,\n",
      "        -1.5670e-09, -3.6418e-09, -3.9282e-09, -1.0010e-09, -1.9010e-09,\n",
      "        -5.7433e-09, -1.4924e-10, -5.0169e-09,  6.4936e-09,  6.4940e-09,\n",
      "         5.4574e-09, -5.4795e-09, -1.1780e-10,  4.2999e-09,  7.9397e-10,\n",
      "        -3.5576e-09,  3.7159e-09,  1.3726e-09,  9.7475e-11, -4.6362e-10,\n",
      "         5.9537e-09,  2.1867e-09,  1.3403e-09,  5.9511e-09, -1.0068e-08,\n",
      "         1.0442e-09, -2.6358e-10,  4.3703e-09, -3.4839e-09, -1.6334e-09,\n",
      "         4.0453e-09, -3.8312e-09,  1.5412e-09, -6.0106e-09,  4.6258e-09,\n",
      "        -6.2424e-09,  2.9185e-09, -7.5580e-10,  6.4785e-09, -2.5520e-09,\n",
      "        -2.7342e-09,  3.7590e-09, -1.5034e-09, -2.3010e-09,  1.6516e-10,\n",
      "         1.3289e-08,  1.0648e-09,  1.4044e-09, -8.4230e-09,  1.7853e-09,\n",
      "        -5.7244e-09, -7.2048e-09,  4.3931e-09,  1.7610e-09,  4.3800e-09,\n",
      "        -6.7885e-09,  1.2318e-08, -4.0264e-09,  1.1127e-08, -3.0690e-09,\n",
      "         4.3496e-09, -1.1820e-08, -1.3748e-08,  1.4763e-09, -4.4715e-09,\n",
      "        -4.0023e-09,  9.2988e-09, -1.0740e-08, -4.2516e-09, -2.6124e-09,\n",
      "         8.9145e-09,  3.8560e-09,  8.7362e-09, -1.4800e-09, -4.4962e-10,\n",
      "        -1.0930e-08, -2.7852e-10,  5.6260e-09,  7.7389e-09, -8.9718e-09,\n",
      "         2.2146e-09,  9.6998e-09,  7.6313e-10,  8.5928e-09,  1.6051e-09,\n",
      "         9.1881e-09,  6.7665e-09, -3.1006e-10,  2.6361e-09, -2.6393e-10,\n",
      "        -1.0048e-08, -2.2089e-09, -4.4322e-09,  8.0506e-09,  1.3620e-09,\n",
      "        -1.3245e-08, -1.0526e-09,  1.0181e-08, -1.1837e-09, -6.8340e-09,\n",
      "        -4.9628e-09, -3.6111e-09,  4.3612e-09,  6.1261e-09,  3.6402e-09,\n",
      "        -7.4332e-10,  3.5411e-09,  1.0093e-08,  6.3322e-09,  7.7599e-09,\n",
      "         7.8575e-09,  3.8579e-09,  2.7297e-09, -5.6757e-09,  2.1364e-09,\n",
      "        -6.1689e-09, -3.5684e-10, -2.8625e-09, -4.9369e-09,  7.3165e-09,\n",
      "         1.0721e-08,  5.6609e-09, -6.4699e-09, -1.5527e-08,  1.5133e-08,\n",
      "        -7.1349e-09,  7.9631e-10,  5.3462e-09, -2.6034e-09, -4.3020e-09,\n",
      "         9.3713e-09, -5.0692e-09,  2.2756e-09, -9.9040e-09, -9.5530e-09,\n",
      "         8.3845e-09, -1.3248e-09, -8.6775e-09,  1.0755e-11,  3.9268e-09,\n",
      "         1.5339e-08, -2.2221e-09, -2.7921e-09, -6.0643e-09,  5.8380e-09,\n",
      "        -1.6950e-08,  1.5497e-08,  1.0476e-08, -1.3459e-09,  1.5707e-08,\n",
      "        -1.7362e-08,  1.4799e-08,  1.8550e-09,  1.8256e-08,  4.8086e-09,\n",
      "        -8.1748e-09, -1.6872e-08, -4.4100e-09, -1.3678e-08, -8.4908e-09,\n",
      "         4.9662e-09,  1.8321e-08,  1.3127e-08,  6.6298e-10,  1.0356e-08,\n",
      "        -4.0944e-10, -4.5750e-09,  8.1129e-09,  1.8925e-11,  7.9267e-09,\n",
      "         7.6819e-09,  3.9674e-09,  3.7103e-09,  1.1993e-08, -1.6953e-08,\n",
      "        -8.1320e-09,  9.6496e-09, -5.1133e-09,  1.3544e-09,  9.5833e-10,\n",
      "         2.5675e-09, -3.9619e-09, -7.5339e-09,  2.4181e-10, -2.1634e-09,\n",
      "         2.4010e-09,  1.4790e-09,  3.4663e-09,  1.4324e-09,  4.4932e-10,\n",
      "         3.5708e-09, -3.0086e-09, -3.5662e-09,  6.1765e-09,  3.9486e-09,\n",
      "         5.6604e-09, -4.9086e-09, -3.3458e-09, -5.9122e-09, -8.8440e-09,\n",
      "        -1.6149e-09, -3.6117e-09,  3.6774e-10,  4.1026e-09, -2.4949e-09,\n",
      "         3.2887e-09, -4.5889e-10, -7.8218e-09,  1.1613e-08,  1.3037e-09,\n",
      "        -9.1052e-09,  5.2289e-09,  8.9644e-09, -1.7720e-09,  3.5028e-09,\n",
      "         1.7052e-08,  1.0546e-08,  8.8807e-09,  5.7264e-09,  3.5879e-09,\n",
      "        -8.4683e-09,  1.6912e-10,  2.2032e-09,  7.7094e-09,  4.7450e-09,\n",
      "        -3.1857e-10, -1.0697e-09,  2.3421e-09,  6.3989e-09, -7.7754e-09,\n",
      "        -9.3007e-09,  3.4874e-09, -2.0343e-09, -1.1014e-08, -3.6174e-09,\n",
      "        -1.2116e-09,  5.8284e-09, -3.2018e-11, -3.5261e-09, -2.5613e-10,\n",
      "        -7.3956e-09])\n",
      "\n",
      "bert.encoder.layer.1.attention.self.value.weight:\n",
      "\n",
      "tensor([[ 0.0232, -0.0058, -0.0152,  ..., -0.0038,  0.0266, -0.0057],\n",
      "        [ 0.0080, -0.0235,  0.0012,  ...,  0.0150,  0.0112, -0.0056],\n",
      "        [-0.0024, -0.0295, -0.0079,  ..., -0.0020, -0.0260, -0.0053],\n",
      "        ...,\n",
      "        [-0.0160, -0.0089, -0.0108,  ...,  0.0292, -0.0076,  0.0247],\n",
      "        [ 0.0044, -0.0203, -0.0107,  ..., -0.0009, -0.0017,  0.0313],\n",
      "        [-0.0043,  0.0085, -0.0154,  ..., -0.0117, -0.0106, -0.0346]])\n",
      "\n",
      "bert.encoder.layer.1.attention.self.value.bias:\n",
      "\n",
      "tensor([ 3.7868e-04, -2.2601e-03, -1.5263e-03,  1.2138e-03, -9.3319e-05,\n",
      "         1.4434e-03, -2.0332e-03,  9.2755e-05,  1.0561e-04, -3.6233e-04,\n",
      "         9.0136e-04, -1.0456e-03,  1.2121e-04,  8.1793e-04,  4.5699e-04,\n",
      "        -8.8862e-04,  1.1095e-03,  8.4139e-04,  2.1112e-04, -8.0741e-04,\n",
      "         5.0151e-04, -3.0926e-04,  3.2923e-04,  1.1626e-03, -5.8382e-04,\n",
      "         7.0595e-04,  1.0440e-03, -1.8338e-03,  1.4131e-04,  8.6118e-04,\n",
      "         1.7841e-04, -9.5885e-04,  1.6846e-03,  8.1397e-05,  7.3577e-04,\n",
      "        -1.3402e-04,  2.7409e-04, -6.1731e-04,  2.3453e-04, -5.2475e-04,\n",
      "        -1.1907e-03,  3.3861e-06,  4.6733e-04, -1.5317e-03, -8.8545e-04,\n",
      "        -4.7854e-04,  1.1542e-03,  4.7362e-04, -1.4340e-03,  2.1286e-03,\n",
      "         9.5897e-04, -1.5383e-03,  8.6992e-04, -5.0587e-05,  1.2088e-03,\n",
      "         8.4591e-05, -6.2558e-04, -1.1767e-03, -1.7516e-03,  9.6811e-05,\n",
      "         3.7228e-04,  1.6249e-03,  4.1633e-04,  8.1521e-04, -7.6996e-04,\n",
      "         9.7839e-04,  1.0444e-03,  7.0433e-04, -5.9034e-04,  4.1439e-04,\n",
      "         1.4155e-03, -5.8502e-04,  9.8183e-04,  1.5097e-03,  8.9284e-04,\n",
      "        -1.9719e-04, -1.2993e-03, -1.0071e-03, -1.1268e-04,  1.2103e-03,\n",
      "        -3.2223e-04, -4.6939e-04,  1.4748e-03, -9.8753e-04,  1.8177e-03,\n",
      "        -4.7846e-04, -3.8713e-04, -4.0553e-04, -8.6577e-04,  1.2462e-03,\n",
      "        -1.2466e-03, -3.2102e-04,  1.0489e-03, -8.7322e-04,  1.9650e-04,\n",
      "        -1.4870e-04, -4.2550e-04,  9.4521e-04, -4.4228e-04, -1.3502e-03,\n",
      "         8.3755e-04, -3.8618e-04, -1.8001e-04, -3.8991e-04, -1.4814e-03,\n",
      "        -7.8966e-04,  1.2076e-03, -7.7019e-06,  7.4660e-04,  6.2602e-04,\n",
      "        -3.0915e-04,  1.4561e-03,  6.5288e-04,  1.2553e-03,  9.2029e-04,\n",
      "         2.9852e-04,  5.5842e-04, -3.8377e-04, -2.0622e-03,  1.5443e-03,\n",
      "         8.4805e-04,  1.0211e-04, -2.0979e-03,  1.2789e-03,  1.3970e-03,\n",
      "         1.3820e-03,  1.0003e-03, -2.0500e-03,  9.7556e-04,  1.2497e-03,\n",
      "         3.4210e-04,  2.1485e-03, -2.3337e-03, -1.4173e-03,  8.4813e-04,\n",
      "        -1.1641e-03,  6.5246e-04,  1.5243e-04, -1.2360e-03, -1.0585e-05,\n",
      "        -1.7235e-03, -1.8463e-04, -1.2505e-03, -1.6991e-04,  2.2902e-03,\n",
      "        -1.8671e-03, -1.6946e-04,  4.5866e-04, -1.6386e-03,  1.5681e-03,\n",
      "        -8.4524e-04,  1.2848e-03, -9.2569e-04, -6.6345e-04,  1.1500e-04,\n",
      "         1.6961e-03,  9.6648e-04,  1.3917e-03, -1.3797e-03, -2.4971e-04,\n",
      "        -8.3183e-04,  4.3003e-04,  6.2926e-04,  6.9927e-05,  8.8142e-04,\n",
      "        -3.6063e-04,  1.9665e-03,  2.2964e-03,  8.3333e-04, -5.5593e-04,\n",
      "        -1.5104e-05, -1.0802e-03, -5.8807e-04,  8.0959e-04,  3.7383e-04,\n",
      "        -6.2282e-04, -1.9403e-03, -2.3392e-03, -1.0799e-03,  5.6053e-04,\n",
      "        -2.2695e-03,  5.5770e-04,  5.4223e-06, -6.2437e-04, -1.6496e-04,\n",
      "         9.0397e-04, -1.4274e-03,  2.2167e-03,  8.4376e-04,  4.5424e-04,\n",
      "         4.8048e-04,  5.4725e-04,  7.5369e-04, -1.3801e-03,  3.6428e-04,\n",
      "         1.7193e-03, -2.2514e-03, -1.2560e-04, -7.0247e-04,  1.6432e-03,\n",
      "         3.2057e-04, -4.9252e-04,  2.2333e-04,  1.7952e-04, -3.4066e-04,\n",
      "        -9.3227e-04, -4.8643e-04,  3.8580e-04,  2.1323e-03,  9.7193e-04,\n",
      "         2.5312e-04, -1.6161e-03, -7.0048e-04,  6.7297e-04, -1.1310e-03,\n",
      "         6.8490e-04,  5.2222e-05,  1.2669e-04,  1.5973e-03, -8.3385e-04,\n",
      "        -5.7260e-04, -3.9672e-04, -2.0097e-03,  1.6081e-03,  9.8293e-04,\n",
      "        -1.0017e-03,  7.7560e-04,  2.3090e-04, -1.1482e-04,  1.7908e-04,\n",
      "         1.3342e-03, -1.3043e-03, -5.6673e-04,  3.8763e-04, -8.8346e-04,\n",
      "        -1.0647e-03,  1.2317e-03,  1.3855e-03, -7.0502e-04,  1.5888e-03,\n",
      "        -2.5428e-03, -1.6805e-03,  1.1373e-03,  8.9960e-04,  1.2811e-03,\n",
      "         2.4097e-04,  1.7420e-03,  1.8018e-04,  7.4809e-04,  2.7011e-03,\n",
      "         1.8930e-03, -4.4014e-04,  2.7383e-04, -9.3274e-05,  9.0008e-04,\n",
      "        -4.4024e-04])\n",
      "\n",
      "bert.encoder.layer.1.attention.output.dense.weight:\n",
      "\n",
      "tensor([[-0.0198,  0.0126,  0.0205,  ..., -0.0161, -0.0161,  0.0253],\n",
      "        [ 0.0296,  0.0073, -0.0382,  ..., -0.0085,  0.0170, -0.0127],\n",
      "        [-0.0054, -0.0027,  0.0040,  ...,  0.0232, -0.0060,  0.0107],\n",
      "        ...,\n",
      "        [ 0.0455, -0.0288, -0.0018,  ...,  0.0368,  0.0142, -0.0155],\n",
      "        [ 0.0335,  0.0331, -0.0132,  ...,  0.0331,  0.0106,  0.0082],\n",
      "        [ 0.0189,  0.0170,  0.0025,  ...,  0.0237, -0.0108, -0.0056]])\n",
      "\n",
      "bert.encoder.layer.1.attention.output.dense.bias:\n",
      "\n",
      "tensor([ 3.5609e-04, -1.3662e-03, -1.9036e-04, -2.4128e-05,  8.6891e-04,\n",
      "         1.0023e-03, -6.3993e-04,  8.9544e-04,  1.1742e-03, -1.8726e-03,\n",
      "         3.6939e-05,  3.4416e-04, -1.2049e-03,  3.9758e-04,  9.6360e-05,\n",
      "        -8.2276e-04,  2.6138e-04,  7.5484e-04, -9.9474e-04,  2.9219e-04,\n",
      "        -2.9840e-04, -4.6398e-04, -1.0518e-03,  1.7657e-03,  3.9581e-04,\n",
      "        -8.6726e-05,  2.6799e-04, -6.3798e-04,  1.8125e-03,  1.5028e-03,\n",
      "         3.2812e-05,  1.0659e-03,  2.3362e-04, -5.6063e-04,  1.1090e-04,\n",
      "         1.4606e-03, -1.0615e-03,  2.1216e-03, -1.1238e-03, -1.6371e-03,\n",
      "        -1.8480e-03,  1.6279e-03,  8.8000e-04, -1.4761e-03, -1.0395e-04,\n",
      "        -6.0990e-05,  1.0229e-03, -6.6056e-04,  7.1540e-04,  1.1108e-03,\n",
      "        -7.4647e-05,  8.0895e-04, -2.2313e-04, -6.3610e-04, -3.3379e-04,\n",
      "        -1.4496e-03,  1.2172e-04, -7.5081e-04, -5.5111e-05, -1.7648e-04,\n",
      "        -2.3089e-05, -3.4833e-04, -2.0044e-03, -8.1740e-04,  3.1859e-04,\n",
      "         1.3296e-03,  1.5634e-03,  1.3143e-03,  1.0622e-03, -1.3732e-03,\n",
      "         2.4455e-06, -1.1162e-03, -1.6249e-04,  5.0543e-04, -5.5708e-04,\n",
      "        -7.0438e-04,  1.0827e-03, -8.7228e-04,  1.6646e-03, -3.7342e-04,\n",
      "         1.3228e-03,  9.6092e-04,  1.2763e-03, -8.9659e-04,  1.8825e-03,\n",
      "         2.0407e-03, -1.7981e-03, -9.3226e-04, -4.8598e-04, -1.3684e-03,\n",
      "         4.3119e-04,  1.0483e-03, -5.7511e-04,  2.6234e-04,  6.7536e-04,\n",
      "        -2.3852e-03, -5.2707e-05,  1.2592e-04, -1.1754e-03, -1.8937e-03,\n",
      "        -2.0467e-03, -5.3100e-04,  4.0569e-05, -1.3327e-03,  1.6666e-03,\n",
      "        -5.3641e-05,  4.3155e-04, -1.3222e-03, -2.7484e-04,  5.5204e-04,\n",
      "         3.7703e-04,  8.9263e-04,  2.0702e-04,  5.3964e-04,  1.1044e-03,\n",
      "         3.7987e-04, -7.3296e-04,  1.8620e-04, -2.1003e-03,  8.8081e-04,\n",
      "        -5.8583e-04, -1.0012e-03, -6.5582e-04,  1.0140e-03, -7.8767e-04,\n",
      "        -5.4261e-04, -1.3603e-03, -1.8646e-03,  1.7369e-03, -5.4153e-04,\n",
      "         1.7020e-04, -9.8125e-05, -3.2251e-04, -1.9381e-03,  6.1357e-04,\n",
      "        -3.2932e-04,  5.7107e-04, -7.7443e-04, -2.0989e-04, -7.7182e-04,\n",
      "         1.0460e-03, -8.6982e-04,  7.6583e-04, -7.6406e-04, -5.5882e-04,\n",
      "        -2.2564e-04,  3.0377e-03, -1.4190e-03, -1.0028e-03,  8.9705e-04,\n",
      "        -6.3788e-04,  1.2617e-03, -3.6494e-04,  1.6288e-03,  1.3818e-03,\n",
      "        -4.4601e-04,  1.9895e-04,  9.0091e-05,  4.3725e-04, -1.2895e-03,\n",
      "         1.0520e-03,  1.4064e-05,  1.5227e-03,  9.0783e-04, -2.2195e-03,\n",
      "        -7.7819e-04,  3.9822e-04, -5.7030e-04, -9.7892e-04, -7.2652e-04,\n",
      "        -8.6490e-04, -3.7922e-04,  1.8941e-05,  1.1946e-04, -1.4328e-03,\n",
      "         3.6886e-04,  2.3006e-03,  1.1393e-03,  1.4285e-03,  6.7796e-04,\n",
      "         4.2957e-04,  2.9531e-04, -1.1733e-03,  2.4644e-03,  4.9973e-04,\n",
      "        -2.4470e-03, -9.5114e-04,  3.0307e-04, -2.6991e-05, -1.3126e-03,\n",
      "         1.1917e-03, -4.5789e-04,  9.2490e-04, -1.1678e-04,  1.0648e-03,\n",
      "         1.3262e-03,  7.6897e-05, -9.1253e-04,  1.0640e-03, -7.4204e-06,\n",
      "         5.9733e-04, -2.6935e-04, -8.6128e-04,  2.2307e-05, -1.5197e-03,\n",
      "         1.0663e-03, -5.4167e-04, -9.1904e-05,  1.3812e-03,  9.4159e-04,\n",
      "         3.7809e-04, -8.7361e-04, -5.0844e-04,  1.1413e-04, -1.2298e-03,\n",
      "         2.2296e-04,  1.3793e-03,  2.9897e-04, -1.3866e-03, -7.5194e-04,\n",
      "        -4.2610e-04, -1.3228e-03, -1.6658e-03,  3.1860e-04,  5.1216e-04,\n",
      "        -9.1898e-04,  6.3807e-04, -9.1245e-04,  2.2117e-04,  2.3496e-04,\n",
      "        -4.4141e-04,  3.6436e-04, -1.2347e-03,  6.1575e-04, -8.6402e-04,\n",
      "         8.5481e-04,  9.5945e-04,  1.4839e-03,  1.2191e-04, -1.2705e-03,\n",
      "         4.0020e-04, -1.7905e-04, -1.0333e-03, -1.1434e-03, -3.3403e-04,\n",
      "         3.3670e-04, -1.7261e-03, -1.6823e-03,  1.2777e-03,  4.1578e-04,\n",
      "        -7.0856e-04,  1.2260e-03, -7.2313e-04,  5.2068e-04, -1.6004e-03,\n",
      "        -1.1803e-03])\n",
      "\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9998, 1.0003, 1.0008, 0.9996, 1.0012, 1.0000, 0.9981, 1.0006, 0.9973,\n",
      "        0.9990, 0.9997, 0.9998, 1.0000, 0.9991, 1.0007, 1.0012, 0.9998, 1.0004,\n",
      "        1.0022, 0.9998, 1.0004, 1.0020, 1.0001, 1.0009, 1.0000, 1.0017, 1.0026,\n",
      "        1.0018, 1.0027, 0.9989, 0.9998, 1.0002, 1.0014, 1.0004, 1.0004, 1.0002,\n",
      "        0.9988, 0.9986, 1.0009, 0.9994, 1.0006, 1.0007, 1.0023, 1.0008, 0.9974,\n",
      "        0.9978, 1.0023, 0.9995, 0.9975, 1.0000, 1.0002, 1.0003, 0.9998, 0.9995,\n",
      "        0.9988, 1.0008, 1.0014, 1.0003, 1.0008, 0.9983, 0.9996, 0.9982, 1.0005,\n",
      "        1.0001, 1.0011, 1.0000, 1.0011, 0.9982, 1.0019, 1.0015, 1.0007, 1.0000,\n",
      "        0.9984, 1.0006, 1.0023, 1.0021, 1.0000, 0.9999, 1.0021, 0.9988, 0.9993,\n",
      "        1.0015, 1.0000, 0.9994, 1.0002, 1.0014, 1.0016, 1.0003, 0.9984, 1.0008,\n",
      "        0.9986, 0.9995, 0.9970, 1.0007, 0.9990, 1.0017, 1.0001, 1.0010, 0.9994,\n",
      "        1.0011, 1.0011, 1.0018, 0.9977, 0.9974, 1.0010, 1.0015, 0.9985, 1.0001,\n",
      "        0.9995, 0.9992, 1.0001, 0.9985, 1.0014, 0.9999, 1.0002, 0.9996, 1.0003,\n",
      "        1.0013, 1.0021, 0.9970, 1.0012, 1.0005, 1.0003, 1.0008, 0.9995, 0.9975,\n",
      "        1.0017, 0.9989, 0.9985, 1.0007, 1.0005, 1.0015, 0.9996, 1.0016, 0.9971,\n",
      "        0.9991, 0.9992, 0.9991, 1.0003, 0.9967, 1.0009, 1.0017, 0.9967, 0.9983,\n",
      "        0.9984, 0.9973, 1.0020, 1.0007, 1.0014, 0.9991, 1.0006, 1.0017, 0.9993,\n",
      "        0.9986, 1.0017, 1.0020, 0.9997, 0.9994, 1.0002, 1.0004, 1.0008, 0.9962,\n",
      "        1.0020, 1.0014, 1.0010, 1.0002, 0.9984, 1.0011, 1.0007, 0.9998, 1.0013,\n",
      "        0.9980, 0.9996, 1.0014, 1.0009, 0.9994, 1.0011, 1.0010, 0.9988, 0.9994,\n",
      "        1.0006, 1.0004, 0.9989, 1.0024, 0.9990, 1.0003, 1.0007, 0.9991, 1.0005,\n",
      "        1.0019, 0.9997, 1.0004, 0.9990, 1.0019, 0.9985, 1.0024, 0.9986, 1.0023,\n",
      "        1.0008, 1.0012, 0.9964, 0.9997, 0.9969, 0.9976, 0.9994, 0.9996, 1.0007,\n",
      "        1.0000, 0.9979, 0.9987, 0.9995, 1.0010, 0.9980, 1.0006, 0.9994, 1.0003,\n",
      "        0.9979, 0.9987, 0.9984, 0.9986, 1.0004, 1.0008, 0.9990, 0.9990, 0.9983,\n",
      "        0.9981, 1.0004, 1.0007, 0.9988, 1.0014, 1.0003, 0.9996, 1.0003, 1.0016,\n",
      "        1.0023, 0.9999, 0.9991, 1.0000, 1.0001, 0.9992, 1.0016, 0.9989, 0.9971,\n",
      "        0.9995, 0.9996, 0.9996, 1.0003, 0.9961, 1.0003, 0.9994, 1.0016, 0.9978,\n",
      "        0.9997, 0.9997, 1.0012, 1.0012])\n",
      "\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias:\n",
      "\n",
      "tensor([ 4.9934e-05, -1.0740e-03,  9.9283e-05,  2.0824e-04,  5.0336e-04,\n",
      "         1.1697e-03, -2.9586e-04,  1.2222e-03,  6.8999e-04, -7.3286e-04,\n",
      "        -6.5859e-04,  2.0723e-04,  4.1630e-04,  3.0029e-04, -4.2356e-05,\n",
      "        -1.2425e-03, -1.7954e-03,  1.1166e-03, -8.6717e-04,  7.5419e-04,\n",
      "        -7.7282e-04, -8.4843e-04, -1.0998e-03,  2.2426e-03,  8.3112e-04,\n",
      "        -2.8173e-04,  1.5951e-03, -9.2122e-05,  1.3355e-03,  6.8975e-04,\n",
      "         8.0387e-05,  3.8423e-04,  8.0394e-04, -4.6920e-04, -2.8780e-04,\n",
      "         8.4970e-04, -9.4076e-04, -4.0564e-05, -2.0145e-03,  1.6827e-04,\n",
      "        -1.1137e-03,  2.0470e-03,  1.8162e-03, -1.1808e-03, -9.1370e-05,\n",
      "         5.0841e-04,  1.6308e-03, -5.0590e-04,  4.9766e-04,  9.6932e-04,\n",
      "        -9.5615e-04,  9.0536e-04, -3.7653e-04, -2.6527e-04, -1.4492e-04,\n",
      "        -1.6490e-03,  6.2477e-04, -1.0923e-03, -9.7360e-06,  2.1274e-04,\n",
      "        -2.1081e-04, -6.9078e-04, -1.9973e-03, -1.7067e-03,  7.5576e-04,\n",
      "         4.1634e-04,  1.3438e-03,  1.4335e-03,  1.4029e-03, -1.4284e-03,\n",
      "        -3.9429e-04, -1.2850e-03, -3.4299e-04, -3.9760e-04, -3.2631e-04,\n",
      "        -6.4736e-04,  1.2912e-03, -1.2541e-03,  1.2937e-03,  2.7524e-04,\n",
      "         1.2372e-03,  1.1919e-03,  7.5793e-04, -8.5261e-04,  1.9379e-03,\n",
      "         1.9240e-03, -1.4152e-03, -1.0631e-03, -5.8553e-04, -5.6868e-04,\n",
      "         3.7959e-04,  1.0300e-03, -1.1406e-03, -7.1777e-05,  5.0495e-04,\n",
      "        -1.8621e-03,  9.2565e-04, -5.9124e-04, -8.1022e-04, -5.8644e-04,\n",
      "        -1.5877e-03, -1.5098e-03, -6.9265e-04, -1.1133e-03,  1.3934e-03,\n",
      "        -5.8495e-05, -2.6417e-04, -1.6855e-03, -3.9110e-04,  5.9633e-04,\n",
      "         3.0185e-04,  7.0238e-04,  8.2710e-04,  7.5580e-04,  3.3969e-04,\n",
      "        -4.3351e-04, -1.1751e-03,  3.5054e-04, -1.2270e-03, -2.4989e-04,\n",
      "        -2.0696e-04, -5.8878e-04, -5.1222e-04,  1.1621e-03,  5.7674e-04,\n",
      "        -4.7326e-04, -1.3500e-03, -1.5059e-03,  1.3806e-03, -2.8032e-04,\n",
      "         5.7351e-04,  1.1563e-04,  1.3424e-04, -2.3439e-03,  7.3546e-04,\n",
      "        -2.1205e-04,  7.9535e-04, -8.0405e-04,  2.2285e-04, -2.4353e-04,\n",
      "         1.4558e-03,  1.7817e-04,  9.7417e-04, -7.5627e-04, -7.6212e-06,\n",
      "        -2.0258e-04,  2.6038e-03, -6.7806e-04, -7.4526e-04,  1.2491e-03,\n",
      "        -3.4052e-05,  9.0501e-04, -7.3584e-04,  1.8428e-03,  1.5454e-03,\n",
      "        -2.2817e-04, -7.2610e-04, -5.0770e-04, -3.1859e-04, -7.8828e-04,\n",
      "         1.0304e-03,  8.8274e-04,  5.9948e-04,  6.3016e-04, -1.3061e-03,\n",
      "        -8.5802e-04,  8.2346e-04, -2.5998e-04, -1.2595e-03, -5.1437e-04,\n",
      "         9.9536e-04, -1.4390e-04, -4.9626e-04, -2.1855e-04, -1.0556e-03,\n",
      "         6.8329e-04,  1.8875e-03,  2.0250e-03,  4.9916e-04,  5.2877e-04,\n",
      "        -9.9621e-04,  4.6991e-04, -1.6767e-03,  1.9006e-03,  2.3020e-04,\n",
      "        -1.2986e-03, -1.3370e-04, -2.6374e-06,  1.7271e-04, -8.8371e-04,\n",
      "         6.5079e-04, -2.2632e-04,  1.2596e-03,  7.1023e-05,  1.6183e-03,\n",
      "         1.5976e-03,  1.1165e-04, -5.3856e-04,  1.0059e-03,  4.6074e-04,\n",
      "         9.0174e-04, -1.9952e-04, -3.4840e-04,  1.1402e-04, -1.0575e-03,\n",
      "        -1.4269e-04,  4.9943e-04,  1.2024e-03,  1.1468e-03,  1.9228e-04,\n",
      "         8.0399e-05, -4.0089e-04, -1.6454e-04,  4.6106e-04, -6.7188e-04,\n",
      "         1.6888e-04,  1.2914e-03, -2.7910e-04, -1.2881e-03, -6.2876e-04,\n",
      "        -1.1204e-03, -1.5377e-03, -7.5703e-04,  1.1688e-04,  1.1921e-03,\n",
      "        -8.3977e-04,  4.2714e-04, -4.8865e-04,  8.2843e-04,  1.9136e-04,\n",
      "        -7.6696e-04,  5.0032e-04, -1.4112e-03,  7.9631e-04, -4.3566e-04,\n",
      "         1.2713e-03,  4.6636e-04,  9.8247e-04,  1.5012e-04, -1.2052e-03,\n",
      "         3.9523e-04,  2.1379e-04, -6.2922e-04, -1.1977e-03,  1.8338e-04,\n",
      "         7.7433e-04, -1.7423e-03, -1.3139e-03,  9.2279e-04, -1.8284e-04,\n",
      "        -1.1461e-03,  1.9555e-03, -9.2370e-04,  3.1064e-04, -1.4462e-03,\n",
      "        -9.6593e-04])\n",
      "\n",
      "bert.encoder.layer.1.intermediate.dense.weight:\n",
      "\n",
      "tensor([[-0.0039,  0.0118, -0.0038,  ..., -0.0324,  0.0045,  0.0077],\n",
      "        [ 0.0069, -0.0059,  0.0067,  ..., -0.0140,  0.0272, -0.0153],\n",
      "        [-0.0300,  0.0186,  0.0373,  ...,  0.0251, -0.0299,  0.0363],\n",
      "        ...,\n",
      "        [-0.0134, -0.0128,  0.0114,  ..., -0.0019,  0.0006,  0.0472],\n",
      "        [ 0.0252,  0.0568,  0.0310,  ...,  0.0128,  0.0084,  0.0091],\n",
      "        [-0.0080, -0.0146,  0.0120,  ...,  0.0203,  0.0060, -0.0095]])\n",
      "\n",
      "bert.encoder.layer.1.intermediate.dense.bias:\n",
      "\n",
      "tensor([ 0.0002, -0.0004,  0.0009,  ..., -0.0005, -0.0003,  0.0001])\n",
      "\n",
      "bert.encoder.layer.1.output.dense.weight:\n",
      "\n",
      "tensor([[-0.0142, -0.0175, -0.0032,  ...,  0.0068, -0.0183, -0.0167],\n",
      "        [-0.0064,  0.0330,  0.0065,  ...,  0.0079,  0.0162, -0.0148],\n",
      "        [-0.0050, -0.0344,  0.0281,  ...,  0.0374,  0.0037, -0.0268],\n",
      "        ...,\n",
      "        [ 0.0159, -0.0189, -0.0267,  ..., -0.0223, -0.0238,  0.0260],\n",
      "        [ 0.0154, -0.0048,  0.0280,  ...,  0.0103,  0.0272,  0.0154],\n",
      "        [ 0.0253,  0.0026,  0.0151,  ...,  0.0025, -0.0093,  0.0147]])\n",
      "\n",
      "bert.encoder.layer.1.output.dense.bias:\n",
      "\n",
      "tensor([ 1.3065e-04, -1.0744e-03,  3.3988e-04,  7.0188e-05,  7.3303e-04,\n",
      "         8.8167e-04, -1.2467e-04,  1.2667e-03,  2.1997e-04, -1.2954e-03,\n",
      "        -1.0602e-03,  4.4757e-04,  4.8096e-04,  5.6209e-05,  2.7888e-04,\n",
      "        -7.7393e-04, -1.0825e-03,  1.3700e-03, -9.6937e-04,  8.7879e-04,\n",
      "        -4.2231e-04, -4.5722e-04, -1.0631e-03,  1.6908e-03,  8.2493e-04,\n",
      "         1.8903e-04, -7.5328e-04,  3.1040e-04,  1.5101e-04,  6.2603e-04,\n",
      "        -1.1282e-04, -4.7529e-04,  5.9276e-04, -5.0016e-04,  2.8332e-04,\n",
      "         6.3272e-04, -1.9818e-03,  1.6025e-03, -2.3339e-03, -1.6213e-03,\n",
      "        -2.5509e-03,  2.0458e-03,  1.8766e-03, -5.7523e-04,  1.9291e-04,\n",
      "         1.1484e-03,  1.2960e-03, -5.3980e-04,  3.3922e-04,  6.2738e-04,\n",
      "        -1.1674e-03,  8.0165e-04,  1.0132e-03, -2.6878e-04, -2.3290e-04,\n",
      "        -2.0133e-03,  5.2858e-04, -8.4143e-04, -2.7469e-04,  2.2678e-04,\n",
      "        -2.1370e-04, -1.0829e-03, -2.2308e-03, -2.7286e-03,  2.3468e-04,\n",
      "         1.4806e-03,  8.2261e-04,  1.8922e-03,  5.8147e-04, -8.8278e-04,\n",
      "        -7.1655e-04, -1.5164e-03,  1.6422e-04, -1.2891e-04,  5.7950e-04,\n",
      "        -1.5497e-03,  1.2281e-03, -9.5977e-04,  6.7805e-04,  5.3890e-04,\n",
      "         8.7255e-04,  9.0908e-04,  9.3358e-04, -6.9074e-04,  8.3985e-04,\n",
      "         9.2445e-04, -1.2249e-04, -8.6271e-04, -4.0947e-04, -2.4586e-04,\n",
      "         1.3999e-03,  1.5829e-03, -5.1148e-04, -5.0040e-04,  6.6117e-04,\n",
      "        -1.3972e-03,  6.0287e-04, -1.8062e-04, -1.1696e-03, -1.0488e-03,\n",
      "        -2.0383e-03, -1.5150e-03, -7.5021e-04, -7.9650e-04,  1.2248e-03,\n",
      "        -3.9080e-04,  5.1260e-04, -1.6152e-03,  6.9884e-05,  1.1237e-03,\n",
      "         1.1896e-04,  7.0924e-04,  9.6649e-04, -2.7148e-06,  1.6612e-03,\n",
      "        -4.9509e-04, -1.0996e-03, -2.6265e-04, -1.1152e-03,  8.6434e-05,\n",
      "        -1.9671e-04, -4.1010e-04, -6.1422e-04,  1.2525e-03,  1.9311e-04,\n",
      "         7.2890e-04, -1.9523e-03, -1.8338e-03,  1.5008e-03,  4.7898e-04,\n",
      "         3.4486e-05, -2.3651e-04,  1.2006e-04, -2.6136e-03,  7.7124e-04,\n",
      "         1.6544e-03,  1.4467e-04, -5.5521e-04, -5.7358e-04, -4.9812e-04,\n",
      "         1.2891e-03, -7.1138e-05,  1.1844e-03, -8.6435e-04, -9.3918e-04,\n",
      "         9.5653e-04,  2.4955e-03, -4.6129e-04,  1.2380e-03,  9.2325e-04,\n",
      "         7.9526e-04,  1.6260e-04, -9.9855e-04,  1.8675e-03, -1.0631e-05,\n",
      "         2.3623e-04, -6.9600e-04,  3.6993e-05,  5.2683e-04, -5.7414e-04,\n",
      "         7.2856e-04,  8.9332e-04,  1.2245e-04,  1.5023e-03, -8.3818e-04,\n",
      "        -3.9492e-04,  1.4321e-03, -7.7696e-04, -1.4609e-03, -7.9989e-04,\n",
      "         9.4847e-04, -3.7594e-04,  8.4393e-04, -7.8305e-04, -1.2917e-03,\n",
      "        -8.4827e-04,  1.9592e-03,  2.7168e-03,  7.2794e-04,  1.0890e-03,\n",
      "        -1.4060e-03,  5.5446e-04, -1.3588e-03,  1.2909e-03,  8.7304e-04,\n",
      "        -1.8297e-03, -1.1185e-04, -3.7577e-04, -1.4156e-04, -1.3651e-03,\n",
      "         9.1563e-04, -6.8903e-04,  8.6848e-04, -4.1354e-04,  1.3232e-03,\n",
      "         4.9694e-04,  5.0957e-04, -4.7504e-04,  7.8132e-04, -1.3534e-04,\n",
      "         2.7644e-04, -8.4433e-04,  8.9273e-05,  1.2414e-03, -9.0030e-04,\n",
      "         1.2775e-04,  5.1601e-04,  1.0627e-03,  1.2987e-03, -4.2902e-04,\n",
      "        -1.1143e-04, -7.1021e-04, -3.6025e-04, -2.1082e-04, -1.1272e-03,\n",
      "        -3.2799e-04,  1.9359e-03, -9.6393e-04, -1.7233e-03, -7.5936e-04,\n",
      "        -9.0164e-04, -1.3870e-03, -4.1221e-04,  7.2311e-05,  9.3780e-04,\n",
      "        -5.7680e-04, -6.2280e-04, -7.3948e-04,  5.2705e-04, -7.6756e-04,\n",
      "         9.5826e-04,  4.6244e-04, -1.7879e-03,  1.2089e-03, -2.3298e-04,\n",
      "         1.1806e-03,  1.8021e-04,  8.9635e-04, -9.9131e-05, -1.0755e-03,\n",
      "         7.1233e-04, -5.8444e-04, -6.8206e-04, -6.9734e-04, -5.1624e-04,\n",
      "         1.5494e-03, -1.2220e-03, -1.5412e-03,  1.3929e-03, -1.1944e-04,\n",
      "        -1.1500e-03,  1.4399e-03, -8.9261e-04,  8.4160e-04, -2.1204e-03,\n",
      "        -6.4626e-04])\n",
      "\n",
      "bert.encoder.layer.1.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9995, 1.0000, 0.9996, 0.9999, 1.0008, 0.9999, 0.9982, 1.0006, 0.9973,\n",
      "        0.9991, 1.0001, 0.9993, 1.0003, 0.9992, 1.0006, 1.0009, 0.9998, 1.0009,\n",
      "        1.0018, 0.9998, 0.9991, 1.0012, 1.0004, 1.0007, 0.9997, 1.0010, 1.0022,\n",
      "        1.0020, 1.0026, 0.9989, 0.9998, 0.9998, 1.0012, 1.0004, 1.0005, 1.0002,\n",
      "        0.9986, 0.9987, 1.0010, 0.9998, 1.0008, 1.0014, 1.0025, 1.0005, 0.9975,\n",
      "        0.9978, 1.0023, 0.9992, 0.9976, 0.9998, 1.0002, 1.0003, 0.9998, 0.9996,\n",
      "        0.9987, 1.0010, 1.0013, 1.0001, 1.0008, 0.9988, 0.9996, 0.9985, 1.0007,\n",
      "        1.0007, 1.0008, 1.0000, 1.0009, 0.9992, 1.0019, 1.0016, 1.0015, 1.0006,\n",
      "        0.9988, 1.0008, 1.0024, 1.0020, 1.0004, 1.0000, 1.0017, 0.9988, 0.9995,\n",
      "        1.0014, 0.9996, 0.9997, 0.9998, 1.0010, 1.0017, 1.0003, 0.9983, 1.0009,\n",
      "        0.9985, 0.9998, 0.9968, 1.0007, 0.9989, 1.0014, 1.0000, 1.0012, 0.9993,\n",
      "        1.0012, 1.0013, 1.0009, 0.9981, 0.9975, 1.0014, 1.0014, 0.9987, 1.0001,\n",
      "        0.9994, 0.9987, 0.9998, 0.9984, 1.0015, 1.0004, 1.0000, 0.9996, 1.0003,\n",
      "        1.0015, 1.0020, 0.9969, 1.0012, 1.0005, 1.0005, 1.0011, 0.9993, 0.9978,\n",
      "        1.0015, 0.9992, 0.9982, 1.0011, 1.0003, 1.0013, 0.9996, 1.0014, 0.9971,\n",
      "        0.9990, 0.9992, 0.9995, 0.9997, 0.9978, 1.0007, 1.0017, 0.9969, 0.9979,\n",
      "        0.9977, 0.9977, 1.0021, 1.0002, 1.0010, 0.9998, 1.0005, 1.0017, 0.9994,\n",
      "        0.9991, 1.0014, 1.0016, 0.9994, 0.9993, 1.0000, 1.0002, 1.0004, 0.9962,\n",
      "        1.0017, 1.0014, 1.0011, 1.0000, 0.9992, 1.0011, 1.0007, 0.9994, 1.0014,\n",
      "        0.9983, 0.9999, 1.0010, 1.0007, 0.9993, 1.0012, 1.0017, 0.9991, 0.9994,\n",
      "        1.0003, 1.0004, 0.9991, 1.0025, 0.9989, 0.9999, 1.0008, 0.9988, 0.9999,\n",
      "        1.0016, 0.9993, 1.0002, 0.9988, 1.0020, 0.9995, 1.0019, 0.9982, 1.0023,\n",
      "        1.0012, 1.0013, 0.9964, 0.9994, 0.9963, 0.9981, 0.9998, 0.9991, 1.0007,\n",
      "        0.9999, 0.9977, 0.9987, 0.9992, 1.0001, 0.9980, 1.0004, 0.9998, 0.9999,\n",
      "        0.9980, 0.9994, 0.9992, 0.9991, 1.0003, 1.0007, 0.9988, 0.9990, 0.9982,\n",
      "        0.9981, 1.0002, 1.0007, 0.9987, 1.0015, 1.0001, 0.9999, 1.0000, 1.0010,\n",
      "        1.0020, 0.9996, 0.9993, 1.0001, 0.9998, 0.9988, 1.0017, 0.9987, 0.9971,\n",
      "        0.9995, 0.9996, 0.9994, 1.0002, 0.9961, 1.0004, 0.9996, 1.0017, 0.9982,\n",
      "        0.9994, 0.9997, 1.0013, 1.0013])\n",
      "\n",
      "bert.encoder.layer.1.output.LayerNorm.bias:\n",
      "\n",
      "tensor([ 1.8987e-04, -9.1695e-04,  6.3806e-05,  3.5198e-04,  5.2388e-04,\n",
      "         1.0434e-03, -1.3375e-04,  1.2340e-03,  6.0907e-04, -4.0610e-04,\n",
      "        -7.1397e-04,  2.9070e-05,  5.1140e-05,  4.0035e-04,  1.0827e-04,\n",
      "        -1.1785e-03, -1.7556e-03,  1.1970e-03, -7.9476e-04,  5.0553e-04,\n",
      "        -6.7337e-04, -8.3470e-04, -8.8685e-04,  2.0559e-03,  5.9546e-04,\n",
      "        -5.2749e-06,  1.3084e-03, -2.5270e-04,  1.1490e-03,  7.2502e-04,\n",
      "         7.7734e-05,  1.4429e-04,  3.6372e-04, -4.1405e-04, -3.0026e-05,\n",
      "         1.1531e-03, -1.1954e-03,  1.8052e-05, -1.9107e-03,  2.5694e-04,\n",
      "        -8.5999e-04,  2.0868e-03,  1.7823e-03, -1.0500e-03, -1.1850e-04,\n",
      "         5.9781e-04,  1.4602e-03, -2.1984e-04,  5.5379e-04,  9.2689e-04,\n",
      "        -6.1046e-04,  7.3854e-04, -3.4674e-04, -1.3311e-04, -6.0393e-04,\n",
      "        -1.6724e-03,  6.1725e-04, -1.1238e-03,  2.7076e-05, -5.9444e-05,\n",
      "        -1.2054e-04, -6.2410e-04, -1.9434e-03, -1.8801e-03,  7.8621e-04,\n",
      "         4.8209e-04,  1.1473e-03,  1.5137e-03,  1.1527e-03, -1.2456e-03,\n",
      "        -1.9561e-04, -1.1655e-03, -3.0903e-04, -5.0332e-04, -2.3965e-04,\n",
      "        -6.5258e-04,  1.2532e-03, -1.1728e-03,  1.2883e-03,  3.1614e-04,\n",
      "         1.1254e-03,  1.0861e-03,  2.8273e-04, -8.4455e-04,  1.4705e-03,\n",
      "         1.4794e-03, -1.1322e-03, -9.5741e-04, -4.7099e-04, -5.6296e-04,\n",
      "         4.8019e-04,  1.0344e-03, -1.1311e-03, -2.6318e-04,  4.7912e-04,\n",
      "        -1.4445e-03,  7.2871e-04, -5.9512e-04, -8.1798e-04, -6.4498e-04,\n",
      "        -1.7162e-03, -1.3941e-03, -6.5772e-04, -1.3196e-03,  1.5022e-03,\n",
      "         3.1231e-05,  1.9714e-04, -1.4227e-03, -3.0674e-04,  8.1460e-04,\n",
      "         1.7825e-04,  4.8677e-04,  9.3423e-04,  7.8693e-04,  7.0833e-04,\n",
      "        -8.8107e-04, -1.1472e-03,  4.9635e-05, -1.0785e-03, -2.2744e-04,\n",
      "        -3.2651e-04, -8.0437e-04, -4.0461e-04,  1.2486e-03,  4.8587e-04,\n",
      "        -5.4471e-04, -1.0647e-03, -1.4683e-03,  1.0513e-03,  2.5793e-04,\n",
      "         4.2280e-04,  3.0034e-04,  4.8147e-05, -2.1660e-03,  1.2586e-03,\n",
      "         2.9897e-04,  7.1510e-04, -8.8549e-04,  3.1270e-04, -1.9879e-04,\n",
      "         1.3300e-03,  2.7818e-04,  9.0158e-04, -8.2634e-04, -1.9790e-05,\n",
      "        -3.8547e-04,  2.5588e-03, -3.0216e-04, -7.2037e-04,  1.6373e-03,\n",
      "        -7.9725e-05,  8.4649e-04, -8.4763e-04,  1.8017e-03,  1.3800e-03,\n",
      "        -4.2432e-04, -7.9404e-04, -5.2981e-04, -1.5251e-04, -6.5965e-04,\n",
      "         6.7241e-04,  8.6383e-04,  7.4226e-04,  3.2898e-04, -1.1567e-03,\n",
      "        -8.0502e-04,  1.0517e-03, -4.2995e-04, -1.3638e-03, -4.2022e-04,\n",
      "         7.9840e-04, -1.1623e-04, -5.0897e-05, -1.0252e-04, -8.5171e-04,\n",
      "         4.6863e-04,  1.8568e-03,  1.9920e-03,  5.3752e-04,  2.5880e-04,\n",
      "        -1.2149e-03,  5.6415e-04, -1.6949e-03,  1.8979e-03,  2.4421e-04,\n",
      "        -1.4685e-03, -1.7369e-04, -6.3854e-06,  8.2892e-05, -6.1895e-04,\n",
      "         1.0761e-03, -4.4226e-04,  1.3001e-03, -2.0195e-04,  1.7140e-03,\n",
      "         1.4194e-03,  4.9284e-04, -6.1402e-04,  1.0563e-03,  3.7112e-04,\n",
      "         8.9633e-04, -4.1107e-04, -3.3673e-04, -3.3842e-05, -7.9032e-04,\n",
      "        -9.4000e-05,  3.8836e-04,  9.5857e-04,  9.1706e-04,  1.1874e-04,\n",
      "        -9.5741e-06, -5.4912e-04, -4.4133e-04,  2.4663e-05, -7.4576e-04,\n",
      "         6.4430e-05,  1.0502e-03, -2.7094e-04, -1.3289e-03, -5.5081e-04,\n",
      "        -1.0425e-03, -1.4939e-03, -8.4221e-04, -1.1148e-06,  1.2912e-03,\n",
      "        -6.4938e-04, -3.2070e-04, -6.0593e-04,  8.6560e-04,  5.6148e-04,\n",
      "        -8.1398e-04,  5.7043e-04, -1.4155e-03,  7.7364e-04, -3.7332e-04,\n",
      "         1.3088e-03,  7.3222e-04,  1.1109e-03,  3.3939e-05, -1.4022e-03,\n",
      "         2.2009e-04, -3.8541e-05, -2.1627e-04, -1.1133e-03, -7.7708e-05,\n",
      "         7.9812e-04, -1.5369e-03, -9.6962e-04,  9.9965e-04, -4.2011e-04,\n",
      "        -1.1944e-03,  1.9795e-03, -7.9434e-04,  2.4403e-04, -1.5237e-03,\n",
      "        -8.0174e-04])\n",
      "\n",
      "bert.encoder.layer.2.attention.self.query.weight:\n",
      "\n",
      "tensor([[ 1.7632e-02,  2.8574e-02, -2.9344e-02,  ..., -8.7262e-03,\n",
      "         -3.5227e-02,  9.3832e-03],\n",
      "        [ 1.0684e-03, -2.8414e-03,  2.5721e-02,  ...,  1.5054e-02,\n",
      "          2.4077e-05,  2.9200e-03],\n",
      "        [ 2.1272e-02,  1.7768e-02, -5.9162e-03,  ...,  1.1137e-02,\n",
      "         -4.9875e-03,  1.5075e-02],\n",
      "        ...,\n",
      "        [-6.5100e-03,  7.5779e-03, -7.5677e-03,  ..., -5.2970e-03,\n",
      "          2.0013e-02,  2.3875e-03],\n",
      "        [-1.1142e-02,  8.3250e-03,  1.0391e-02,  ..., -1.1608e-02,\n",
      "         -3.1870e-02,  2.5257e-02],\n",
      "        [ 2.3227e-02, -1.0116e-02, -1.0565e-02,  ...,  1.1232e-02,\n",
      "          2.2068e-02, -2.4472e-03]])\n",
      "\n",
      "bert.encoder.layer.2.attention.self.query.bias:\n",
      "\n",
      "tensor([-4.8191e-04, -7.9539e-04,  3.8999e-04,  1.7042e-03,  2.6781e-03,\n",
      "        -1.7397e-03,  1.5683e-03,  2.4252e-03, -7.2831e-05, -1.3291e-03,\n",
      "        -6.1409e-04, -5.9135e-04, -6.7056e-04,  1.4316e-05,  9.2518e-04,\n",
      "         3.1619e-03,  5.7486e-05, -7.9250e-04, -2.5400e-03,  2.1128e-03,\n",
      "        -1.2060e-03,  1.8936e-03,  8.0044e-04, -7.6514e-04, -1.9829e-04,\n",
      "         1.0024e-03, -9.7441e-04,  7.2287e-04,  5.8723e-04,  4.3880e-04,\n",
      "         1.2879e-03,  6.3994e-04, -6.7295e-04,  1.2840e-03, -1.2269e-03,\n",
      "         2.3176e-03, -1.2300e-03,  9.4340e-04, -6.6846e-04, -3.9826e-04,\n",
      "         1.2012e-04,  1.1970e-03, -1.3053e-04, -2.1349e-03, -1.2532e-03,\n",
      "        -2.5654e-03,  1.9491e-04, -1.6723e-03,  1.1074e-03,  5.2682e-04,\n",
      "        -1.4468e-03,  2.2125e-04,  1.1566e-03,  6.0105e-04,  1.0287e-03,\n",
      "         5.3124e-04,  1.3439e-03,  1.3097e-03,  6.5828e-04, -3.8701e-04,\n",
      "        -1.4465e-04,  1.5691e-03, -3.9417e-04, -2.9064e-03, -1.7985e-04,\n",
      "         4.4491e-04,  2.1192e-03,  6.2423e-04, -1.5493e-03,  1.8211e-03,\n",
      "        -1.6426e-03, -1.3281e-03, -2.3429e-03, -1.7176e-03,  2.5575e-04,\n",
      "         2.4867e-04,  1.0376e-03,  7.4515e-05,  2.7638e-03, -1.7019e-03,\n",
      "        -7.7835e-04,  2.2371e-04, -1.8222e-04,  1.8735e-03,  2.6202e-03,\n",
      "        -1.5619e-03,  3.2433e-03, -2.6141e-03, -1.0187e-03, -5.3653e-04,\n",
      "        -1.7610e-03, -1.3096e-03,  3.9440e-04,  9.7388e-05,  4.1584e-04,\n",
      "        -1.8441e-03, -6.6231e-04,  1.2117e-03, -1.2763e-03,  1.2392e-03,\n",
      "         2.3928e-03, -6.6243e-04,  1.8268e-03,  8.8879e-04,  1.7054e-03,\n",
      "        -1.1746e-03,  3.3688e-04, -1.9689e-03,  4.1274e-04,  2.3627e-04,\n",
      "         5.6556e-04, -8.7979e-04, -1.7881e-03, -1.2600e-03, -6.2094e-04,\n",
      "        -8.9782e-06, -1.1652e-03, -1.4201e-03, -7.0450e-04, -5.5730e-04,\n",
      "        -8.5675e-04,  1.6486e-03,  3.0455e-03, -2.5563e-04, -4.3076e-04,\n",
      "        -4.7614e-04, -2.6684e-03,  9.8361e-04, -2.8488e-03, -1.2433e-03,\n",
      "        -4.0481e-04, -2.1953e-05, -8.9863e-04,  1.4194e-03,  1.8327e-03,\n",
      "         1.2689e-03, -6.7525e-04,  1.7231e-03, -2.4013e-03, -3.2844e-03,\n",
      "        -7.6310e-04,  3.1641e-03, -1.0172e-04,  1.0746e-03,  2.5381e-03,\n",
      "         1.5061e-03, -1.8740e-03,  4.2716e-03,  1.4283e-03, -2.9856e-04,\n",
      "         3.2095e-03,  2.0344e-03, -2.7836e-03, -7.0150e-04,  1.6262e-03,\n",
      "        -7.6348e-04,  3.1016e-03, -7.9915e-04,  4.8753e-04, -6.2265e-04,\n",
      "        -1.7647e-03,  2.4788e-03, -2.0155e-05, -2.4759e-03,  3.0000e-04,\n",
      "        -1.6847e-03,  1.6618e-03, -9.6125e-04, -1.3007e-03,  5.7148e-04,\n",
      "         2.5767e-03, -1.6781e-03, -1.6439e-03,  6.9284e-04,  2.1347e-03,\n",
      "        -1.3552e-03,  1.0053e-03,  2.5029e-03,  2.1508e-04,  4.9089e-04,\n",
      "        -1.5987e-03, -1.3053e-03,  6.6851e-04,  1.2141e-03, -1.7662e-03,\n",
      "        -1.9999e-03, -8.9379e-04, -1.5746e-03, -1.0358e-03, -2.6619e-03,\n",
      "         2.0260e-03,  1.0109e-03,  2.7637e-04, -1.9770e-03,  2.3403e-03,\n",
      "        -3.7545e-04,  5.0990e-04,  2.4534e-03,  3.2599e-03, -9.4473e-04,\n",
      "        -1.3486e-03,  5.6822e-04, -2.9839e-04, -1.8825e-03,  2.3977e-03,\n",
      "         1.7704e-03,  6.4038e-04,  1.9047e-04, -5.9066e-04, -2.6817e-04,\n",
      "         1.1985e-03,  1.0396e-03,  1.4544e-03,  1.3770e-03, -9.1746e-04,\n",
      "         2.5752e-05, -1.5655e-03, -3.7642e-04,  2.5503e-03, -8.3332e-04,\n",
      "         3.0641e-03,  1.7982e-03,  6.8442e-04,  2.0102e-03, -6.5945e-04,\n",
      "        -1.8066e-03,  1.4320e-03, -1.9871e-03, -1.7881e-04,  1.8556e-04,\n",
      "         7.8138e-04, -3.5224e-04,  2.5075e-03, -1.5282e-03, -1.9452e-03,\n",
      "        -4.0559e-04,  5.1167e-04,  1.6543e-03,  2.8429e-04,  1.6150e-03,\n",
      "         6.7839e-04,  1.3598e-03,  1.4877e-03,  2.0267e-03, -3.6824e-04,\n",
      "        -1.6629e-03, -1.9392e-03,  1.6968e-03, -4.1840e-04,  3.2966e-04,\n",
      "        -1.5160e-03,  1.7858e-03, -1.3192e-03,  2.4893e-03,  1.4770e-03,\n",
      "         2.8332e-03])\n",
      "\n",
      "bert.encoder.layer.2.attention.self.key.weight:\n",
      "\n",
      "tensor([[-0.0033, -0.0252, -0.0110,  ...,  0.0193, -0.0210,  0.0148],\n",
      "        [-0.0341, -0.0101, -0.0025,  ..., -0.0268, -0.0132, -0.0385],\n",
      "        [ 0.0282,  0.0022,  0.0263,  ..., -0.0113,  0.0037, -0.0003],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0056, -0.0342,  ..., -0.0089,  0.0129, -0.0033],\n",
      "        [ 0.0179, -0.0316, -0.0093,  ...,  0.0252,  0.0046, -0.0136],\n",
      "        [ 0.0090, -0.0239, -0.0109,  ...,  0.0228, -0.0257, -0.0075]])\n",
      "\n",
      "bert.encoder.layer.2.attention.self.key.bias:\n",
      "\n",
      "tensor([-7.8726e-10, -1.4308e-09, -1.6496e-09, -4.9594e-09, -9.1868e-10,\n",
      "        -8.8310e-10, -2.7915e-10, -8.7388e-09, -5.9035e-09,  3.5863e-09,\n",
      "         7.1350e-09,  4.7326e-09,  3.6930e-09,  3.6700e-09, -1.2343e-08,\n",
      "        -1.7736e-09,  4.0808e-11,  4.8625e-09,  9.8383e-09, -2.6031e-09,\n",
      "         2.9523e-09, -1.2910e-08, -5.1807e-09, -8.2323e-09,  4.7052e-09,\n",
      "        -9.6468e-10, -6.7303e-10, -4.1021e-09, -1.7762e-09,  8.7612e-09,\n",
      "         1.3685e-08,  3.7621e-10, -4.9683e-09,  1.6585e-10,  2.1038e-09,\n",
      "         1.4768e-09,  5.9076e-09, -2.4718e-09, -3.8077e-09,  5.7356e-09,\n",
      "        -2.8313e-09, -3.8560e-09,  8.3156e-09,  2.3790e-10, -9.4758e-09,\n",
      "         1.1218e-08, -1.3620e-08,  2.8217e-09,  1.9159e-09,  5.7123e-09,\n",
      "        -3.2193e-09,  5.6295e-09, -6.5090e-09,  6.8283e-09,  3.9435e-09,\n",
      "         2.6459e-09,  7.3814e-10, -1.0713e-09,  8.3734e-10,  1.5300e-08,\n",
      "         2.9907e-09, -1.9955e-09,  4.1074e-09,  4.4360e-09,  7.9633e-09,\n",
      "         3.4784e-09,  9.8850e-10, -6.7436e-09,  4.5537e-09, -2.1030e-10,\n",
      "         1.9672e-09, -6.4582e-10,  2.1442e-10,  5.1225e-10, -8.9632e-09,\n",
      "         1.6413e-09,  5.0471e-09,  2.6697e-13, -3.7488e-09,  2.5781e-09,\n",
      "         6.6705e-09,  1.7143e-09, -3.6019e-09,  5.9349e-09,  1.7339e-08,\n",
      "         1.2139e-09, -3.9851e-09,  1.7465e-08,  5.9017e-09,  7.7075e-10,\n",
      "        -6.0785e-09,  3.8542e-09, -2.5342e-09, -1.8977e-09,  6.5523e-09,\n",
      "         1.2462e-09,  7.9217e-09,  9.3625e-09,  2.5658e-10,  7.6130e-09,\n",
      "         8.5445e-10,  4.7907e-09,  3.9005e-09,  5.2814e-09, -9.0295e-09,\n",
      "        -1.5912e-09,  5.9677e-09, -5.1049e-09,  3.0869e-09, -2.3488e-09,\n",
      "         1.9428e-09, -4.3356e-10,  6.6881e-09, -9.1845e-09,  9.0419e-09,\n",
      "        -4.0034e-09, -1.4122e-08, -2.4223e-09,  9.6204e-09,  8.5259e-09,\n",
      "        -2.4389e-09,  1.2259e-08, -2.3359e-09,  8.3116e-10, -1.6372e-09,\n",
      "         2.2411e-09,  6.1959e-09,  5.9829e-09,  8.6597e-09, -5.6160e-09,\n",
      "        -1.2249e-09,  2.5540e-09, -4.8817e-09, -7.9088e-09, -2.2278e-09,\n",
      "         1.0284e-09, -3.3574e-09, -1.7108e-09,  5.6306e-09,  6.9625e-09,\n",
      "         8.1078e-10,  6.8519e-10,  2.5796e-10,  1.2661e-09, -3.5637e-09,\n",
      "        -7.2658e-09,  5.4802e-09,  9.6076e-10, -7.9075e-10,  1.6280e-09,\n",
      "        -6.1515e-09, -4.6275e-09,  1.2424e-08,  6.1437e-09, -5.5143e-10,\n",
      "         1.4104e-09, -2.6927e-09, -6.0084e-09, -5.7210e-09,  1.8140e-09,\n",
      "         5.0014e-09, -1.5724e-09,  6.8444e-09, -3.2789e-09,  4.5624e-09,\n",
      "        -2.2172e-09, -6.1176e-09, -1.5856e-09, -1.5082e-09, -5.5154e-09,\n",
      "        -3.4569e-09, -2.1509e-10,  9.6663e-09, -2.7312e-09,  2.8425e-10,\n",
      "        -3.0555e-09, -5.2314e-10,  2.5506e-09, -2.8473e-09,  2.4555e-09,\n",
      "         4.3652e-09, -4.7165e-09, -3.2844e-10,  1.3721e-09,  6.8714e-10,\n",
      "         8.0644e-10,  1.8978e-10,  2.8603e-09, -1.5807e-09,  3.4311e-09,\n",
      "        -6.1962e-09, -5.5386e-09,  6.7430e-09, -2.7673e-09,  9.3676e-10,\n",
      "        -1.7840e-10, -2.7874e-09,  9.9039e-10, -6.9654e-09, -1.0454e-08,\n",
      "         2.3041e-09, -3.7624e-09, -5.8872e-09,  3.8967e-09,  2.9438e-09,\n",
      "         8.4056e-09, -2.5897e-09, -3.7399e-09, -1.7930e-09, -2.8861e-09,\n",
      "         5.8127e-09,  2.4411e-09, -8.9456e-09, -3.4132e-09, -3.3713e-09,\n",
      "         6.2462e-10,  3.8396e-09,  2.1494e-09, -2.5651e-09, -2.8881e-09,\n",
      "         4.7632e-10,  2.3684e-09,  4.7979e-09, -2.2906e-09,  8.5495e-09,\n",
      "        -1.6205e-09, -5.2672e-09, -1.0935e-09, -9.5639e-09,  8.7625e-09,\n",
      "        -3.4719e-09,  5.6679e-09, -1.3948e-09,  4.1381e-09,  6.1726e-09,\n",
      "        -3.6979e-09,  4.0498e-09, -5.5498e-09,  2.6387e-10, -4.4818e-09,\n",
      "         1.0656e-09, -5.5645e-10,  5.4624e-09,  3.9279e-10,  7.5731e-10,\n",
      "        -5.8826e-10,  1.0246e-08, -5.9623e-09, -5.5137e-11,  4.0009e-09,\n",
      "         9.3854e-09, -8.1588e-10,  9.0845e-10, -1.6381e-09,  3.9829e-09,\n",
      "         1.6516e-10])\n",
      "\n",
      "bert.encoder.layer.2.attention.self.value.weight:\n",
      "\n",
      "tensor([[-0.0240,  0.0034, -0.0096,  ..., -0.0081,  0.0064, -0.0282],\n",
      "        [ 0.0178,  0.0253,  0.0071,  ..., -0.0345,  0.0157, -0.0004],\n",
      "        [ 0.0192, -0.0035,  0.0178,  ..., -0.0116, -0.0067, -0.0038],\n",
      "        ...,\n",
      "        [ 0.0126, -0.0191,  0.0403,  ..., -0.0177, -0.0113,  0.0126],\n",
      "        [-0.0105, -0.0332, -0.0169,  ...,  0.0020, -0.0178, -0.0118],\n",
      "        [ 0.0035, -0.0023,  0.0039,  ..., -0.0039,  0.0044,  0.0423]])\n",
      "\n",
      "bert.encoder.layer.2.attention.self.value.bias:\n",
      "\n",
      "tensor([ 4.8870e-04,  2.9403e-05,  1.0341e-03,  1.0456e-04,  9.7601e-04,\n",
      "         2.2580e-03,  1.0036e-03, -7.8124e-04,  7.0442e-04,  2.3418e-03,\n",
      "        -2.2437e-04,  8.6410e-04, -5.7884e-04,  1.1841e-03, -1.6327e-03,\n",
      "        -1.7977e-03, -9.8081e-04, -1.5078e-03,  7.0098e-04,  7.6944e-04,\n",
      "        -6.5075e-04,  1.4161e-04,  1.5700e-04, -2.3407e-03,  4.7306e-04,\n",
      "        -5.3135e-04,  7.9278e-04, -8.9640e-04, -1.2764e-03,  5.9741e-04,\n",
      "        -1.4894e-03,  3.4219e-04, -1.0228e-03, -1.0778e-03,  9.5170e-04,\n",
      "         1.7114e-04, -3.1089e-04, -8.1901e-05, -2.1682e-03, -1.3437e-04,\n",
      "         9.8195e-04, -8.3051e-05,  7.1932e-04, -7.7431e-04, -6.2144e-04,\n",
      "         5.3908e-04, -1.3350e-03,  1.9667e-03,  1.2094e-04, -1.2976e-03,\n",
      "        -1.2388e-04, -6.2349e-04, -1.9223e-03,  1.8076e-03,  7.6456e-04,\n",
      "        -7.3901e-04, -1.8668e-03, -2.4795e-03, -1.0165e-03, -5.0013e-04,\n",
      "        -4.5118e-04, -8.4955e-04, -1.2865e-04, -1.1705e-03, -7.3117e-04,\n",
      "         1.3132e-04, -9.1704e-04, -1.2809e-03,  7.1870e-04,  1.5279e-03,\n",
      "         1.4653e-03,  2.8133e-04,  1.6402e-03,  1.9797e-03,  2.7964e-04,\n",
      "        -2.4932e-04,  6.2652e-04, -2.8844e-04,  8.8210e-04, -3.8034e-04,\n",
      "        -2.7565e-03, -9.9943e-05, -1.8852e-04,  1.7584e-03, -4.5445e-04,\n",
      "         2.9378e-04, -6.8852e-04, -1.3684e-03, -6.8457e-04,  1.2059e-03,\n",
      "         9.1594e-04, -6.6793e-04,  4.8480e-04, -2.4429e-03, -1.0859e-03,\n",
      "         1.3876e-03, -1.3119e-03, -3.0366e-04,  1.4113e-03, -1.3650e-03,\n",
      "        -1.2464e-04,  8.1970e-04,  1.1862e-03,  2.4531e-04, -6.6467e-04,\n",
      "         9.2586e-04,  2.1800e-04,  5.6902e-04, -1.0007e-03, -6.2255e-04,\n",
      "         5.1640e-04,  6.7775e-04, -1.4359e-03, -6.7912e-04, -6.9895e-04,\n",
      "        -3.3738e-04,  1.4873e-03,  9.1446e-04,  1.3996e-03, -6.6500e-04,\n",
      "         1.5825e-03, -6.5096e-04, -1.0574e-03,  8.3103e-04,  1.4644e-03,\n",
      "        -2.9050e-04,  4.2185e-04,  9.5156e-06,  1.5411e-03, -5.3326e-04,\n",
      "        -1.0712e-03, -1.4026e-03,  9.6754e-04,  1.6377e-05,  9.5120e-04,\n",
      "        -2.8181e-04, -6.1163e-04,  5.1714e-04, -1.4771e-03, -1.7604e-03,\n",
      "         5.4548e-04, -4.2115e-04, -4.5438e-04, -1.7326e-03, -1.0326e-03,\n",
      "         4.1001e-04,  5.4479e-04,  2.1850e-04, -1.0478e-03,  3.3517e-04,\n",
      "         8.8237e-04,  2.5276e-04, -7.1040e-04,  9.8829e-04,  2.6677e-03,\n",
      "        -1.0045e-03,  1.0736e-03, -7.5889e-06,  1.1047e-03, -1.4524e-03,\n",
      "        -1.0839e-04,  7.1271e-04, -2.2852e-03, -1.0726e-03,  1.8307e-04,\n",
      "        -1.3402e-03,  4.5258e-04, -1.0024e-03, -1.7229e-03, -7.7557e-04,\n",
      "         1.9366e-03,  1.3573e-03,  9.8733e-04,  3.0942e-03, -7.0160e-04,\n",
      "         2.8850e-03,  2.1141e-04,  3.0174e-04,  4.2601e-04,  8.7420e-04,\n",
      "        -8.8455e-04, -1.5366e-03, -8.2007e-05,  3.1517e-04, -9.9039e-04,\n",
      "         1.2572e-03,  2.0557e-04, -4.2360e-04, -8.6536e-04,  1.3301e-03,\n",
      "         1.5338e-03,  1.1195e-03, -9.1422e-04,  1.8479e-03, -9.3428e-04,\n",
      "        -5.5987e-04, -1.7144e-04, -2.3305e-04,  5.1805e-04,  9.4403e-04,\n",
      "         1.8215e-04, -1.6195e-03,  3.8880e-04,  1.4612e-04,  7.8324e-04,\n",
      "         6.5717e-04, -4.6277e-05,  5.5009e-05,  6.1406e-04, -1.7855e-03,\n",
      "        -1.2301e-04,  2.2230e-04,  1.7339e-03, -1.0106e-03,  3.8580e-04,\n",
      "         7.4268e-05, -1.0085e-03,  2.8353e-04,  1.1276e-03,  3.2442e-04,\n",
      "        -3.5724e-04, -1.1330e-03, -1.2477e-03,  1.5260e-03, -2.2805e-04,\n",
      "         1.0348e-03, -7.0035e-04, -1.7996e-03,  7.2323e-04, -5.0574e-04,\n",
      "        -1.1278e-03, -9.0407e-04,  9.0081e-04,  6.4578e-04,  1.4000e-03,\n",
      "         6.9219e-04, -1.0451e-03,  5.7057e-04,  1.2696e-03, -7.0994e-04,\n",
      "        -3.5916e-04, -3.6190e-04, -9.5527e-04,  3.6220e-04, -5.3566e-04,\n",
      "        -3.8758e-05, -9.8092e-04, -2.1561e-04,  4.2044e-04,  8.7799e-04,\n",
      "         2.7920e-04,  4.0095e-04,  6.1655e-04, -7.9824e-04, -2.2393e-03,\n",
      "         1.4879e-03])\n",
      "\n",
      "bert.encoder.layer.2.attention.output.dense.weight:\n",
      "\n",
      "tensor([[-6.1145e-03,  1.5193e-02,  8.5724e-03,  ...,  1.5330e-02,\n",
      "         -1.1163e-02, -3.7084e-02],\n",
      "        [-3.4339e-05,  2.5627e-02, -3.1179e-02,  ..., -3.0511e-02,\n",
      "         -9.4394e-03,  1.0463e-02],\n",
      "        [ 8.2469e-04, -3.0123e-02,  3.3594e-02,  ...,  5.4236e-03,\n",
      "          9.6011e-03,  2.9375e-02],\n",
      "        ...,\n",
      "        [ 1.7779e-02,  8.5663e-03, -1.9945e-02,  ..., -5.8366e-04,\n",
      "          1.4705e-02,  3.7900e-02],\n",
      "        [-1.4789e-02,  4.1388e-03,  2.1314e-02,  ...,  3.1224e-05,\n",
      "          1.2361e-02, -1.3929e-02],\n",
      "        [ 1.3234e-02,  3.3305e-02,  9.1761e-04,  ..., -7.8234e-03,\n",
      "          1.5415e-02, -6.8393e-03]])\n",
      "\n",
      "bert.encoder.layer.2.attention.output.dense.bias:\n",
      "\n",
      "tensor([ 7.5157e-04, -7.4490e-04,  4.8409e-04,  1.4493e-03,  3.5990e-04,\n",
      "         8.1724e-04, -1.3591e-04,  6.6394e-04,  6.5459e-05, -8.7334e-04,\n",
      "         5.5888e-04, -3.5275e-04, -1.7495e-03,  4.6711e-04, -1.1630e-04,\n",
      "        -9.5341e-04, -9.4280e-04,  1.1765e-03, -8.7041e-04, -8.6146e-04,\n",
      "        -1.1968e-03, -1.1305e-03, -1.3158e-03,  1.7762e-03,  1.0569e-03,\n",
      "        -1.0998e-03,  1.1157e-03,  3.2086e-04,  1.2353e-03,  6.0662e-04,\n",
      "        -2.3387e-04,  9.4257e-05, -9.6277e-05, -6.4115e-04, -4.9569e-04,\n",
      "         1.5495e-03, -1.0289e-03,  4.2272e-04, -2.2123e-03,  8.9859e-04,\n",
      "        -5.3890e-04,  1.1896e-03,  1.4493e-03, -9.7868e-04, -1.5784e-04,\n",
      "         1.0935e-03,  9.6886e-04,  8.8111e-05,  1.0492e-03,  6.6975e-04,\n",
      "        -6.0867e-04,  7.9994e-04,  3.5626e-05,  1.6070e-04,  1.0981e-03,\n",
      "        -1.2837e-03, -3.0949e-04, -1.1920e-03,  4.9996e-04, -4.8817e-04,\n",
      "        -1.4803e-04, -1.5574e-04, -1.7180e-03, -2.3115e-03,  9.4174e-04,\n",
      "         3.3750e-06,  5.3893e-04,  1.3740e-03,  2.1195e-03, -1.8010e-03,\n",
      "        -2.1103e-04, -1.5508e-03, -8.8271e-04,  1.2252e-03, -2.6834e-04,\n",
      "        -1.3920e-03,  5.0150e-04, -1.1034e-03,  1.4285e-03,  3.6618e-04,\n",
      "         1.0725e-03,  1.5658e-03,  9.8844e-05, -1.3842e-03, -1.6324e-04,\n",
      "         1.9112e-03, -3.1756e-04, -1.3402e-03, -7.2796e-04, -2.1602e-04,\n",
      "        -6.9990e-04,  4.8976e-04, -2.3093e-03,  2.5091e-04,  5.6637e-04,\n",
      "        -1.2507e-03,  5.4149e-05, -6.0360e-04, -3.4453e-04, -2.1431e-04,\n",
      "        -2.6206e-03, -6.1050e-04, -1.0568e-03, -3.1195e-04,  1.1652e-03,\n",
      "         8.5269e-04,  4.6697e-04, -9.7734e-04,  1.5300e-03,  1.1210e-03,\n",
      "         8.5504e-04,  9.2086e-04,  1.2512e-03,  3.8762e-04, -5.6542e-04,\n",
      "        -3.5664e-04, -9.6653e-04,  1.1039e-04, -1.0015e-03, -9.8032e-05,\n",
      "        -2.0889e-04, -9.0683e-04, -2.2551e-04,  6.5374e-04,  1.3850e-03,\n",
      "        -1.3692e-03,  1.2543e-04, -8.7657e-04,  1.1757e-03,  4.2989e-04,\n",
      "         2.0201e-04,  2.1783e-04, -3.8827e-04, -1.8684e-03,  7.0985e-04,\n",
      "        -4.8524e-04,  1.1963e-03, -8.2413e-04,  1.0261e-03, -1.8243e-04,\n",
      "         1.3835e-03,  1.5822e-03, -3.0638e-04, -6.0942e-04,  1.7101e-04,\n",
      "         1.0249e-04,  1.4703e-03, -2.9139e-04,  2.3680e-04,  2.5718e-03,\n",
      "        -3.7519e-04, -7.7749e-05, -3.0614e-04,  2.0251e-03,  1.0018e-03,\n",
      "        -1.4648e-03, -5.0453e-04, -5.2749e-05, -5.7617e-04, -7.7474e-04,\n",
      "        -2.4563e-04,  7.9809e-04,  1.8776e-04, -3.9262e-06, -5.2771e-04,\n",
      "        -1.4493e-03,  9.2287e-04,  1.0628e-04, -8.9309e-04, -9.3561e-04,\n",
      "        -5.6319e-04, -3.5819e-04,  4.3249e-04,  1.6323e-04, -7.3665e-04,\n",
      "        -2.0643e-04,  2.0301e-03,  1.8691e-03,  3.2382e-04, -1.9554e-04,\n",
      "        -8.6996e-04,  6.7112e-04, -2.1078e-03,  1.9487e-03, -4.1183e-04,\n",
      "        -1.3156e-03, -6.6827e-04, -4.1324e-04, -1.5864e-04, -3.8588e-04,\n",
      "         1.6068e-03, -7.6506e-04,  1.4528e-03,  1.7076e-05,  1.0801e-03,\n",
      "         9.5641e-04,  6.7155e-04, -8.8698e-04,  1.0885e-03, -2.4472e-05,\n",
      "         1.2739e-03, -1.9758e-04, -3.5500e-04, -9.0286e-04, -1.7436e-04,\n",
      "        -1.4482e-04, -7.4318e-04,  5.0764e-04,  8.5126e-04,  2.9487e-04,\n",
      "         4.7897e-05, -2.7545e-04, -2.3278e-04,  2.3814e-04,  2.4452e-04,\n",
      "         3.5047e-04,  1.2406e-03, -4.3176e-04, -9.2495e-04, -9.1667e-04,\n",
      "        -1.7285e-03, -1.2863e-03, -3.4639e-04,  1.1146e-03,  8.1477e-04,\n",
      "        -1.3022e-03,  6.1198e-04, -5.6132e-04,  6.8241e-04, -1.2462e-03,\n",
      "        -5.1054e-05,  9.6557e-04, -1.4900e-03,  9.8898e-04, -3.2236e-04,\n",
      "         1.1797e-03, -1.8502e-04,  1.8070e-03, -3.0763e-04, -1.2412e-03,\n",
      "        -6.8203e-04,  3.0133e-04,  7.6947e-04, -7.7757e-04, -3.6364e-04,\n",
      "         1.8159e-05, -1.1292e-03, -3.5341e-04,  1.2958e-03,  1.6069e-04,\n",
      "        -1.4673e-03,  1.1906e-03, -1.1319e-03,  8.8947e-04, -1.8985e-03,\n",
      "        -6.8101e-04])\n",
      "\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9998, 0.9999, 0.9994, 1.0001, 1.0009, 0.9999, 0.9980, 1.0005, 0.9974,\n",
      "        0.9989, 1.0000, 0.9994, 1.0001, 0.9992, 1.0004, 1.0010, 0.9998, 1.0010,\n",
      "        1.0019, 0.9998, 0.9995, 1.0013, 1.0004, 1.0007, 0.9998, 1.0011, 1.0022,\n",
      "        1.0020, 1.0026, 0.9989, 0.9998, 0.9999, 1.0010, 1.0004, 1.0001, 1.0003,\n",
      "        0.9986, 0.9987, 1.0012, 0.9998, 1.0004, 1.0010, 1.0026, 1.0004, 0.9976,\n",
      "        0.9981, 1.0024, 0.9992, 0.9975, 0.9998, 1.0001, 1.0001, 0.9997, 0.9997,\n",
      "        0.9987, 1.0010, 1.0013, 1.0002, 1.0008, 0.9986, 0.9995, 0.9985, 1.0007,\n",
      "        1.0015, 1.0007, 0.9997, 1.0008, 0.9997, 1.0019, 1.0016, 1.0013, 1.0006,\n",
      "        0.9987, 1.0006, 1.0018, 1.0026, 1.0001, 1.0002, 1.0017, 0.9987, 0.9994,\n",
      "        1.0015, 0.9996, 0.9999, 0.9998, 1.0011, 1.0016, 1.0001, 0.9984, 1.0008,\n",
      "        0.9987, 0.9999, 0.9974, 1.0008, 0.9987, 1.0014, 0.9998, 1.0014, 0.9992,\n",
      "        1.0012, 1.0010, 1.0007, 0.9982, 0.9976, 1.0010, 1.0014, 0.9987, 1.0002,\n",
      "        0.9992, 0.9987, 0.9999, 0.9987, 1.0015, 1.0001, 1.0001, 0.9995, 1.0004,\n",
      "        1.0014, 1.0019, 0.9970, 1.0012, 1.0004, 1.0005, 1.0012, 0.9992, 0.9977,\n",
      "        1.0010, 0.9992, 0.9982, 1.0010, 1.0003, 1.0015, 0.9996, 1.0013, 0.9971,\n",
      "        0.9987, 0.9990, 0.9994, 0.9999, 0.9973, 1.0006, 1.0017, 0.9964, 0.9978,\n",
      "        0.9973, 0.9975, 1.0019, 1.0002, 1.0008, 1.0006, 1.0006, 1.0016, 0.9994,\n",
      "        0.9993, 1.0013, 1.0016, 0.9994, 0.9993, 0.9999, 1.0003, 1.0003, 0.9962,\n",
      "        1.0017, 1.0014, 1.0011, 1.0001, 0.9993, 1.0011, 1.0007, 0.9997, 1.0014,\n",
      "        0.9981, 0.9998, 1.0007, 1.0008, 0.9993, 1.0012, 1.0017, 0.9992, 0.9993,\n",
      "        1.0004, 1.0003, 1.0002, 1.0026, 0.9989, 0.9998, 1.0007, 0.9988, 1.0000,\n",
      "        1.0017, 0.9994, 1.0004, 0.9993, 1.0020, 0.9997, 1.0017, 0.9982, 1.0023,\n",
      "        1.0013, 1.0012, 0.9968, 0.9994, 0.9963, 0.9980, 0.9998, 0.9994, 1.0002,\n",
      "        0.9998, 0.9978, 0.9987, 0.9991, 1.0005, 0.9981, 1.0004, 0.9998, 1.0001,\n",
      "        0.9984, 0.9992, 0.9991, 0.9992, 1.0004, 1.0006, 0.9987, 0.9991, 0.9982,\n",
      "        0.9982, 1.0003, 1.0009, 0.9987, 1.0012, 1.0001, 0.9999, 1.0002, 1.0010,\n",
      "        1.0018, 0.9995, 0.9992, 1.0002, 0.9996, 0.9988, 1.0018, 0.9984, 0.9972,\n",
      "        0.9994, 0.9995, 0.9985, 1.0002, 0.9960, 1.0004, 0.9997, 1.0016, 0.9978,\n",
      "        0.9994, 0.9999, 1.0013, 1.0015])\n",
      "\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias:\n",
      "\n",
      "tensor([ 1.6670e-04, -7.6766e-04, -2.6182e-04,  3.7043e-04,  5.2619e-04,\n",
      "         1.0315e-03, -4.4975e-05,  1.2842e-03,  5.7214e-04, -2.9683e-04,\n",
      "        -8.4966e-04,  1.9403e-04, -2.9417e-04,  4.2985e-04,  3.4180e-04,\n",
      "        -1.3678e-03, -1.8351e-03,  1.1210e-03, -8.0476e-04,  4.7557e-04,\n",
      "        -7.5092e-04, -8.1233e-04, -8.6887e-04,  1.9343e-03,  9.4964e-04,\n",
      "        -1.4261e-05,  1.2836e-03, -1.6264e-04,  1.3223e-03,  6.7706e-04,\n",
      "         4.8834e-05,  1.0597e-04,  4.2209e-04, -1.2925e-04, -1.7026e-05,\n",
      "         1.1741e-03, -1.3613e-03,  1.0050e-04, -2.0091e-03,  7.6137e-05,\n",
      "        -5.0652e-04,  2.0377e-03,  1.8760e-03, -8.9188e-04,  1.7621e-04,\n",
      "         7.8468e-04,  1.4179e-03, -1.1871e-04,  6.5190e-04,  8.4985e-04,\n",
      "        -4.7039e-04,  5.7942e-04, -1.9661e-04, -2.0534e-04, -4.5525e-04,\n",
      "        -1.7709e-03,  6.7023e-04, -1.3003e-03,  4.2072e-05, -2.1100e-04,\n",
      "        -1.0613e-04, -7.3336e-04, -1.9268e-03, -1.7382e-03,  8.2484e-04,\n",
      "         7.9704e-04,  1.0297e-03,  1.6176e-03,  1.1322e-03, -1.3461e-03,\n",
      "        -3.5655e-04, -1.0801e-03, -4.0396e-04, -3.7448e-04,  1.1330e-04,\n",
      "        -7.3187e-04,  1.3717e-03, -1.2194e-03,  1.2292e-03,  2.6300e-04,\n",
      "         9.8495e-04,  1.1185e-03,  2.0872e-04, -1.0882e-03,  1.3171e-03,\n",
      "         1.5402e-03, -7.0375e-04, -9.1327e-04, -5.0841e-04, -5.5305e-04,\n",
      "         7.4572e-04,  1.0510e-03, -1.1625e-03, -2.3026e-04,  5.7267e-04,\n",
      "        -1.3086e-03,  3.9477e-04, -5.0226e-04, -6.5229e-04, -6.9602e-04,\n",
      "        -1.3776e-03, -1.0839e-03, -6.6801e-04, -7.9671e-04,  1.4924e-03,\n",
      "         1.0633e-04,  1.3916e-04, -1.5040e-03, -2.1981e-04,  6.6000e-04,\n",
      "         1.8391e-04,  4.9969e-04,  9.8083e-04,  7.5520e-04,  1.1881e-03,\n",
      "        -8.4272e-04, -1.3068e-03, -4.5008e-05, -1.1526e-03, -3.0466e-05,\n",
      "        -3.2803e-04, -8.6321e-04, -5.3207e-04,  1.1822e-03,  2.1605e-04,\n",
      "        -4.7333e-04, -8.9551e-04, -1.4307e-03,  9.9935e-04, -2.2308e-04,\n",
      "         4.0907e-04,  2.6608e-04,  7.9425e-05, -1.8382e-03,  1.0719e-03,\n",
      "         3.4942e-04,  8.9874e-04, -7.1786e-04,  3.4894e-04, -1.6656e-04,\n",
      "         1.2281e-03,  4.4737e-04,  6.4032e-04, -7.1259e-04,  1.7074e-04,\n",
      "        -2.0916e-04,  2.4223e-03, -2.4509e-04, -6.1104e-04,  1.6222e-03,\n",
      "        -4.5170e-04,  5.8131e-04, -8.3769e-04,  1.8149e-03,  1.3866e-03,\n",
      "        -5.9059e-04, -9.8070e-04, -5.2464e-04, -1.0430e-04, -6.9429e-04,\n",
      "         4.4559e-04,  9.8347e-04,  7.0845e-04,  4.7221e-04, -1.1564e-03,\n",
      "        -8.4293e-04,  9.3224e-04, -4.6508e-04, -1.2532e-03, -3.8633e-04,\n",
      "         8.2071e-04, -9.0245e-05,  9.2704e-05, -2.6844e-04, -7.9807e-04,\n",
      "         4.0776e-04,  1.8792e-03,  2.0167e-03,  5.6153e-04,  1.2057e-04,\n",
      "        -9.7529e-04,  4.9765e-04, -1.8814e-03,  2.1001e-03,  1.8991e-04,\n",
      "        -1.4865e-03, -2.2640e-04, -2.0726e-05,  1.2402e-04, -7.1213e-04,\n",
      "         8.9017e-04, -5.1527e-04,  1.1027e-03,  1.0158e-04,  1.8082e-03,\n",
      "         1.2177e-03,  4.9188e-04, -8.0891e-04,  1.1980e-03,  3.1806e-04,\n",
      "         1.0666e-03, -4.3621e-04, -4.2080e-04, -5.7435e-05, -8.1240e-04,\n",
      "         1.0691e-05,  2.7401e-04,  7.9891e-04,  8.6551e-04,  1.2737e-04,\n",
      "        -7.7162e-05, -4.4958e-04, -3.6027e-04, -1.0567e-05, -6.7283e-04,\n",
      "         2.0761e-05,  1.1968e-03, -2.1780e-04, -1.3125e-03, -7.1330e-04,\n",
      "        -1.0328e-03, -1.3098e-03, -1.0106e-03,  2.4761e-06,  1.3473e-03,\n",
      "        -4.3828e-04, -3.2606e-04, -4.1457e-04,  9.1489e-04, -2.3679e-04,\n",
      "        -7.7647e-04,  6.1432e-04, -1.4858e-03,  8.2813e-04, -4.7860e-04,\n",
      "         1.3877e-03,  1.7785e-04,  1.2971e-03, -2.2316e-04, -1.4578e-03,\n",
      "         3.5708e-04, -4.1590e-04, -1.3144e-04, -9.4975e-04, -1.0851e-04,\n",
      "         8.5313e-04, -1.5217e-03, -1.2115e-03,  1.2346e-03, -3.9586e-04,\n",
      "        -1.0655e-03,  1.7384e-03, -7.2815e-04,  4.4659e-05, -1.5666e-03,\n",
      "        -8.9470e-04])\n",
      "\n",
      "bert.encoder.layer.2.intermediate.dense.weight:\n",
      "\n",
      "tensor([[ 1.4313e-02,  1.8231e-02, -1.5721e-02,  ...,  1.8128e-02,\n",
      "         -1.7715e-03,  1.9258e-02],\n",
      "        [-5.5669e-03, -2.5717e-03, -5.8197e-03,  ..., -3.1985e-02,\n",
      "         -4.0337e-03, -2.2705e-02],\n",
      "        [ 2.0189e-02,  8.3448e-03, -1.8100e-02,  ...,  7.3431e-03,\n",
      "          2.4955e-02, -1.2679e-02],\n",
      "        ...,\n",
      "        [ 4.8462e-03,  9.5041e-03,  1.1114e-02,  ...,  2.5850e-02,\n",
      "         -4.9313e-03, -3.1550e-02],\n",
      "        [-2.5888e-02, -2.7607e-02,  4.2028e-03,  ..., -2.6977e-02,\n",
      "          6.0864e-05, -9.5503e-03],\n",
      "        [ 1.7566e-02,  1.3355e-02,  2.3783e-02,  ...,  1.8842e-04,\n",
      "         -2.7196e-02,  9.4987e-03]])\n",
      "\n",
      "bert.encoder.layer.2.intermediate.dense.bias:\n",
      "\n",
      "tensor([ 0.0008,  0.0008, -0.0001,  ...,  0.0003,  0.0007,  0.0008])\n",
      "\n",
      "bert.encoder.layer.2.output.dense.weight:\n",
      "\n",
      "tensor([[ 0.0043, -0.0453,  0.0221,  ..., -0.0238, -0.0426, -0.0159],\n",
      "        [ 0.0385,  0.0343, -0.0200,  ...,  0.0148,  0.0227,  0.0030],\n",
      "        [ 0.0016, -0.0302, -0.0177,  ...,  0.0064,  0.0316,  0.0129],\n",
      "        ...,\n",
      "        [ 0.0100, -0.0065, -0.0016,  ..., -0.0127,  0.0046,  0.0099],\n",
      "        [ 0.0186, -0.0234,  0.0006,  ..., -0.0196, -0.0187, -0.0030],\n",
      "        [-0.0332,  0.0102,  0.0321,  ...,  0.0166,  0.0224,  0.0032]])\n",
      "\n",
      "bert.encoder.layer.2.output.dense.bias:\n",
      "\n",
      "tensor([ 1.3085e-04, -7.3477e-04, -5.8990e-04,  1.1831e-04,  9.1858e-04,\n",
      "         8.9919e-04,  3.8564e-04,  1.2317e-03,  2.6570e-04, -6.6775e-05,\n",
      "        -9.2514e-04, -3.5927e-05, -3.3878e-04,  5.4696e-04, -4.8851e-04,\n",
      "        -1.0126e-03, -1.4225e-03,  3.8949e-04, -7.1326e-04,  6.7117e-04,\n",
      "        -1.0994e-03, -2.5949e-04, -5.8196e-04,  1.4885e-03,  2.0921e-04,\n",
      "        -4.2255e-04,  2.1052e-03,  4.1431e-05,  1.1305e-03,  8.4915e-04,\n",
      "         2.0770e-04,  2.1889e-04,  4.9905e-04, -6.6217e-04,  1.3764e-04,\n",
      "         7.5613e-04, -1.9716e-03,  1.7110e-03, -2.1137e-03, -1.9893e-04,\n",
      "         6.7534e-05,  1.5880e-03,  1.9398e-03, -1.0102e-03,  3.2555e-04,\n",
      "         1.1448e-03,  9.9367e-04,  1.9050e-04,  1.2284e-04,  8.4514e-04,\n",
      "        -9.9105e-05,  5.0290e-04, -5.7375e-04, -6.8838e-04, -7.0152e-04,\n",
      "        -6.5218e-04, -4.4001e-04, -1.0904e-03, -3.6673e-04, -1.8685e-04,\n",
      "         7.8513e-04, -6.8639e-05, -1.0634e-03, -1.0847e-03,  7.6872e-04,\n",
      "         7.8272e-04,  1.1185e-03,  1.1986e-03,  8.8973e-04, -9.8799e-04,\n",
      "         4.7673e-05, -1.1176e-03,  2.4140e-04,  1.1806e-04, -1.0758e-04,\n",
      "        -1.3138e-03,  1.0024e-03, -7.3080e-04,  1.2744e-03,  7.0729e-04,\n",
      "         1.2421e-03,  2.4152e-04,  4.3816e-04, -1.1285e-03,  1.6172e-03,\n",
      "         7.4549e-04, -1.7407e-04, -1.0655e-03,  9.2730e-05, -2.2875e-04,\n",
      "         8.6560e-04,  1.4098e-03, -1.4830e-03,  4.3959e-04,  7.5202e-04,\n",
      "        -1.6579e-03, -4.9425e-04, -6.9099e-04,  2.0449e-04, -9.4929e-04,\n",
      "        -1.1380e-03, -2.3150e-03, -8.6595e-04, -4.5827e-04,  9.3943e-04,\n",
      "        -7.9191e-04,  1.8777e-05, -1.2449e-03, -1.0125e-03,  1.0937e-03,\n",
      "         5.7971e-06,  4.5088e-04,  9.2727e-04,  7.0966e-04,  1.7369e-03,\n",
      "        -4.4382e-04, -1.0723e-03,  1.0423e-03, -1.2098e-03, -3.0571e-04,\n",
      "        -5.9556e-04, -1.1115e-03, -4.5196e-04,  9.7073e-04, -1.0248e-04,\n",
      "        -2.0686e-03, -5.3185e-04, -1.0553e-03,  8.9597e-04, -1.5995e-04,\n",
      "         1.7883e-04, -1.4185e-04,  5.8583e-04, -1.5898e-03,  9.6115e-04,\n",
      "        -4.2675e-04,  2.3153e-04, -2.5134e-04,  8.9276e-05, -1.6575e-04,\n",
      "         1.4734e-03, -6.3952e-04,  1.6583e-03, -2.8364e-04, -7.9600e-04,\n",
      "        -1.8784e-04,  1.2509e-03,  2.4850e-04, -8.1228e-04, -7.0240e-04,\n",
      "        -8.3693e-04,  1.1791e-03, -1.2929e-03,  1.4716e-03,  9.2652e-04,\n",
      "        -4.3225e-04, -1.6053e-03, -1.6133e-04,  4.1370e-04, -1.7964e-04,\n",
      "         6.6335e-04,  9.3458e-04,  9.4773e-04,  4.8912e-04, -1.5445e-03,\n",
      "        -1.3643e-03,  4.6422e-04, -3.0564e-04, -1.3715e-03, -3.1807e-04,\n",
      "         1.5052e-03, -8.9013e-04, -1.1946e-03, -7.0775e-04, -1.2064e-03,\n",
      "         5.0115e-04,  1.8257e-03,  2.0306e-03, -1.1293e-04,  8.1243e-05,\n",
      "        -8.6873e-04,  5.4289e-04, -1.4126e-03,  1.7567e-03,  1.4276e-04,\n",
      "        -1.2845e-03, -7.4258e-04, -2.8392e-04,  2.4308e-04, -5.6397e-04,\n",
      "         1.2918e-03, -9.1993e-04,  5.0325e-04, -6.5146e-04,  1.4541e-03,\n",
      "         1.5911e-03, -3.1059e-04, -5.6051e-04,  4.8580e-04,  2.4839e-04,\n",
      "         5.0119e-04,  4.9798e-04, -2.1229e-04,  1.4237e-04, -1.4105e-03,\n",
      "        -6.4292e-06,  1.0192e-03,  8.6282e-04,  5.7543e-04, -9.1740e-04,\n",
      "         5.6873e-05, -6.7668e-04, -8.5367e-04,  7.1117e-04, -8.2151e-04,\n",
      "         2.0830e-04,  4.7953e-04, -1.5101e-04, -2.3694e-04, -8.0465e-04,\n",
      "        -7.9259e-04, -1.3710e-03, -5.8370e-04,  2.4589e-04,  1.9966e-03,\n",
      "        -6.2977e-04, -7.8809e-04, -6.7358e-04,  1.2143e-03,  7.0114e-04,\n",
      "        -1.5672e-03,  2.1180e-04, -1.9746e-03,  9.3527e-04, -5.6373e-04,\n",
      "         1.5350e-03,  5.8250e-04,  1.2428e-03, -5.5770e-05, -2.0373e-03,\n",
      "         2.7551e-04, -5.5859e-04,  1.3013e-04, -1.1540e-03, -2.5585e-04,\n",
      "        -1.9592e-04, -9.0696e-04, -3.2110e-04,  2.6471e-04, -2.8218e-04,\n",
      "        -1.3078e-03,  1.0525e-03, -5.4402e-04,  1.9008e-05, -1.1559e-03,\n",
      "        -8.2103e-04])\n",
      "\n",
      "bert.encoder.layer.2.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9997, 0.9999, 0.9999, 1.0000, 1.0003, 0.9997, 0.9981, 1.0006, 0.9973,\n",
      "        0.9990, 1.0004, 0.9992, 1.0001, 0.9998, 1.0003, 1.0010, 0.9997, 1.0008,\n",
      "        1.0017, 0.9997, 0.9998, 1.0012, 1.0006, 1.0004, 0.9996, 1.0012, 1.0021,\n",
      "        1.0017, 1.0025, 0.9987, 0.9999, 1.0001, 1.0006, 1.0002, 1.0002, 1.0002,\n",
      "        0.9988, 0.9988, 1.0012, 0.9998, 1.0002, 1.0013, 1.0026, 1.0005, 0.9979,\n",
      "        0.9982, 1.0022, 0.9992, 0.9979, 0.9999, 1.0002, 1.0001, 0.9999, 0.9996,\n",
      "        0.9986, 1.0011, 1.0007, 0.9999, 1.0009, 0.9986, 0.9997, 0.9986, 1.0007,\n",
      "        1.0018, 1.0011, 0.9999, 1.0008, 0.9998, 1.0014, 1.0013, 1.0014, 1.0007,\n",
      "        0.9985, 1.0002, 1.0019, 1.0026, 1.0002, 1.0002, 1.0020, 0.9989, 0.9999,\n",
      "        1.0014, 0.9996, 0.9999, 0.9998, 1.0008, 1.0015, 1.0005, 0.9982, 1.0008,\n",
      "        0.9985, 1.0000, 0.9971, 1.0012, 0.9991, 1.0019, 0.9995, 1.0012, 0.9991,\n",
      "        1.0012, 1.0009, 1.0007, 0.9980, 0.9976, 1.0007, 1.0009, 0.9987, 1.0003,\n",
      "        0.9991, 0.9984, 0.9999, 0.9990, 1.0014, 1.0005, 0.9998, 0.9993, 1.0004,\n",
      "        1.0012, 1.0018, 0.9972, 1.0012, 1.0004, 1.0013, 1.0011, 0.9992, 0.9979,\n",
      "        1.0007, 0.9989, 0.9986, 1.0010, 1.0000, 1.0013, 0.9998, 1.0010, 0.9970,\n",
      "        0.9987, 0.9994, 0.9993, 1.0000, 0.9976, 1.0005, 1.0017, 0.9971, 0.9982,\n",
      "        0.9973, 0.9974, 1.0016, 0.9998, 1.0008, 0.9998, 1.0009, 1.0012, 0.9993,\n",
      "        1.0000, 1.0011, 1.0010, 0.9993, 0.9991, 1.0001, 1.0002, 1.0001, 0.9962,\n",
      "        1.0015, 1.0011, 1.0013, 1.0002, 0.9994, 1.0008, 1.0004, 0.9993, 1.0014,\n",
      "        0.9995, 0.9996, 1.0003, 1.0005, 0.9998, 1.0014, 1.0019, 0.9991, 0.9991,\n",
      "        1.0004, 1.0005, 0.9996, 1.0020, 0.9988, 0.9998, 1.0005, 0.9990, 0.9991,\n",
      "        1.0016, 0.9992, 1.0002, 0.9995, 1.0020, 0.9995, 1.0019, 0.9985, 1.0021,\n",
      "        1.0013, 1.0016, 0.9971, 0.9998, 0.9962, 0.9988, 1.0000, 0.9990, 0.9994,\n",
      "        0.9997, 0.9976, 0.9989, 0.9990, 1.0003, 0.9978, 1.0002, 1.0000, 0.9998,\n",
      "        0.9988, 0.9992, 0.9984, 0.9997, 1.0006, 1.0007, 0.9988, 0.9992, 0.9989,\n",
      "        0.9984, 1.0001, 1.0007, 0.9988, 1.0011, 0.9999, 0.9998, 1.0004, 1.0007,\n",
      "        1.0016, 0.9994, 0.9993, 1.0003, 1.0000, 0.9986, 1.0011, 0.9984, 0.9974,\n",
      "        0.9997, 0.9995, 0.9999, 1.0001, 0.9963, 1.0006, 0.9996, 1.0015, 0.9976,\n",
      "        0.9993, 0.9998, 1.0011, 1.0013])\n",
      "\n",
      "bert.encoder.layer.2.output.LayerNorm.bias:\n",
      "\n",
      "tensor([ 3.1787e-04, -6.8034e-04, -3.3818e-04,  3.7059e-04,  5.2767e-04,\n",
      "         8.6962e-04,  5.3692e-05,  1.2000e-03,  4.4534e-04, -2.7461e-04,\n",
      "        -6.9904e-04,  2.1811e-05, -4.2662e-04,  5.4294e-04,  2.3490e-04,\n",
      "        -1.2265e-03, -1.8435e-03,  9.5383e-04, -8.3158e-04,  3.5518e-04,\n",
      "        -1.0091e-03, -7.7309e-04, -7.4142e-04,  1.8003e-03,  1.1168e-03,\n",
      "        -2.7527e-04,  1.4991e-03, -1.5990e-06,  1.1544e-03,  6.0739e-04,\n",
      "         2.2092e-04,  7.1164e-05,  7.9310e-04,  1.4060e-05, -1.4234e-04,\n",
      "         1.0667e-03, -1.7238e-03,  2.6879e-04, -1.9279e-03,  2.6935e-04,\n",
      "        -5.0855e-04,  2.0154e-03,  1.8111e-03, -8.7475e-04, -1.0826e-04,\n",
      "         6.5410e-04,  1.2409e-03, -1.4429e-04,  7.3540e-04,  9.0273e-04,\n",
      "        -5.4471e-04,  5.5280e-04, -2.7818e-04, -3.0210e-04, -4.6833e-04,\n",
      "        -1.6570e-03,  2.3375e-04, -1.1537e-03,  5.0295e-05, -1.3249e-04,\n",
      "         3.3628e-05, -6.1888e-04, -1.8897e-03, -1.6818e-03,  8.6328e-04,\n",
      "         9.0468e-04,  9.8561e-04,  1.5962e-03,  1.1991e-03, -1.2356e-03,\n",
      "        -6.9468e-05, -1.0592e-03, -2.1255e-04, -4.1536e-04,  1.4633e-04,\n",
      "        -7.1830e-04,  1.4110e-03, -1.3001e-03,  1.3581e-03,  2.8963e-05,\n",
      "         9.3155e-04,  1.2957e-03,  1.6806e-04, -9.6392e-04,  1.2404e-03,\n",
      "         1.4682e-03, -1.1303e-03, -8.2677e-04, -4.7924e-04, -3.1027e-04,\n",
      "         5.0162e-04,  1.1140e-03, -1.2745e-03, -7.4832e-05,  5.7777e-04,\n",
      "        -1.3855e-03,  2.8250e-04, -5.8378e-04, -5.2685e-04, -6.1951e-04,\n",
      "        -1.1294e-03, -1.0032e-03, -7.5678e-04, -8.2496e-04,  1.3816e-03,\n",
      "         2.1078e-04,  2.8832e-05, -1.3090e-03, -1.8059e-04,  7.2469e-04,\n",
      "         1.0481e-04,  7.2224e-04,  1.0402e-03,  7.9277e-04,  8.5418e-04,\n",
      "        -1.0413e-03, -1.2829e-03,  4.7384e-04, -1.0837e-03,  1.2237e-04,\n",
      "        -5.0823e-04, -1.0172e-03, -6.9419e-04,  1.2353e-03,  2.9494e-04,\n",
      "        -2.5366e-04, -9.4179e-04, -1.1831e-03,  1.0937e-03, -1.4867e-04,\n",
      "         1.3444e-04,  3.2118e-04,  1.0069e-04, -1.5880e-03,  9.4601e-04,\n",
      "        -1.2618e-04,  6.2123e-04, -9.5941e-04,  9.7532e-05, -2.6288e-04,\n",
      "         1.1799e-03,  3.9750e-04,  7.3021e-04, -6.0288e-04,  1.4916e-04,\n",
      "        -2.8257e-04,  2.2425e-03, -8.3079e-05, -7.4992e-04,  1.4443e-03,\n",
      "        -2.2703e-04,  7.6446e-04, -5.0391e-04,  1.8842e-03,  1.3320e-03,\n",
      "        -7.0588e-04, -8.1840e-04, -5.6572e-04,  1.3445e-04, -4.8997e-04,\n",
      "         3.5077e-04,  8.6850e-04,  9.0916e-04,  9.8434e-05, -1.3330e-03,\n",
      "        -8.3655e-04,  5.6995e-04, -3.5643e-04, -1.1168e-03, -3.7034e-04,\n",
      "         8.7545e-04, -1.1380e-04,  2.6274e-04, -3.5463e-04, -5.9122e-04,\n",
      "         4.8914e-04,  1.9491e-03,  2.0771e-03,  4.6301e-04,  1.2445e-04,\n",
      "        -1.0862e-03,  3.9137e-04, -1.9562e-03,  1.8850e-03,  2.5665e-04,\n",
      "        -1.4103e-03, -1.8289e-04, -6.0485e-05, -1.5978e-04, -6.0266e-04,\n",
      "         1.1142e-03, -7.6008e-04,  1.0430e-03, -1.4545e-04,  1.7493e-03,\n",
      "         1.4409e-03,  2.9259e-04, -6.8691e-04,  9.1496e-04,  2.5714e-04,\n",
      "         1.0065e-03, -2.3474e-04, -3.7304e-04,  2.5872e-04, -1.0045e-03,\n",
      "        -1.3151e-04,  3.1206e-04,  4.1977e-04,  4.7360e-04, -1.0917e-04,\n",
      "         2.0951e-06, -4.4104e-04, -4.8243e-04, -9.6970e-05, -2.9693e-04,\n",
      "        -2.5548e-04,  1.1501e-03,  1.6844e-05, -1.3720e-03, -9.8262e-04,\n",
      "        -1.1532e-03, -1.4108e-03, -7.9262e-04, -1.3480e-04,  1.6447e-03,\n",
      "        -5.3918e-04, -4.3860e-04, -4.7026e-04,  8.4864e-04,  5.1093e-04,\n",
      "        -5.9002e-04,  5.9448e-04, -1.4105e-03,  9.0277e-04, -4.2955e-04,\n",
      "         1.1289e-03,  3.0090e-04,  1.2949e-03, -2.2015e-04, -1.4118e-03,\n",
      "         5.6313e-05, -5.4326e-04, -4.2702e-06, -1.1180e-03,  3.8028e-05,\n",
      "         8.1797e-04, -1.4099e-03, -9.6119e-04,  1.0596e-03, -1.6382e-04,\n",
      "        -1.0614e-03,  1.8146e-03, -6.8350e-04, -1.7038e-04, -1.4429e-03,\n",
      "        -7.5577e-04])\n",
      "\n",
      "bert.encoder.layer.3.attention.self.query.weight:\n",
      "\n",
      "tensor([[ 0.0239,  0.0218,  0.0173,  ..., -0.0420, -0.0076,  0.0082],\n",
      "        [ 0.0191, -0.0111,  0.0298,  ..., -0.0161, -0.0449, -0.0124],\n",
      "        [ 0.0159,  0.0237,  0.0228,  ..., -0.0259,  0.0025,  0.0375],\n",
      "        ...,\n",
      "        [-0.0121,  0.0046, -0.0263,  ...,  0.0001,  0.0127,  0.0075],\n",
      "        [-0.0211,  0.0073, -0.0096,  ..., -0.0151, -0.0361, -0.0179],\n",
      "        [-0.0135,  0.0201,  0.0101,  ..., -0.0099,  0.0075, -0.0164]])\n",
      "\n",
      "bert.encoder.layer.3.attention.self.query.bias:\n",
      "\n",
      "tensor([-2.3639e-03, -1.6425e-03,  2.4228e-03,  9.7170e-04, -1.9763e-03,\n",
      "        -1.9638e-03,  2.1503e-03,  1.2400e-03, -3.1990e-03,  1.4412e-03,\n",
      "         1.8464e-03,  1.3899e-03,  2.2226e-03,  9.2892e-04,  1.9405e-03,\n",
      "        -1.1812e-04, -9.7413e-04,  2.3728e-03,  1.1086e-03,  9.3505e-04,\n",
      "        -1.8935e-03,  2.2837e-03, -1.6872e-03, -1.0543e-03, -7.4335e-04,\n",
      "        -1.1083e-03, -1.5107e-03, -1.9491e-04,  7.8281e-04, -9.2151e-04,\n",
      "        -9.4437e-04,  1.9980e-03, -1.4930e-04, -1.3389e-03, -1.6280e-04,\n",
      "        -2.7185e-03,  2.2537e-03,  6.8215e-04, -2.3371e-03,  3.8521e-06,\n",
      "         1.5040e-04, -1.1677e-03, -9.7662e-04,  2.2456e-05, -3.2075e-05,\n",
      "         1.6725e-04, -1.7958e-04, -2.5360e-03,  1.0346e-04, -2.7173e-04,\n",
      "         8.7939e-05, -1.9852e-03,  1.5827e-03, -2.6428e-03, -1.5984e-03,\n",
      "         1.7192e-05, -2.6919e-04, -3.4322e-04,  3.4080e-04, -1.2991e-03,\n",
      "        -1.2290e-03, -2.7393e-04, -2.3901e-03,  8.4227e-04, -7.9997e-04,\n",
      "        -2.4725e-03, -4.5237e-05, -3.8279e-04, -5.1417e-04, -1.2912e-03,\n",
      "        -1.3501e-03, -1.6179e-03, -5.1727e-04,  4.3294e-04, -2.7383e-03,\n",
      "        -8.5882e-04, -3.1849e-04,  1.4477e-03,  2.4991e-03,  1.2147e-03,\n",
      "         1.1004e-03, -1.3610e-03,  4.7261e-05, -8.6583e-04,  1.2452e-03,\n",
      "         2.2374e-04,  4.3038e-04, -1.1310e-03,  1.6286e-04,  1.5084e-03,\n",
      "        -5.4221e-04, -8.9741e-04, -1.8075e-03, -1.0043e-04, -7.2104e-04,\n",
      "        -7.2218e-04,  1.7474e-03,  1.1812e-03,  1.7738e-03,  2.5787e-04,\n",
      "        -8.1839e-04, -2.4770e-04, -1.1838e-04,  9.0113e-04,  1.5355e-03,\n",
      "         8.0562e-04,  9.6662e-04, -3.8430e-04, -1.8723e-03,  1.4585e-03,\n",
      "         2.4513e-03, -8.4638e-04,  5.9910e-04, -2.6548e-04, -1.5450e-03,\n",
      "        -1.1233e-04,  1.8051e-03, -2.3129e-03,  1.5002e-03, -7.0980e-04,\n",
      "        -3.4503e-03,  1.7120e-03, -3.4065e-04, -7.1225e-04,  1.5568e-03,\n",
      "        -5.3239e-04, -9.8298e-04, -9.7030e-04,  2.4675e-03, -3.0956e-03,\n",
      "         1.0753e-03,  1.5516e-03,  3.1670e-04,  1.6234e-03, -8.5618e-04,\n",
      "        -6.4283e-04,  1.7967e-03,  1.6379e-03,  9.4574e-04, -2.0991e-03,\n",
      "         1.4277e-03, -7.0293e-04,  4.4313e-04,  1.6214e-03, -1.4220e-03,\n",
      "        -1.2936e-03, -4.1182e-04, -9.2634e-04,  1.5090e-03, -2.2175e-03,\n",
      "         2.7106e-04, -2.1135e-03, -7.7137e-04,  1.6339e-03, -1.7130e-03,\n",
      "        -2.0733e-03, -1.4903e-03, -2.8109e-04,  2.3013e-04,  1.2595e-03,\n",
      "        -1.6121e-03, -2.4999e-04,  1.5852e-03,  5.1445e-04,  1.1009e-03,\n",
      "        -1.1309e-03,  2.1062e-05, -1.2719e-03, -1.4892e-03, -1.5448e-05,\n",
      "         1.9417e-03, -3.8731e-04, -1.5085e-03, -1.5699e-04, -6.2944e-04,\n",
      "         1.9350e-03,  2.7838e-03, -9.0174e-04,  8.9753e-04, -1.9046e-03,\n",
      "         1.4458e-03,  3.0735e-04, -7.2701e-05,  4.2218e-05,  3.6701e-03,\n",
      "        -2.0075e-04, -2.1439e-03, -3.1490e-04,  1.4602e-03, -1.7256e-03,\n",
      "         2.7813e-03, -8.6971e-04,  1.6072e-03, -1.0644e-03,  2.5111e-03,\n",
      "        -2.6814e-03, -8.3739e-04, -4.4558e-04, -8.1252e-04, -1.1871e-03,\n",
      "         9.2662e-04,  1.7786e-03,  7.2663e-04,  1.2225e-03,  4.1104e-04,\n",
      "         5.5420e-04,  5.5462e-04, -1.6980e-03, -4.4567e-04,  3.0442e-04,\n",
      "        -3.0767e-04,  2.7802e-03, -2.5800e-03,  2.9155e-04,  1.1271e-04,\n",
      "         1.1153e-03,  3.6730e-05,  1.4267e-03, -1.9849e-03,  9.8016e-04,\n",
      "         4.3197e-04,  2.1436e-03,  6.8243e-04, -1.2812e-04,  9.3884e-05,\n",
      "         8.8546e-04,  2.5587e-03, -3.9869e-06, -2.5712e-03,  1.9001e-03,\n",
      "        -1.6050e-03,  5.6272e-04,  1.9898e-03, -1.6394e-03,  8.4541e-04,\n",
      "        -7.7874e-04,  8.2929e-04, -8.8530e-04,  1.9859e-03,  1.9697e-03,\n",
      "        -4.8526e-04, -1.7153e-03, -1.9717e-03, -2.2657e-03, -9.7637e-04,\n",
      "         5.5831e-05, -4.2048e-04,  4.0922e-04,  1.0696e-03,  8.2125e-04,\n",
      "         6.1563e-04,  1.7504e-03,  1.7255e-03, -2.7633e-03,  7.1742e-04,\n",
      "         1.4237e-03])\n",
      "\n",
      "bert.encoder.layer.3.attention.self.key.weight:\n",
      "\n",
      "tensor([[-0.0040, -0.0068, -0.0139,  ...,  0.0055,  0.0012,  0.0351],\n",
      "        [-0.0246, -0.0060,  0.0251,  ..., -0.0377,  0.0068, -0.0088],\n",
      "        [ 0.0251,  0.0067,  0.0182,  ..., -0.0123, -0.0111,  0.0027],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0177, -0.0008,  ...,  0.0121,  0.0015,  0.0071],\n",
      "        [-0.0069, -0.0158, -0.0038,  ..., -0.0033, -0.0002, -0.0147],\n",
      "        [ 0.0094,  0.0187,  0.0173,  ..., -0.0026,  0.0346, -0.0041]])\n",
      "\n",
      "bert.encoder.layer.3.attention.self.key.bias:\n",
      "\n",
      "tensor([ 1.6505e-09,  6.3589e-09, -1.1220e-08, -1.2128e-08,  3.0204e-09,\n",
      "         8.7534e-09, -1.4318e-08,  5.8778e-09,  1.4417e-08, -7.0074e-09,\n",
      "        -7.9148e-09, -4.5508e-10, -3.1292e-09, -1.6840e-09,  2.4899e-09,\n",
      "         7.3785e-10, -1.0809e-08, -7.7778e-09, -6.2816e-09, -9.9472e-09,\n",
      "         8.9201e-09, -8.4926e-09,  6.0311e-09, -2.4588e-09, -2.6664e-09,\n",
      "         2.6333e-09,  3.8866e-10,  8.3886e-09, -1.3927e-09, -9.0164e-10,\n",
      "         6.7360e-09, -1.0777e-08,  4.6342e-10,  1.2716e-09,  5.9316e-09,\n",
      "         1.0338e-08, -4.6241e-09, -7.0508e-09,  9.1618e-09, -5.0684e-09,\n",
      "        -8.3205e-09,  1.2943e-08,  3.6689e-09,  4.1687e-10, -8.5618e-09,\n",
      "         3.8163e-09,  8.9570e-09,  7.0815e-09,  2.3017e-09, -1.0531e-09,\n",
      "        -3.0753e-09,  4.9994e-09, -1.0792e-10,  1.7749e-08,  3.1439e-09,\n",
      "         2.6876e-09,  7.2654e-09,  2.5671e-09,  2.0471e-09,  8.1107e-09,\n",
      "        -5.2715e-09, -1.7375e-09,  6.7172e-09, -6.9201e-09, -4.9934e-09,\n",
      "        -6.6385e-09,  4.8156e-09, -6.6328e-09, -1.2591e-08, -1.8485e-08,\n",
      "         5.2343e-09, -1.5302e-08, -7.8161e-09,  6.5367e-09, -9.5190e-09,\n",
      "         9.0690e-09,  9.1984e-09,  1.6764e-08,  2.1497e-08, -1.4235e-09,\n",
      "        -1.1451e-08,  2.9622e-09,  6.9779e-09, -5.5077e-09,  3.1955e-09,\n",
      "        -4.1819e-10,  4.8654e-09,  6.3368e-09,  8.4928e-09, -5.6381e-09,\n",
      "         3.8859e-09, -6.2565e-10, -5.2813e-09, -4.3783e-09, -9.9576e-09,\n",
      "        -1.0295e-08,  4.4259e-09,  5.5426e-09,  8.2938e-09,  1.4370e-09,\n",
      "        -4.8669e-09, -1.1462e-09,  3.0413e-09,  3.6456e-09, -6.2841e-09,\n",
      "         7.6418e-09, -2.6843e-09, -2.3911e-09, -9.6409e-09,  1.3224e-08,\n",
      "         1.5091e-08, -5.8424e-09,  6.3794e-09,  4.5289e-09, -5.9318e-09,\n",
      "        -7.1482e-09,  1.9025e-08, -1.6545e-08,  1.3814e-08,  3.7739e-09,\n",
      "        -2.2229e-08,  1.5970e-08,  7.9193e-09, -1.0969e-09,  1.1973e-08,\n",
      "        -9.4860e-09, -9.4965e-09, -3.1454e-09, -4.3649e-09, -2.0378e-09,\n",
      "        -3.7996e-10, -6.2984e-09, -5.2073e-09,  3.8568e-09, -2.6277e-09,\n",
      "         1.6897e-09,  4.6961e-10, -1.4090e-09, -2.7780e-09,  8.6812e-09,\n",
      "        -1.1394e-08, -4.2297e-09, -2.3467e-09,  2.1443e-09, -5.4920e-10,\n",
      "        -3.7596e-09, -2.5947e-09,  7.2728e-09, -5.2175e-09,  2.7465e-09,\n",
      "         4.2186e-09,  5.3470e-09,  5.0360e-09, -2.4973e-09, -2.5489e-09,\n",
      "         2.8754e-09,  5.3941e-09,  2.4729e-09, -3.3798e-09, -4.1324e-10,\n",
      "         3.0482e-09, -2.0482e-09, -2.0229e-09,  8.9536e-10, -9.2949e-09,\n",
      "        -3.3249e-09, -4.7113e-09, -2.1953e-09,  2.6473e-09, -5.0890e-10,\n",
      "        -2.5037e-10, -3.0474e-09, -2.3803e-09,  4.5174e-09, -2.2006e-09,\n",
      "        -1.4678e-09, -4.2312e-09, -5.5006e-09, -2.8857e-09,  1.1405e-09,\n",
      "         2.9003e-09, -1.1376e-08, -3.3383e-09,  3.4202e-09, -6.8728e-09,\n",
      "         1.2245e-09, -3.5225e-09,  2.4780e-09, -6.6799e-10,  3.8343e-09,\n",
      "        -6.4901e-09,  4.7639e-09,  2.1707e-09,  4.6356e-09,  5.7858e-09,\n",
      "        -8.4965e-11, -7.1630e-09, -5.0774e-09,  1.2881e-09, -7.8413e-09,\n",
      "        -4.5746e-09,  4.0271e-09,  1.2877e-08,  6.1101e-09, -7.2916e-09,\n",
      "        -4.7090e-09,  4.1091e-09, -1.5882e-08, -2.9066e-09, -4.4246e-09,\n",
      "         4.6334e-09,  2.9465e-09, -1.6292e-09, -2.2196e-09,  6.7827e-09,\n",
      "        -1.0167e-08,  1.3115e-09,  2.4309e-09,  2.2271e-10,  9.2467e-10,\n",
      "        -4.2470e-09, -1.5528e-09,  9.2250e-11, -2.5487e-09, -1.6174e-09,\n",
      "         7.1783e-09, -1.4244e-09,  1.0695e-08,  5.6606e-09,  8.4143e-09,\n",
      "         7.7221e-09,  6.9556e-10, -1.1702e-09, -6.2435e-11,  2.2889e-09,\n",
      "        -8.1523e-10,  1.0051e-09, -2.6729e-09,  2.7125e-09, -1.0158e-09,\n",
      "        -1.2480e-09,  2.0811e-10, -3.0355e-09, -1.1175e-08, -2.2130e-09,\n",
      "         3.3539e-09, -3.2158e-09,  9.3922e-09,  6.6670e-09, -4.9645e-09,\n",
      "        -9.7951e-09,  4.1146e-09, -7.2001e-09, -7.5849e-10,  6.3497e-09,\n",
      "        -1.8820e-09])\n",
      "\n",
      "bert.encoder.layer.3.attention.self.value.weight:\n",
      "\n",
      "tensor([[ 0.0268, -0.0228, -0.0069,  ...,  0.0203, -0.0124, -0.0245],\n",
      "        [-0.0343,  0.0266,  0.0300,  ...,  0.0224,  0.0133, -0.0204],\n",
      "        [ 0.0120, -0.0065,  0.0157,  ...,  0.0042,  0.0066, -0.0247],\n",
      "        ...,\n",
      "        [-0.0007,  0.0218, -0.0082,  ..., -0.0021, -0.0179, -0.0117],\n",
      "        [-0.0040,  0.0183,  0.0034,  ...,  0.0305,  0.0026,  0.0304],\n",
      "        [-0.0253, -0.0147,  0.0123,  ...,  0.0165, -0.0034, -0.0235]])\n",
      "\n",
      "bert.encoder.layer.3.attention.self.value.bias:\n",
      "\n",
      "tensor([-2.2327e-04,  8.4631e-04,  6.1820e-04,  1.7556e-03, -9.8153e-04,\n",
      "         2.3991e-05,  1.3872e-03,  5.7561e-04, -1.4137e-03, -4.1565e-04,\n",
      "         2.0705e-04, -6.8518e-04, -2.9389e-04,  9.8749e-05,  3.2397e-04,\n",
      "        -1.0138e-04,  1.8900e-03,  8.8726e-04,  1.0729e-03, -5.0239e-04,\n",
      "         8.5164e-04, -1.6012e-03,  9.1135e-04,  7.0709e-05,  1.7593e-04,\n",
      "        -3.3553e-04, -7.1726e-05,  4.6149e-04,  1.3933e-03,  2.6975e-04,\n",
      "        -3.7260e-04, -1.0715e-03,  3.2501e-04, -1.0167e-04, -1.3308e-03,\n",
      "        -8.2784e-04, -2.1489e-04, -1.1652e-03, -1.1432e-03,  8.8128e-04,\n",
      "         9.9449e-05,  1.0558e-03,  5.8928e-04, -1.6523e-03, -7.8581e-05,\n",
      "         5.9759e-04,  6.4298e-04, -9.0221e-04, -4.3020e-05,  1.7632e-03,\n",
      "        -8.5088e-04,  1.0778e-03, -1.3274e-04,  8.9386e-04,  1.7176e-04,\n",
      "         1.3947e-03, -1.0015e-03,  2.5689e-04,  2.0112e-04,  1.0660e-04,\n",
      "         1.5244e-03, -1.3464e-03,  9.8226e-04, -1.8570e-03,  8.4453e-04,\n",
      "         1.3467e-04,  6.7368e-04, -1.2555e-03, -6.9978e-04,  6.3553e-04,\n",
      "        -5.7598e-04,  1.0715e-03,  1.5533e-03,  1.3006e-04, -8.0567e-04,\n",
      "        -3.7812e-04, -1.3574e-04,  1.0097e-03,  7.7266e-04,  4.2917e-04,\n",
      "         4.9382e-04,  1.3748e-03, -9.6491e-04, -5.6782e-04, -8.3120e-04,\n",
      "        -1.9507e-04, -1.5217e-03, -1.0613e-03,  1.0283e-03,  5.4827e-04,\n",
      "        -1.3900e-03, -1.3491e-03, -1.7175e-03, -8.2795e-04, -4.9771e-04,\n",
      "        -9.4148e-04, -8.4607e-05,  3.5305e-04,  1.3587e-07, -4.1400e-04,\n",
      "         7.4249e-04,  1.4417e-04, -8.0505e-04,  1.3678e-04, -9.9643e-04,\n",
      "         2.7875e-05, -2.6851e-04,  2.1868e-03,  2.6654e-04, -2.1215e-03,\n",
      "         4.8460e-04,  8.6824e-04, -1.3322e-03, -6.0206e-04,  1.0349e-03,\n",
      "        -4.7120e-04,  5.8136e-04, -1.3582e-03, -1.2025e-03, -1.9607e-05,\n",
      "         1.0449e-03,  1.4060e-04,  1.4705e-03,  7.1576e-04,  5.5521e-04,\n",
      "        -1.7807e-04,  1.9971e-03, -8.5735e-04, -1.5298e-03,  6.9621e-04,\n",
      "         1.4473e-03,  3.2118e-06, -8.9455e-05,  8.8368e-04,  3.0338e-04,\n",
      "         6.5590e-05,  1.8315e-03,  9.2608e-04,  2.2539e-04,  1.1289e-05,\n",
      "         1.1926e-03, -8.3152e-04, -5.8640e-04, -4.7588e-04, -6.8589e-04,\n",
      "        -1.3583e-03,  1.4185e-03,  1.1471e-03,  9.2626e-04, -5.0371e-04,\n",
      "         6.7109e-04, -3.3421e-04, -2.7997e-04,  1.0758e-03, -1.0260e-03,\n",
      "         8.2826e-04, -3.5008e-04, -5.4398e-04, -7.7812e-04, -3.9831e-04,\n",
      "        -6.8075e-04, -1.3966e-03,  1.3592e-03, -6.0549e-05,  2.1740e-04,\n",
      "         1.0662e-03,  5.8169e-04, -5.7274e-04, -7.0547e-04, -1.3279e-03,\n",
      "         3.4881e-04, -1.1259e-03,  3.3818e-04, -8.2455e-05, -1.2326e-03,\n",
      "         8.4291e-04,  9.0975e-04,  1.4204e-03,  2.9465e-04, -1.2327e-03,\n",
      "         1.2147e-03, -1.7911e-03, -2.0843e-04,  1.5646e-03, -6.6057e-04,\n",
      "         1.1367e-03,  2.3621e-03, -2.9889e-04, -8.7822e-04,  8.2703e-05,\n",
      "         1.2151e-03, -1.3626e-03, -1.8283e-03,  6.9056e-04, -1.0788e-03,\n",
      "        -1.7340e-03,  3.3894e-05,  1.0523e-05,  1.2067e-03,  1.5195e-04,\n",
      "        -9.8646e-04, -1.5692e-03,  7.9737e-04, -1.4383e-03, -5.9052e-04,\n",
      "         3.4275e-04, -1.2611e-03,  3.7598e-04, -1.6353e-03,  7.5179e-04,\n",
      "        -8.9866e-04, -4.3973e-06,  5.4578e-04, -1.1736e-04,  1.1748e-04,\n",
      "        -1.2477e-03, -6.7405e-04,  3.2110e-04,  1.4181e-04, -2.2483e-05,\n",
      "         2.5433e-04,  4.1794e-04,  1.0393e-03, -1.2593e-03,  1.0205e-03,\n",
      "        -1.5689e-04, -7.1450e-04, -6.1919e-04, -4.4992e-05,  4.0784e-04,\n",
      "         3.1927e-04,  2.9734e-04, -1.1444e-04,  1.1758e-03, -2.0514e-03,\n",
      "        -4.1002e-04,  9.8289e-04, -1.6875e-03, -1.5724e-03,  1.9050e-03,\n",
      "        -6.7808e-04,  5.3856e-04, -1.1706e-03, -1.1205e-03, -2.2480e-04,\n",
      "        -3.4337e-04,  8.4257e-04, -1.3766e-03, -8.6163e-04, -1.0368e-03,\n",
      "        -8.9029e-04, -3.2480e-04, -1.2456e-03, -3.2748e-04, -1.8620e-03,\n",
      "         1.8347e-07])\n",
      "\n",
      "bert.encoder.layer.3.attention.output.dense.weight:\n",
      "\n",
      "tensor([[ 1.0334e-02,  2.0885e-03, -2.5098e-02,  ..., -1.7868e-02,\n",
      "          8.8156e-03,  1.2529e-02],\n",
      "        [ 8.2739e-06, -3.0376e-03,  2.3870e-02,  ...,  4.3504e-04,\n",
      "         -1.6385e-02, -1.9953e-02],\n",
      "        [-5.8513e-03, -5.5804e-03, -1.0151e-02,  ..., -2.3618e-03,\n",
      "          3.5666e-02,  3.4458e-02],\n",
      "        ...,\n",
      "        [-1.1157e-02, -7.8556e-03, -1.3477e-02,  ..., -3.5992e-02,\n",
      "          4.6584e-02,  4.0279e-03],\n",
      "        [-2.5117e-02, -3.7228e-02, -3.5564e-02,  ...,  8.9365e-03,\n",
      "          4.2727e-03,  1.0839e-02],\n",
      "        [-3.4587e-02, -1.6331e-02,  5.4620e-03,  ..., -1.1095e-02,\n",
      "         -7.1483e-03, -2.6762e-02]])\n",
      "\n",
      "bert.encoder.layer.3.attention.output.dense.bias:\n",
      "\n",
      "tensor([ 6.5065e-04, -5.5446e-05,  1.4002e-04,  4.8566e-04,  2.2132e-04,\n",
      "         5.7497e-04, -4.4686e-05,  8.9535e-04, -1.1889e-04, -4.1332e-04,\n",
      "        -5.5985e-04, -1.4018e-04, -1.8311e-03,  1.1166e-03,  4.3763e-04,\n",
      "        -1.5588e-03, -1.2752e-03,  8.6531e-04, -4.2982e-04, -4.7106e-05,\n",
      "        -8.5895e-04, -5.2595e-04,  1.0936e-05,  1.6898e-03,  1.1737e-03,\n",
      "        -3.5102e-04,  2.0213e-03, -1.2241e-03,  9.3024e-04,  1.1689e-03,\n",
      "         2.0787e-04, -2.9912e-04,  1.4296e-04,  5.6731e-04,  4.2802e-04,\n",
      "         1.3021e-04, -1.5424e-03,  1.0700e-03, -1.7391e-03,  1.2401e-03,\n",
      "        -5.2640e-04,  1.4849e-03,  2.9695e-03,  5.9725e-06,  9.6097e-04,\n",
      "         6.2991e-04,  4.6031e-04, -5.3480e-04,  2.0394e-03,  9.7398e-04,\n",
      "        -1.9120e-04, -1.6576e-04, -1.9110e-04, -1.2748e-04, -1.0575e-03,\n",
      "        -1.0054e-03,  2.3363e-04, -1.2571e-03,  4.2539e-04, -5.2970e-04,\n",
      "        -1.1168e-04, -3.1377e-04, -2.3617e-03, -9.7093e-04,  1.1989e-03,\n",
      "        -1.0997e-03,  8.9139e-04,  1.0350e-03,  1.1164e-03, -2.1290e-03,\n",
      "        -3.2107e-04, -8.9526e-04, -3.4351e-04, -4.4993e-04,  1.3925e-04,\n",
      "        -9.5669e-04,  3.8493e-04, -1.6498e-03,  1.2952e-03,  1.0111e-03,\n",
      "         7.6700e-04,  1.5226e-03,  2.0496e-04, -2.5986e-04,  7.1660e-04,\n",
      "         1.3367e-03, -1.3520e-03, -1.1591e-03, -3.7217e-04, -3.1536e-04,\n",
      "        -1.3455e-03,  4.8084e-04, -8.8260e-04, -4.3436e-04,  7.7607e-04,\n",
      "        -9.6677e-04,  7.7226e-04, -8.6887e-04,  6.2372e-04, -8.9293e-04,\n",
      "        -1.0540e-03, -6.2242e-04, -9.0144e-04,  1.2127e-05,  1.0593e-03,\n",
      "         4.9768e-04,  5.7295e-04, -1.5493e-03, -1.0915e-04,  1.0003e-03,\n",
      "        -2.6616e-04,  9.0658e-04,  4.6403e-04,  3.8394e-04,  9.7987e-06,\n",
      "        -9.2659e-04, -1.2652e-03,  8.1605e-04, -5.1386e-04, -3.3440e-05,\n",
      "        -1.7779e-04, -1.3649e-03, -9.3922e-04,  8.1536e-04,  4.6732e-04,\n",
      "        -4.9407e-04, -8.0265e-04, -7.6448e-04,  4.2457e-04,  7.6573e-04,\n",
      "         8.1955e-05,  6.9519e-04, -3.7874e-04, -1.3272e-03,  6.0362e-04,\n",
      "        -1.3575e-03, -1.7171e-04, -1.2000e-03,  2.0497e-04, -7.0629e-04,\n",
      "         1.1583e-03,  6.1857e-04,  2.5381e-04, -1.0004e-03,  1.0782e-05,\n",
      "        -7.3799e-04,  2.5556e-03,  2.5917e-04, -1.3026e-03,  1.2368e-03,\n",
      "        -4.1519e-05,  4.5544e-04, -6.6513e-04,  1.6653e-03,  1.6012e-03,\n",
      "        -1.0028e-03, -1.6696e-03,  4.6058e-05, -1.2717e-03, -4.6482e-04,\n",
      "         7.7383e-05,  1.0109e-03, -2.1948e-05, -9.1621e-04, -1.7715e-03,\n",
      "         3.9744e-04,  3.6811e-04, -5.9105e-04, -1.2021e-03, -3.8170e-04,\n",
      "         9.5038e-04, -6.2028e-05,  9.3322e-04,  1.0580e-03, -5.9179e-04,\n",
      "         3.5068e-04,  2.2770e-03,  1.8291e-03,  1.0085e-03,  4.9435e-04,\n",
      "        -1.3950e-03,  4.7481e-04, -1.6895e-03,  1.1163e-03,  4.2479e-04,\n",
      "        -1.1729e-03,  1.6998e-04,  1.4761e-04, -3.7935e-04, -4.2298e-04,\n",
      "        -4.7153e-04, -2.5754e-04,  5.3944e-04, -4.1353e-04,  1.7511e-03,\n",
      "         4.6565e-04,  2.2857e-05, -7.6457e-04, -9.1811e-04,  4.6761e-04,\n",
      "         8.5199e-04, -1.7893e-06, -2.1463e-04,  1.8804e-04, -1.1903e-03,\n",
      "        -4.5945e-04,  3.0979e-04, -1.4178e-04,  1.1962e-04, -1.5994e-04,\n",
      "        -5.3824e-04,  2.7304e-04, -2.9253e-04, -1.9616e-04, -1.1702e-03,\n",
      "        -4.6083e-04,  1.2237e-03,  4.7491e-04, -7.5610e-04, -8.5688e-04,\n",
      "        -1.2766e-03, -1.8929e-03, -1.0613e-03, -1.3066e-03,  8.3934e-04,\n",
      "         1.7157e-04, -5.7440e-04, -8.9990e-04,  4.2895e-04, -6.7481e-04,\n",
      "        -3.2126e-04,  6.9301e-04, -1.7590e-03,  4.6349e-04, -8.4963e-05,\n",
      "         4.5259e-04,  6.7028e-04,  5.8028e-04, -1.7628e-04, -1.5677e-03,\n",
      "         2.9402e-04, -2.3477e-04,  1.2803e-03, -1.0512e-03, -3.9623e-04,\n",
      "         1.1430e-05, -1.1873e-03, -1.0283e-04,  1.1626e-03,  2.7004e-04,\n",
      "         1.3873e-04,  9.9058e-04, -2.0979e-04,  6.0252e-05, -1.7238e-03,\n",
      "        -4.7296e-04])\n",
      "\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9999, 0.9999, 0.9998, 1.0001, 1.0001, 0.9998, 0.9982, 1.0006, 0.9972,\n",
      "        0.9987, 1.0002, 0.9992, 1.0000, 1.0000, 1.0002, 1.0012, 0.9998, 1.0009,\n",
      "        1.0016, 0.9998, 0.9995, 1.0013, 1.0004, 1.0004, 0.9996, 1.0012, 1.0022,\n",
      "        1.0017, 1.0022, 0.9988, 0.9998, 1.0000, 1.0006, 1.0003, 1.0000, 1.0001,\n",
      "        0.9988, 0.9987, 1.0012, 0.9996, 1.0002, 1.0011, 1.0027, 1.0005, 0.9979,\n",
      "        0.9981, 1.0020, 0.9993, 0.9979, 0.9999, 1.0000, 1.0000, 0.9999, 0.9994,\n",
      "        0.9984, 1.0013, 1.0005, 0.9999, 1.0009, 0.9987, 0.9995, 0.9985, 1.0007,\n",
      "        1.0019, 1.0013, 0.9999, 1.0008, 0.9997, 1.0015, 1.0014, 1.0013, 1.0008,\n",
      "        0.9983, 1.0002, 1.0013, 1.0026, 1.0005, 1.0003, 1.0019, 0.9991, 1.0000,\n",
      "        1.0013, 0.9995, 0.9998, 0.9998, 1.0009, 1.0017, 1.0004, 0.9983, 1.0009,\n",
      "        0.9989, 0.9999, 0.9972, 1.0011, 0.9992, 1.0019, 0.9995, 1.0011, 0.9990,\n",
      "        1.0013, 1.0008, 1.0006, 0.9977, 0.9973, 1.0005, 1.0009, 0.9988, 1.0003,\n",
      "        0.9990, 0.9983, 0.9998, 0.9990, 1.0013, 1.0003, 0.9999, 0.9992, 1.0003,\n",
      "        1.0014, 1.0019, 0.9970, 1.0010, 1.0004, 1.0014, 1.0011, 0.9991, 0.9979,\n",
      "        1.0007, 0.9988, 0.9985, 1.0012, 1.0001, 1.0012, 0.9996, 1.0010, 0.9970,\n",
      "        0.9989, 0.9994, 1.0001, 1.0001, 0.9980, 1.0006, 1.0017, 0.9970, 0.9981,\n",
      "        0.9971, 0.9977, 1.0018, 0.9998, 1.0007, 1.0002, 1.0007, 1.0011, 0.9993,\n",
      "        1.0004, 1.0011, 1.0011, 0.9998, 0.9989, 1.0003, 1.0001, 1.0001, 0.9962,\n",
      "        1.0014, 1.0010, 1.0011, 1.0003, 0.9994, 1.0008, 1.0005, 0.9995, 1.0014,\n",
      "        0.9994, 0.9997, 1.0005, 1.0007, 0.9999, 1.0014, 1.0018, 0.9990, 0.9991,\n",
      "        1.0004, 1.0003, 1.0002, 1.0019, 0.9988, 0.9997, 1.0004, 0.9990, 0.9991,\n",
      "        1.0016, 0.9991, 1.0000, 0.9994, 1.0020, 0.9995, 1.0020, 0.9987, 1.0023,\n",
      "        1.0012, 1.0015, 0.9971, 0.9998, 0.9962, 0.9989, 1.0000, 0.9989, 0.9993,\n",
      "        0.9996, 0.9975, 0.9991, 0.9990, 1.0001, 0.9978, 1.0001, 1.0000, 0.9998,\n",
      "        0.9991, 0.9990, 0.9988, 0.9997, 1.0007, 1.0009, 0.9989, 0.9991, 0.9990,\n",
      "        0.9983, 1.0001, 1.0008, 0.9988, 1.0010, 0.9997, 1.0000, 1.0005, 1.0007,\n",
      "        1.0015, 0.9994, 0.9989, 1.0003, 0.9999, 0.9984, 1.0011, 0.9983, 0.9973,\n",
      "        0.9998, 0.9995, 1.0001, 1.0001, 0.9962, 1.0007, 0.9996, 1.0019, 0.9974,\n",
      "        0.9992, 0.9997, 1.0014, 1.0012])\n",
      "\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias:\n",
      "\n",
      "tensor([ 4.7577e-04, -6.4613e-04, -4.1200e-04,  4.7219e-04,  5.6242e-04,\n",
      "         9.5044e-04, -1.2155e-05,  1.1020e-03,  4.1806e-04, -2.4913e-04,\n",
      "        -6.1289e-04,  2.9761e-05, -6.5781e-04,  6.2328e-04,  2.9383e-04,\n",
      "        -1.1686e-03, -1.8080e-03,  9.2031e-04, -7.7564e-04,  5.4783e-04,\n",
      "        -1.0360e-03, -8.1700e-04, -6.4594e-04,  1.7470e-03,  9.5269e-04,\n",
      "        -2.6897e-04,  1.5547e-03,  1.9756e-04,  1.2055e-03,  7.9699e-04,\n",
      "         2.3137e-04,  7.3060e-05,  1.1054e-03,  6.0814e-05,  5.1053e-05,\n",
      "         8.9439e-04, -1.9416e-03,  3.3889e-04, -1.8817e-03,  2.7602e-04,\n",
      "        -4.9508e-04,  1.9403e-03,  1.9787e-03, -7.5684e-04, -1.1679e-04,\n",
      "         7.2561e-04,  1.0841e-03, -4.5480e-05,  9.4341e-04,  8.6586e-04,\n",
      "        -3.3397e-04,  4.1964e-04, -2.3796e-04, -1.3545e-06, -5.3350e-04,\n",
      "        -1.8776e-03,  4.6717e-04, -9.8969e-04,  1.4267e-04, -2.0666e-04,\n",
      "         9.1258e-05, -3.2774e-04, -1.7998e-03, -1.4915e-03,  8.4924e-04,\n",
      "         7.2645e-04,  9.4658e-04,  1.5789e-03,  1.1009e-03, -1.2952e-03,\n",
      "         5.4160e-05, -9.0742e-04,  3.0331e-05, -5.2025e-04,  3.3280e-04,\n",
      "        -7.5065e-04,  1.3672e-03, -1.3447e-03,  1.4477e-03, -3.2445e-04,\n",
      "         1.0364e-03,  1.0676e-03,  2.6437e-04, -1.0617e-03,  1.2107e-03,\n",
      "         1.5875e-03, -1.2589e-03, -8.6405e-04, -4.3657e-04, -5.6527e-04,\n",
      "         5.8910e-04,  1.0355e-03, -1.3873e-03, -5.6384e-05,  5.4704e-04,\n",
      "        -1.3654e-03,  3.7938e-04, -5.9580e-04, -2.5560e-04, -8.4904e-04,\n",
      "        -1.0762e-03, -1.1420e-03, -7.4022e-04, -8.3343e-04,  1.2877e-03,\n",
      "         2.6208e-04,  1.3398e-04, -1.4087e-03, -1.7072e-04,  6.5977e-04,\n",
      "        -4.1166e-06,  9.4420e-04,  8.8156e-04,  7.2459e-04,  1.1083e-03,\n",
      "        -9.9540e-04, -1.1956e-03,  7.9079e-04, -1.3511e-03,  2.7620e-04,\n",
      "        -5.4652e-04, -9.8349e-04, -8.2450e-04,  1.2425e-03,  3.0832e-04,\n",
      "        -3.3206e-04, -9.2562e-04, -1.0977e-03,  8.4162e-04,  1.7071e-04,\n",
      "         6.8659e-05,  4.1581e-04, -2.7331e-04, -1.5165e-03,  8.4089e-04,\n",
      "        -1.1169e-04,  7.5908e-04, -8.2463e-04,  1.8039e-04, -2.9297e-04,\n",
      "         1.1928e-03,  4.2049e-04,  4.2819e-04, -6.9301e-04,  8.0161e-05,\n",
      "        -5.4793e-04,  2.3639e-03, -5.6978e-05, -6.4857e-04,  1.6210e-03,\n",
      "        -1.5079e-04,  9.6800e-04, -4.8783e-04,  1.7211e-03,  1.3132e-03,\n",
      "        -6.8978e-04, -1.0700e-03, -5.6621e-04,  1.4813e-04, -4.1855e-04,\n",
      "         3.8721e-04,  7.1036e-04,  8.9466e-04, -8.3693e-05, -1.1301e-03,\n",
      "        -8.4029e-04,  4.8463e-04, -4.9516e-04, -1.0472e-03, -5.4094e-04,\n",
      "         8.6605e-04, -6.2020e-05,  2.4813e-04, -3.3650e-04, -8.6082e-04,\n",
      "         4.7204e-04,  2.0696e-03,  1.9939e-03,  4.4104e-04,  1.9695e-04,\n",
      "        -8.7418e-04,  1.7662e-04, -1.8108e-03,  1.8723e-03,  2.7621e-04,\n",
      "        -1.5032e-03, -3.3035e-04, -1.6033e-04, -2.3777e-04, -6.7107e-04,\n",
      "         1.1835e-03, -8.6455e-04,  8.8824e-04, -1.8083e-04,  1.7618e-03,\n",
      "         1.4181e-03,  2.0659e-04, -8.4745e-04,  8.8366e-04,  1.8388e-04,\n",
      "         9.3732e-04, -2.6528e-04, -3.8901e-04,  9.9952e-05, -1.1568e-03,\n",
      "        -3.0237e-04,  2.8691e-04,  3.2365e-04,  2.9799e-04, -3.2285e-04,\n",
      "         1.6192e-05, -2.2122e-04, -3.8498e-04, -2.2890e-04, -3.1638e-04,\n",
      "        -3.6402e-04,  1.0590e-03, -1.6675e-04, -1.2195e-03, -9.1286e-04,\n",
      "        -1.1480e-03, -1.4296e-03, -8.5060e-04, -1.9522e-04,  1.5974e-03,\n",
      "        -4.0430e-04, -2.5938e-04, -8.2636e-04,  8.2704e-04, -5.6848e-05,\n",
      "        -5.4686e-04,  6.0604e-04, -1.3799e-03,  1.0612e-03, -5.4926e-04,\n",
      "         1.2529e-03,  2.2807e-05,  1.2236e-03, -1.4827e-04, -1.4323e-03,\n",
      "         1.5791e-05, -6.4061e-04,  2.0757e-04, -1.0910e-03,  1.5082e-04,\n",
      "         9.9996e-04, -1.3123e-03, -1.3156e-03,  1.2260e-03, -7.7864e-05,\n",
      "        -1.0229e-03,  1.7492e-03, -7.0395e-04, -6.2179e-06, -1.5513e-03,\n",
      "        -7.1169e-04])\n",
      "\n",
      "bert.encoder.layer.3.intermediate.dense.weight:\n",
      "\n",
      "tensor([[ 0.0195, -0.0295, -0.0126,  ..., -0.0185, -0.0016,  0.0091],\n",
      "        [ 0.0012,  0.0032, -0.0220,  ...,  0.0061,  0.0135,  0.0101],\n",
      "        [-0.0270,  0.0396, -0.0094,  ..., -0.0431, -0.0085, -0.0084],\n",
      "        ...,\n",
      "        [-0.0106, -0.0050,  0.0152,  ...,  0.0027, -0.0012,  0.0423],\n",
      "        [ 0.0068, -0.0164,  0.0168,  ...,  0.0045, -0.0025, -0.0291],\n",
      "        [-0.0009,  0.0049,  0.0009,  ...,  0.0036, -0.0261,  0.0257]])\n",
      "\n",
      "bert.encoder.layer.3.intermediate.dense.bias:\n",
      "\n",
      "tensor([-0.0023, -0.0006, -0.0007,  ...,  0.0002,  0.0020, -0.0027])\n",
      "\n",
      "bert.encoder.layer.3.output.dense.weight:\n",
      "\n",
      "tensor([[ 0.0215, -0.0297, -0.0231,  ...,  0.0266, -0.0358, -0.0136],\n",
      "        [-0.0127,  0.0211,  0.0167,  ...,  0.0013, -0.0056, -0.0195],\n",
      "        [ 0.0233,  0.0143,  0.0177,  ..., -0.0153, -0.0291, -0.0228],\n",
      "        ...,\n",
      "        [-0.0286, -0.0064,  0.0377,  ..., -0.0118, -0.0087, -0.0053],\n",
      "        [ 0.0268,  0.0154,  0.0298,  ..., -0.0181,  0.0009,  0.0118],\n",
      "        [-0.0138, -0.0243,  0.0279,  ..., -0.0111,  0.0268,  0.0437]])\n",
      "\n",
      "bert.encoder.layer.3.output.dense.bias:\n",
      "\n",
      "tensor([ 4.1112e-04, -8.5213e-04, -7.6428e-04,  1.1408e-03, -6.8597e-05,\n",
      "         8.2761e-04,  4.7995e-04,  1.5851e-03,  7.5850e-04, -3.5457e-04,\n",
      "         5.3219e-04,  3.7896e-05,  4.3430e-04,  1.6929e-04,  1.1870e-03,\n",
      "        -1.3841e-03, -1.1775e-03,  9.0049e-04, -6.4521e-04,  1.4632e-04,\n",
      "        -1.1185e-03, -2.3339e-03, -6.9285e-04,  6.1628e-04,  6.9571e-04,\n",
      "         3.0776e-04,  1.3689e-03,  2.3395e-04,  1.4363e-03,  1.0534e-03,\n",
      "         2.7452e-04, -5.0305e-04,  7.1006e-04, -3.9240e-04, -5.8663e-04,\n",
      "         7.6918e-04, -1.8382e-03,  7.2833e-04, -1.5607e-03, -7.5295e-05,\n",
      "        -8.3792e-04,  1.4072e-03,  2.1530e-03, -8.7456e-04, -2.0760e-04,\n",
      "         1.0184e-03,  5.2551e-07, -5.3314e-04,  1.0157e-03,  1.9201e-04,\n",
      "         5.1238e-05,  2.7840e-04, -2.0328e-04, -7.1102e-04, -1.1490e-03,\n",
      "        -2.2239e-03,  5.7867e-06, -1.0556e-03, -2.7056e-04, -4.7764e-04,\n",
      "        -3.0720e-04,  4.5715e-04, -1.4293e-03, -1.1857e-03,  5.6803e-04,\n",
      "         3.6503e-04,  1.1552e-03,  1.6737e-03,  1.6643e-03, -1.2060e-03,\n",
      "        -2.6777e-04, -4.8862e-04, -2.8054e-04,  6.5247e-04, -6.5016e-05,\n",
      "        -8.4936e-05,  2.0997e-03, -8.5991e-04,  8.4931e-04, -3.2715e-04,\n",
      "         6.8240e-04,  3.4053e-04,  9.8009e-05, -3.2963e-04, -5.2898e-04,\n",
      "         4.8081e-04,  6.8002e-05, -1.4318e-03, -9.9185e-05, -7.0919e-04,\n",
      "         8.7273e-04,  7.2851e-05, -1.7388e-03,  6.7121e-04,  1.1818e-03,\n",
      "        -3.2963e-04,  8.6768e-04, -7.3133e-04, -8.1712e-04,  3.7950e-04,\n",
      "        -1.1747e-03, -1.3093e-03, -1.0143e-03, -1.5091e-03,  1.2615e-03,\n",
      "         2.7956e-04,  6.1416e-04, -1.4646e-03,  1.0116e-03,  3.4738e-04,\n",
      "         2.6989e-04,  1.0408e-03,  1.5944e-03,  4.5563e-04,  2.5044e-03,\n",
      "        -5.7011e-04, -1.2369e-03,  4.5204e-04, -3.0977e-04,  1.8884e-05,\n",
      "        -6.7566e-04, -9.9152e-04, -6.5580e-04,  9.0869e-04, -2.1507e-05,\n",
      "         3.0015e-04, -1.0914e-03, -8.6395e-04,  1.2190e-03,  8.8219e-06,\n",
      "        -4.1526e-04,  1.9482e-04, -4.2745e-04, -6.8246e-04,  8.3876e-04,\n",
      "         7.4757e-05,  1.1138e-03, -1.2127e-03,  3.0802e-04, -5.3191e-07,\n",
      "         1.4399e-03, -8.4527e-04, -1.5433e-04, -4.1801e-04, -5.3869e-04,\n",
      "        -8.2103e-04,  2.4504e-03, -5.1303e-05, -2.8237e-04,  1.4578e-03,\n",
      "        -7.7451e-04,  2.3881e-04,  1.2594e-04,  1.8649e-03,  9.0563e-04,\n",
      "        -4.9761e-04, -1.4205e-03, -5.3710e-04, -1.6960e-04,  8.1837e-05,\n",
      "        -1.3778e-04,  1.1593e-04, -9.8433e-04, -6.1928e-05, -5.7661e-04,\n",
      "         1.0710e-04, -8.6760e-04,  2.7017e-04, -1.3288e-03, -5.8934e-04,\n",
      "         1.3962e-04, -8.1127e-05, -9.9670e-04,  2.1822e-04, -5.0560e-04,\n",
      "         1.1538e-04,  1.8169e-03,  2.0922e-03,  1.8592e-04, -3.1424e-04,\n",
      "        -1.0413e-03,  1.5972e-04, -1.0515e-03,  1.5775e-03, -2.0877e-04,\n",
      "        -2.1158e-03, -6.3978e-04,  3.7464e-05, -2.8285e-04,  1.4576e-04,\n",
      "        -1.2717e-04, -3.0474e-04,  5.1310e-04, -2.4084e-04,  2.2458e-03,\n",
      "         1.5421e-03, -1.2589e-04, -3.9041e-04,  1.0620e-03, -1.6032e-04,\n",
      "         3.7203e-04, -2.9119e-04, -3.4319e-04, -2.9781e-04, -1.0771e-03,\n",
      "         1.0804e-04,  3.3771e-04,  9.6512e-04, -1.0824e-04, -6.2506e-04,\n",
      "        -5.8821e-04,  3.1841e-05, -5.1875e-05,  7.5305e-05, -9.2941e-05,\n",
      "        -5.9059e-04, -4.1864e-04, -5.0424e-04, -2.1649e-03, -1.5934e-03,\n",
      "        -1.4612e-03, -1.0311e-03, -7.0318e-04, -1.9365e-04,  1.3751e-03,\n",
      "        -6.8452e-05,  1.1005e-03, -1.4520e-03,  1.4562e-03, -3.4228e-04,\n",
      "        -7.5453e-04,  9.7846e-04, -1.8596e-03,  1.2647e-03, -1.4817e-04,\n",
      "         9.0680e-04,  1.1167e-04,  1.8289e-03, -4.0878e-04, -1.2227e-03,\n",
      "         5.7652e-04, -7.7830e-04, -2.0737e-04, -1.3613e-03,  1.0102e-03,\n",
      "         1.8628e-03, -9.6261e-04,  3.7007e-04, -2.4372e-04, -5.0975e-04,\n",
      "        -1.5728e-03,  1.0748e-03, -4.1270e-04, -2.7520e-04, -8.1677e-04,\n",
      "        -3.6366e-04])\n",
      "\n",
      "bert.encoder.layer.3.output.LayerNorm.weight:\n",
      "\n",
      "tensor([0.9998, 0.9997, 1.0002, 1.0001, 0.9996, 0.9995, 0.9983, 1.0007, 0.9984,\n",
      "        0.9985, 1.0001, 0.9991, 0.9999, 0.9996, 1.0003, 1.0011, 0.9995, 1.0002,\n",
      "        1.0013, 0.9997, 0.9997, 1.0010, 1.0000, 1.0000, 0.9996, 1.0003, 1.0021,\n",
      "        1.0017, 1.0021, 0.9984, 0.9998, 1.0000, 1.0004, 0.9998, 1.0004, 0.9999,\n",
      "        0.9987, 0.9986, 1.0008, 0.9999, 0.9999, 1.0008, 1.0026, 1.0002, 0.9978,\n",
      "        0.9978, 1.0012, 0.9994, 0.9971, 0.9999, 0.9997, 0.9999, 0.9999, 0.9994,\n",
      "        0.9986, 1.0010, 1.0003, 0.9994, 1.0006, 0.9990, 0.9996, 0.9982, 1.0004,\n",
      "        1.0017, 1.0009, 0.9997, 1.0007, 0.9997, 1.0014, 1.0011, 1.0016, 1.0005,\n",
      "        0.9985, 0.9998, 1.0013, 1.0017, 1.0000, 1.0001, 1.0013, 0.9993, 0.9999,\n",
      "        1.0010, 0.9994, 0.9996, 0.9995, 1.0008, 1.0011, 1.0002, 0.9981, 1.0005,\n",
      "        0.9984, 0.9998, 0.9981, 1.0003, 0.9995, 1.0013, 0.9988, 1.0011, 0.9988,\n",
      "        1.0014, 1.0002, 1.0006, 0.9982, 0.9974, 1.0004, 1.0004, 0.9985, 0.9998,\n",
      "        0.9989, 0.9975, 0.9997, 0.9993, 1.0014, 1.0006, 0.9995, 0.9982, 1.0000,\n",
      "        1.0009, 1.0012, 0.9970, 1.0001, 1.0003, 1.0007, 1.0004, 0.9989, 0.9976,\n",
      "        1.0009, 0.9987, 0.9985, 1.0009, 0.9996, 1.0011, 0.9994, 1.0006, 0.9972,\n",
      "        0.9985, 0.9994, 0.9998, 0.9997, 0.9970, 1.0004, 1.0016, 0.9973, 0.9974,\n",
      "        0.9973, 0.9983, 1.0015, 0.9994, 1.0009, 0.9999, 1.0003, 1.0011, 0.9987,\n",
      "        1.0006, 1.0007, 1.0009, 0.9995, 0.9987, 0.9995, 1.0000, 0.9999, 0.9967,\n",
      "        1.0011, 1.0007, 1.0009, 1.0002, 0.9994, 1.0006, 1.0001, 0.9989, 1.0014,\n",
      "        0.9992, 0.9988, 1.0006, 1.0004, 0.9999, 1.0014, 1.0018, 0.9986, 0.9991,\n",
      "        1.0007, 0.9999, 1.0002, 1.0016, 0.9982, 0.9995, 1.0003, 0.9992, 0.9990,\n",
      "        1.0014, 0.9987, 0.9994, 0.9993, 1.0019, 0.9997, 1.0015, 0.9986, 1.0015,\n",
      "        1.0013, 1.0011, 0.9974, 0.9998, 0.9959, 0.9985, 1.0000, 0.9988, 0.9989,\n",
      "        0.9994, 0.9972, 0.9993, 0.9987, 0.9999, 0.9977, 1.0000, 0.9998, 0.9998,\n",
      "        0.9985, 0.9990, 0.9989, 1.0002, 1.0002, 1.0003, 0.9990, 0.9992, 0.9995,\n",
      "        0.9980, 1.0003, 1.0005, 0.9989, 1.0010, 0.9999, 1.0001, 1.0002, 1.0008,\n",
      "        1.0016, 0.9994, 0.9989, 1.0007, 0.9996, 0.9983, 1.0010, 0.9979, 0.9971,\n",
      "        0.9995, 0.9998, 0.9989, 1.0000, 0.9958, 1.0006, 0.9991, 1.0015, 0.9968,\n",
      "        0.9990, 0.9997, 1.0012, 1.0010])\n",
      "\n",
      "bert.encoder.layer.3.output.LayerNorm.bias:\n",
      "\n",
      "tensor([ 6.1321e-04, -4.2731e-04, -4.6286e-04,  5.5046e-04,  6.1236e-04,\n",
      "         6.6907e-04,  1.0853e-04,  9.8541e-04,  2.6096e-04, -3.0117e-04,\n",
      "        -5.7127e-04, -6.3807e-05, -7.6456e-04,  4.7076e-04,  7.6965e-04,\n",
      "        -1.0591e-03, -1.4270e-03,  1.1616e-03, -6.7612e-04,  4.7518e-04,\n",
      "        -8.8921e-04, -7.0048e-04, -6.0628e-04,  1.4079e-03,  8.8083e-04,\n",
      "        -1.5638e-04,  1.0592e-03,  3.5272e-04,  9.0942e-04,  8.7019e-04,\n",
      "         2.4815e-04,  1.1851e-04,  8.8740e-04,  1.2503e-04,  1.1099e-05,\n",
      "         8.1028e-04, -1.7997e-03,  8.0969e-04, -1.4902e-03,  3.2015e-04,\n",
      "        -3.1520e-04,  1.8047e-03,  1.7015e-03, -3.9326e-04, -4.0564e-04,\n",
      "         7.2795e-04,  5.8637e-04,  2.9659e-04,  1.0043e-03,  8.7820e-04,\n",
      "         1.8819e-05,  2.6215e-04, -9.5928e-05,  2.6117e-05, -4.7122e-04,\n",
      "        -1.6202e-03,  5.1729e-04, -7.1693e-04,  1.2038e-04, -1.9682e-05,\n",
      "         2.0559e-04, -1.4842e-04, -1.4355e-03, -1.3660e-03,  7.7763e-04,\n",
      "         1.0422e-03,  8.7375e-04,  1.3021e-03,  1.2248e-03, -1.0787e-03,\n",
      "         2.8439e-04, -7.4413e-04,  3.7467e-04, -4.6184e-04,  2.0364e-04,\n",
      "        -7.1229e-04,  1.0182e-03, -9.5156e-04,  9.6232e-04, -5.3416e-04,\n",
      "         8.8938e-04,  8.2399e-04,  6.9026e-06, -1.1430e-03,  7.0367e-04,\n",
      "         1.4050e-03, -1.0847e-03, -7.2587e-04, -3.7660e-04, -2.7049e-04,\n",
      "         8.0595e-04,  6.0648e-04, -1.0961e-03,  3.7038e-06,  6.8648e-04,\n",
      "        -1.1868e-03, -1.1698e-04, -5.8111e-04, -1.5186e-04, -7.5611e-04,\n",
      "        -7.5119e-04, -1.0017e-03, -8.0703e-04, -1.2515e-03,  1.3215e-03,\n",
      "         2.8374e-04, -4.1696e-05, -1.0195e-03, -3.9448e-04,  3.4752e-04,\n",
      "        -1.1260e-04,  7.4290e-04,  8.3208e-04,  8.8606e-04,  1.3427e-03,\n",
      "        -7.4791e-04, -8.3163e-04,  4.8607e-04, -7.4375e-04,  2.5906e-04,\n",
      "        -6.7483e-04, -9.0010e-04, -7.6687e-04,  1.0328e-03, -4.8419e-05,\n",
      "        -5.0799e-04, -6.4465e-04, -9.4148e-04,  5.7139e-04,  2.2613e-04,\n",
      "        -1.3172e-04,  7.5991e-04, -2.5629e-04, -1.1852e-03,  1.1099e-03,\n",
      "        -8.9814e-04,  6.3806e-04, -6.5853e-04,  8.3240e-06, -9.6631e-05,\n",
      "         1.2916e-03, -1.0202e-04,  5.3692e-04, -5.4750e-04,  1.3625e-04,\n",
      "        -3.6695e-04,  2.0845e-03,  2.3871e-04, -6.8110e-04,  1.5886e-03,\n",
      "        -1.6339e-04,  7.9513e-04, -4.4940e-05,  1.7277e-03,  1.0123e-03,\n",
      "        -2.9156e-04, -8.7510e-04, -3.9683e-04,  4.3415e-04, -2.8985e-04,\n",
      "         1.9295e-04,  8.8753e-04,  4.1032e-04, -3.7475e-04, -7.8467e-04,\n",
      "        -8.1820e-04,  4.0547e-04, -5.8518e-04, -5.9662e-04, -4.7632e-04,\n",
      "         8.5531e-04,  2.0469e-04,  5.6045e-04, -1.4527e-04, -4.7210e-04,\n",
      "         4.4356e-04,  1.9082e-03,  1.9078e-03,  2.2693e-04,  1.2929e-04,\n",
      "        -7.7379e-04, -2.3852e-04, -1.5361e-03,  1.5805e-03,  3.1634e-04,\n",
      "        -1.2537e-03, -3.3419e-04, -9.5173e-05, -2.7330e-04, -2.0228e-04,\n",
      "         1.3541e-03, -9.4387e-04,  7.2199e-04, -6.9580e-05,  1.5659e-03,\n",
      "         7.8306e-04,  1.5826e-04, -5.2357e-04,  9.7787e-04, -9.7407e-05,\n",
      "         8.6552e-04, -4.5601e-04, -4.2795e-04,  4.9436e-04, -1.1445e-03,\n",
      "        -4.2995e-04, -2.3252e-05,  1.4103e-04, -1.8029e-04,  2.7331e-05,\n",
      "         2.6142e-05, -8.2179e-05, -4.1872e-04, -3.2792e-04, -8.2882e-05,\n",
      "        -5.8619e-04,  7.0922e-04, -7.9670e-05, -1.3830e-03, -9.6401e-04,\n",
      "        -8.7830e-04, -9.0283e-04, -8.7396e-04, -8.4036e-05,  1.6227e-03,\n",
      "        -2.2510e-04, -6.2689e-04, -6.4194e-04,  8.3809e-04, -2.5902e-04,\n",
      "        -1.8347e-04,  6.4502e-04, -9.7537e-04,  1.2011e-03, -4.1448e-04,\n",
      "         1.1801e-03,  2.3672e-04,  1.4237e-03,  5.4651e-05, -1.4627e-03,\n",
      "         6.1732e-05, -8.9366e-04,  1.2860e-04, -9.9728e-04,  3.7601e-04,\n",
      "         1.0382e-03, -1.1011e-03, -8.9718e-04,  7.6003e-04, -5.4907e-05,\n",
      "        -1.0343e-03,  1.2996e-03, -5.3367e-04,  1.0564e-04, -1.5646e-03,\n",
      "        -3.7002e-04])\n",
      "\n",
      "cls.predictions.bias:\n",
      "\n",
      "tensor([-0.0060, -0.0060, -0.0061,  ..., -0.0060, -0.0060, -0.0060])\n",
      "\n",
      "cls.predictions.transform.dense.weight:\n",
      "\n",
      "tensor([[ 0.0422,  0.0039, -0.0224,  ...,  0.0345,  0.0121,  0.0064],\n",
      "        [-0.0018, -0.0124, -0.0055,  ..., -0.0321, -0.0025, -0.0017],\n",
      "        [-0.0020,  0.0007, -0.0192,  ...,  0.0074, -0.0005, -0.0266],\n",
      "        ...,\n",
      "        [ 0.0392,  0.0093, -0.0278,  ..., -0.0055, -0.0284,  0.0005],\n",
      "        [-0.0197, -0.0111,  0.0015,  ...,  0.0058, -0.0081,  0.0040],\n",
      "        [-0.0064,  0.0015, -0.0108,  ...,  0.0292, -0.0146,  0.0072]])\n",
      "\n",
      "cls.predictions.transform.dense.bias:\n",
      "\n",
      "tensor([-1.1458e-03,  1.0045e-03,  1.0671e-03,  2.0776e-03,  1.7792e-03,\n",
      "        -4.2021e-04, -3.7041e-04, -1.8273e-03, -7.8703e-05, -1.9294e-03,\n",
      "        -8.6740e-04,  1.4064e-03,  4.5995e-04,  1.1705e-04, -2.4948e-03,\n",
      "         7.3898e-04,  1.7053e-03,  8.5476e-04, -1.5408e-04, -1.9808e-03,\n",
      "        -1.3063e-05, -1.0148e-03,  4.9966e-04,  6.1147e-04,  6.8937e-05,\n",
      "         2.1409e-06,  1.2022e-03, -8.7609e-04,  1.0630e-03,  4.0398e-04,\n",
      "        -1.7799e-03,  2.4481e-03, -1.0735e-03, -6.8052e-04, -1.1626e-03,\n",
      "         5.9427e-04, -6.3929e-04, -6.2982e-04,  1.0005e-03,  2.9276e-04,\n",
      "         9.7832e-04, -2.0234e-04,  1.2630e-03,  7.0357e-04, -1.0036e-03,\n",
      "        -4.2671e-04,  9.1033e-04, -1.5191e-04, -3.6807e-04,  7.2212e-04,\n",
      "        -8.6514e-04,  9.5078e-04,  1.1442e-03, -2.9144e-03, -2.0152e-03,\n",
      "         6.2228e-04, -8.0125e-04,  2.7451e-03,  5.9604e-05,  1.4624e-04,\n",
      "         5.7900e-04, -1.7971e-03,  5.6678e-04,  7.9290e-04,  3.3792e-05,\n",
      "         2.1152e-04, -6.8849e-05,  1.0026e-03, -1.8195e-03, -1.4350e-03,\n",
      "        -4.4429e-04, -1.0289e-03,  4.1948e-04, -1.9063e-03,  2.3822e-03,\n",
      "         2.8025e-03, -1.4556e-04, -1.0653e-03,  6.7183e-04, -6.5097e-04,\n",
      "         6.6054e-05, -1.5074e-03, -2.4475e-03,  1.3828e-03,  1.9144e-03,\n",
      "        -7.3592e-04,  2.9430e-05,  9.0024e-04, -2.4325e-03, -1.1649e-03,\n",
      "        -4.0294e-04,  4.9353e-04,  1.4616e-03, -8.2432e-04, -4.8203e-05,\n",
      "        -3.5786e-05, -5.0325e-04,  1.0225e-03, -1.0821e-04, -8.5497e-04,\n",
      "         7.6649e-04,  9.6293e-05,  4.0780e-04,  1.4207e-03,  6.5339e-04,\n",
      "         2.1570e-03,  3.3749e-04, -7.0461e-04, -1.3022e-04, -1.1458e-03,\n",
      "        -2.1110e-03,  8.5726e-04, -6.8119e-04,  9.1288e-04,  2.6435e-04,\n",
      "        -8.9876e-04,  7.5057e-04, -1.8334e-04, -1.0375e-03, -5.8801e-04,\n",
      "         8.9338e-04,  1.3573e-03,  8.8337e-04,  9.1533e-05,  5.2668e-04,\n",
      "        -7.4968e-04, -3.7223e-04, -1.6391e-03,  1.2664e-04,  6.9441e-04,\n",
      "         1.5764e-03,  1.3852e-03, -1.2297e-03,  8.0769e-04,  1.5147e-03,\n",
      "         1.5521e-03,  1.4876e-04, -1.5318e-03, -2.6157e-03,  1.5517e-03,\n",
      "        -6.2889e-04, -1.5301e-03,  1.0799e-04, -1.4777e-03, -2.6170e-04,\n",
      "        -1.6362e-03,  9.1783e-04, -2.1114e-04, -2.3724e-04, -2.1138e-03,\n",
      "         7.1654e-04,  6.5465e-04, -1.4706e-03,  1.2070e-03, -3.5741e-04,\n",
      "        -8.1113e-04,  1.6969e-03,  9.0071e-05, -1.7945e-03, -6.2437e-04,\n",
      "         1.0429e-03, -1.9853e-03,  7.8517e-04,  1.1691e-03, -2.1397e-03,\n",
      "        -2.3511e-03, -1.4928e-03, -7.1135e-05,  6.3204e-04, -1.3111e-03,\n",
      "         1.4833e-03,  1.6981e-03,  2.6609e-03,  2.1539e-03,  8.6150e-04,\n",
      "         1.0721e-03,  9.9765e-04, -1.7722e-03,  1.2017e-04,  3.0636e-04,\n",
      "         1.0113e-03, -5.3974e-04,  1.7135e-04,  1.5598e-03, -1.8388e-04,\n",
      "        -8.1928e-04, -5.0321e-04,  8.5881e-04,  2.0231e-04, -8.2602e-04,\n",
      "         2.7017e-04,  9.1581e-04, -1.8072e-03, -5.7608e-06,  6.4788e-04,\n",
      "        -3.2962e-03, -2.1150e-03,  2.4292e-04, -3.8065e-04,  7.9129e-04,\n",
      "        -2.3910e-04, -8.5740e-04, -1.3668e-03,  7.8203e-04, -1.0788e-03,\n",
      "         3.2653e-04, -3.0345e-03, -1.9998e-06,  7.0829e-04,  9.9360e-04,\n",
      "         2.0861e-03,  1.5009e-04, -2.3726e-03,  3.6332e-04,  2.1016e-03,\n",
      "         2.3749e-03, -7.8896e-04,  7.4710e-04, -2.4679e-03, -3.0678e-03,\n",
      "         2.2731e-03, -9.9353e-04,  4.7158e-04, -1.0314e-03,  7.5764e-04,\n",
      "         1.9364e-03,  1.5572e-03, -5.2031e-04,  1.5619e-03, -2.5058e-04,\n",
      "        -1.3977e-03, -1.0262e-03, -1.4685e-03, -4.8439e-04, -1.3344e-03,\n",
      "         6.2889e-04,  4.4914e-04,  1.6644e-03,  1.6454e-03,  1.6523e-03,\n",
      "         2.0814e-03, -7.2253e-04, -1.9027e-03, -6.5179e-04,  5.4769e-04,\n",
      "         3.9653e-05,  8.1184e-04,  3.0818e-04, -1.6461e-03,  1.3320e-04,\n",
      "         6.6012e-04, -9.8760e-04,  1.2080e-03,  7.7988e-04, -1.0309e-03,\n",
      "         7.2692e-04])\n",
      "\n",
      "cls.predictions.transform.LayerNorm.weight:\n",
      "\n",
      "tensor([1.0039, 1.0007, 1.0037, 1.0016, 1.0012, 1.0032, 1.0034, 1.0049, 1.0039,\n",
      "        1.0053, 1.0029, 1.0029, 1.0030, 1.0036, 1.0053, 1.0042, 1.0052, 1.0053,\n",
      "        1.0043, 1.0051, 1.0034, 1.0043, 1.0056, 1.0047, 1.0031, 1.0026, 1.0043,\n",
      "        1.0049, 1.0035, 1.0039, 1.0049, 1.0034, 1.0041, 1.0025, 1.0044, 1.0047,\n",
      "        1.0042, 1.0036, 1.0045, 1.0024, 1.0049, 1.0031, 1.0042, 1.0047, 1.0041,\n",
      "        1.0055, 1.0039, 1.0040, 1.0025, 1.0026, 1.0046, 1.0043, 1.0020, 1.0055,\n",
      "        1.0050, 1.0033, 1.0052, 1.0009, 1.0046, 1.0030, 1.0047, 1.0055, 1.0041,\n",
      "        1.0044, 1.0024, 1.0029, 1.0032, 1.0040, 1.0033, 1.0048, 1.0029, 1.0041,\n",
      "        1.0036, 1.0043, 0.9995, 1.0011, 1.0027, 1.0038, 1.0050, 1.0017, 1.0045,\n",
      "        1.0040, 1.0052, 1.0025, 1.0047, 1.0034, 1.0053, 1.0040, 1.0038, 1.0022,\n",
      "        1.0030, 1.0047, 1.0031, 1.0049, 1.0046, 1.0023, 1.0050, 1.0045, 1.0047,\n",
      "        1.0034, 1.0028, 1.0034, 1.0031, 1.0041, 1.0028, 1.0025, 1.0047, 1.0048,\n",
      "        1.0042, 1.0040, 1.0051, 1.0039, 1.0049, 1.0042, 1.0055, 1.0038, 1.0048,\n",
      "        1.0005, 1.0042, 1.0041, 1.0040, 1.0040, 1.0036, 1.0031, 1.0050, 1.0027,\n",
      "        1.0048, 1.0044, 1.0053, 1.0029, 1.0056, 1.0046, 1.0025, 1.0023, 1.0028,\n",
      "        1.0035, 1.0043, 1.0046, 1.0055, 1.0050, 1.0047, 1.0046, 1.0042, 1.0042,\n",
      "        1.0023, 1.0049, 1.0037, 1.0014, 1.0033, 1.0049, 1.0037, 1.0039, 1.0044,\n",
      "        1.0038, 1.0039, 1.0037, 1.0044, 1.0020, 1.0041, 1.0013, 1.0054, 1.0040,\n",
      "        1.0039, 1.0040, 1.0058, 1.0053, 1.0045, 1.0036, 1.0042, 1.0042, 1.0049,\n",
      "        1.0046, 1.0003, 1.0035, 1.0044, 1.0048, 1.0033, 1.0044, 1.0049, 1.0022,\n",
      "        1.0037, 1.0041, 1.0019, 1.0039, 1.0041, 1.0028, 1.0020, 1.0022, 1.0045,\n",
      "        1.0045, 1.0039, 1.0052, 1.0043, 1.0020, 1.0036, 1.0055, 1.0032, 1.0025,\n",
      "        1.0050, 1.0034, 1.0043, 1.0040, 1.0056, 1.0048, 1.0051, 1.0017, 1.0043,\n",
      "        1.0050, 1.0037, 1.0040, 1.0052, 1.0027, 1.0049, 1.0027, 1.0037, 1.0022,\n",
      "        1.0017, 1.0047, 1.0025, 1.0034, 1.0019, 1.0056, 1.0047, 1.0044, 1.0031,\n",
      "        1.0043, 1.0040, 1.0045, 1.0034, 1.0043, 1.0025, 1.0032, 1.0043, 1.0028,\n",
      "        1.0053, 1.0043, 1.0051, 1.0030, 1.0029, 1.0035, 1.0022, 1.0044, 1.0050,\n",
      "        1.0028, 1.0041, 1.0052, 1.0027, 1.0029, 1.0045, 1.0045, 1.0036, 1.0052,\n",
      "        1.0028, 1.0049, 1.0038, 1.0040])\n",
      "\n",
      "cls.predictions.transform.LayerNorm.bias:\n",
      "\n",
      "tensor([-0.0041, -0.0003,  0.0040, -0.0010,  0.0028,  0.0043, -0.0043, -0.0049,\n",
      "        -0.0039, -0.0057, -0.0047,  0.0037, -0.0027, -0.0034, -0.0056,  0.0043,\n",
      "         0.0056,  0.0054, -0.0040, -0.0052,  0.0035,  0.0044,  0.0057,  0.0049,\n",
      "        -0.0028,  0.0021,  0.0042, -0.0050,  0.0041, -0.0034, -0.0056,  0.0046,\n",
      "        -0.0045,  0.0020, -0.0049, -0.0046, -0.0046,  0.0033, -0.0037, -0.0033,\n",
      "         0.0049, -0.0026, -0.0042,  0.0054,  0.0037, -0.0055, -0.0035,  0.0040,\n",
      "         0.0004, -0.0028, -0.0045, -0.0037, -0.0024, -0.0056, -0.0051, -0.0030,\n",
      "        -0.0052, -0.0013, -0.0049, -0.0031,  0.0032, -0.0055,  0.0041, -0.0044,\n",
      "        -0.0028,  0.0034,  0.0013,  0.0039, -0.0043, -0.0048, -0.0028, -0.0046,\n",
      "        -0.0032, -0.0052,  0.0006,  0.0035, -0.0020, -0.0042,  0.0047, -0.0003,\n",
      "         0.0037, -0.0047, -0.0053, -0.0016,  0.0054, -0.0038,  0.0055,  0.0047,\n",
      "        -0.0047, -0.0036,  0.0040,  0.0050, -0.0023, -0.0047, -0.0040, -0.0016,\n",
      "        -0.0052,  0.0045, -0.0047, -0.0041,  0.0031, -0.0035,  0.0039,  0.0037,\n",
      "         0.0030,  0.0036,  0.0051, -0.0047, -0.0044, -0.0041, -0.0056,  0.0041,\n",
      "        -0.0049,  0.0040,  0.0055, -0.0040,  0.0053,  0.0016, -0.0050, -0.0047,\n",
      "         0.0023,  0.0039,  0.0031, -0.0035,  0.0051, -0.0030, -0.0049, -0.0052,\n",
      "        -0.0053,  0.0037,  0.0056,  0.0049, -0.0046,  0.0015,  0.0030, -0.0038,\n",
      "        -0.0044, -0.0055, -0.0056,  0.0053,  0.0052, -0.0050, -0.0039, -0.0048,\n",
      "         0.0015, -0.0053,  0.0034,  0.0024,  0.0023, -0.0051,  0.0051, -0.0005,\n",
      "        -0.0046,  0.0030,  0.0046, -0.0044,  0.0057, -0.0023, -0.0051, -0.0030,\n",
      "         0.0050, -0.0049,  0.0044, -0.0043, -0.0059, -0.0053, -0.0053, -0.0039,\n",
      "         0.0040, -0.0042, -0.0048,  0.0046, -0.0006,  0.0047,  0.0052,  0.0053,\n",
      "        -0.0029, -0.0047,  0.0050,  0.0031,  0.0040, -0.0047,  0.0011, -0.0040,\n",
      "        -0.0036, -0.0028,  0.0022,  0.0039, -0.0046, -0.0043, -0.0040,  0.0054,\n",
      "        -0.0049,  0.0019,  0.0048, -0.0057, -0.0045, -0.0029, -0.0049, -0.0031,\n",
      "        -0.0042, -0.0041, -0.0058,  0.0051, -0.0049,  0.0023, -0.0056,  0.0051,\n",
      "         0.0045, -0.0040,  0.0052, -0.0031, -0.0054, -0.0024,  0.0043,  0.0047,\n",
      "        -0.0002,  0.0051, -0.0047, -0.0054,  0.0038, -0.0057,  0.0034, -0.0045,\n",
      "         0.0020,  0.0053,  0.0046,  0.0049,  0.0038,  0.0043, -0.0036, -0.0046,\n",
      "        -0.0046,  0.0027, -0.0054,  0.0037,  0.0053, -0.0026,  0.0040,  0.0031,\n",
      "         0.0048, -0.0042, -0.0050, -0.0026,  0.0041, -0.0050,  0.0029,  0.0033,\n",
      "        -0.0046,  0.0043,  0.0040, -0.0054,  0.0030,  0.0048, -0.0036,  0.0048])\n",
      "\n",
      "cls.predictions.decoder.weight:\n",
      "\n",
      "tensor([[ 0.0059,  0.0044, -0.0057,  ..., -0.0060,  0.0051, -0.0059],\n",
      "        [ 0.0134,  0.0080, -0.0361,  ..., -0.0190, -0.0160, -0.0436],\n",
      "        [ 0.0053,  0.0058, -0.0378,  ...,  0.0103,  0.0021, -0.0198],\n",
      "        ...,\n",
      "        [-0.0167, -0.0014,  0.0057,  ..., -0.0296,  0.0171,  0.0228],\n",
      "        [-0.0108,  0.0360, -0.0266,  ..., -0.0060, -0.0037,  0.0164],\n",
      "        [-0.0002, -0.0251, -0.0371,  ..., -0.0160, -0.0234, -0.0275]])\n",
      "\n",
      "cls.predictions.decoder.bias:\n",
      "\n",
      "tensor([-0.0060, -0.0060, -0.0061,  ..., -0.0060, -0.0060, -0.0060])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a165868fb06436fbe620808ed3027c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.3176, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7d8df9056d401eb319d81392e6ec7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-10\n",
      "Configuration saved in my_pretrained_model\\checkpoint-10\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.202439308166504, 'eval_runtime': 0.2689, 'eval_samples_per_second': 33.472, 'eval_steps_per_second': 3.719, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in my_pretrained_model\\checkpoint-10\\pytorch_model.bin\n",
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-20] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.4692, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cdd6df4f3547eb9a9db0d3c37b8fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-20\n",
      "Configuration saved in my_pretrained_model\\checkpoint-20\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.14184284210205, 'eval_runtime': 0.3297, 'eval_samples_per_second': 27.298, 'eval_steps_per_second': 3.033, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in my_pretrained_model\\checkpoint-20\\pytorch_model.bin\n",
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-30] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.6857, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d03e1d8878648439426736594aeedab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-30\n",
      "Configuration saved in my_pretrained_model\\checkpoint-30\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.799484252929688, 'eval_runtime': 0.2979, 'eval_samples_per_second': 30.213, 'eval_steps_per_second': 3.357, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in my_pretrained_model\\checkpoint-30\\pytorch_model.bin\n",
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-10] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from my_pretrained_model\\checkpoint-30 (score: 8.799484252929688).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 36.0433, 'train_samples_per_second': 6.242, 'train_steps_per_second': 0.832, 'train_loss': 8.490803527832032, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=8.490803527832032, metrics={'train_runtime': 36.0433, 'train_samples_per_second': 6.242, 'train_steps_per_second': 0.832, 'train_loss': 8.490803527832032, 'epoch': 3.0})"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8ee48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
