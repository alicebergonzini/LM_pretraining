{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd41ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263daf17",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING\n",
    "\n",
    "Per ottenere un dataset che possa essere utilizzato come training del nostro language model partiamo dai file conllu che contengono i testi annotati di wikipedia italiana. Da questi file vogliamo ottenere una struttura dati che per ogni frase riporti id, testo e indice di Gulpease (per ora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5090422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/conllu\\\\chat.conllu', 'data/conllu\\\\text_all.conllu']\n"
     ]
    }
   ],
   "source": [
    "#si ottengono i path di ogni file per il pretraining e si salvano in una lista\n",
    "ds_directory = \"data/conllu\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(ds_directory):\n",
    "    file_path = os.path.join(ds_directory, file_name)\n",
    "    ds_files.append(file_path)\n",
    "print(ds_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a4027dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef comp_gulpease(ns, nw, nl):\\n    g_value = 89 + ((300*ns - 10*nl)/nw) #è corretta questa formula?\\n    return g_value\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#funzione che calcola gulpease - io in teoria userò read-it\n",
    "'''\n",
    "def comp_gulpease(ns, nw, nl):\n",
    "    g_value = 89 + ((300*ns - 10*nl)/nw) #è corretta questa formula?\n",
    "    return g_value\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b46c94a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_readit_scores(file_path):\\n    readit_list = []\\n    for line in open(file_path, \\'r\\', encoding = \"utf-8\"): \\n        print(line)\\n        if line.startswith(\"# text\"):\\n            current_sent = line[9:].rstrip(\\'\\n\\')\\n            sent_id = load_document(current_sent)\\n            r_score = get_sent_readability(sent_id)\\n            readit_list.append(r_score)\\n    return readit_list\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Qui il codice per ottenere l'indicie di leggibilità\n",
    "\n",
    "SERVER_PATH = \"http://api.italianlp.it\"\n",
    "\n",
    "#con una post si carica il documento nel db del server e si caclcola la leggibiità \n",
    "def load_document(text):\n",
    "    r = requests.post(SERVER_PATH + '/documents/',           # carica il documento nel database del server\n",
    "                      data={'text': text,                    # durante il caricamento viene eseguita un'analisi linguistica necessaria per calcolare la leggibilita'\n",
    "                          'lang': 'IT',\n",
    "                          'extra_tasks': [\"readability\"]     # chiede al server di calcolare anche la leggibilità del docuemnto\n",
    "                  })\n",
    "    doc_id = r.json()['id']                                  # id del documento nel database del server, che serve per richiedere i risultati delle analisi\n",
    "    return doc_id\n",
    "\n",
    "#si fa una get per ottenere i risultati, in questo caso siamo interessati solo alla leggibilità globale\n",
    "def get_sent_readability(doc_id):\n",
    "    r = requests.get(SERVER_PATH + '/documents/details/%s' % doc_id)\n",
    "    result = r.json()\n",
    "    sent_dict = result['sentences']['data'][0]\n",
    "    sent_readability = sent_dict[\"readability_score_all\"]        #prendiamo la leggibilità globale\n",
    "    return sent_readability\n",
    "\n",
    "def get_random_score():\n",
    "    rand_score = random.randint(0,100)\n",
    "    return rand_score\n",
    "\n",
    "#funzione per iterare su ciascuna frase \n",
    "'''def get_readit_scores(file_path):\n",
    "    readit_list = []\n",
    "    for line in open(file_path, 'r', encoding = \"utf-8\"): \n",
    "        print(line)\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            sent_id = load_document(current_sent)\n",
    "            r_score = get_sent_readability(sent_id)\n",
    "            readit_list.append(r_score)\n",
    "    return readit_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "748967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che legge i file conllu riga per riga, estraendo id, testo e indice di complessità di ciascuna frase \n",
    "def extract(file_path, n_file):\n",
    "    id_list = []\n",
    "    text_list = []\n",
    "    readit_list = []\n",
    "    current_id=\"\"\n",
    "    current_sent=\"\"\n",
    "    for line in open(file_path, 'r', encoding='utf-8'):\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            #gulp = comp_gulpease(1, len(words), sum(len(word) for word in words))\n",
    "            print(current_sent)\n",
    "            #sent_id = load_document(current_sent)\n",
    "            #r_score = get_sent_readability(sent_id)\n",
    "            r_score = get_random_score()\n",
    "            readit_list.append(r_score)\n",
    "            text_list.append(current_sent)\n",
    "            #gulp_list.append(gulp)\n",
    "        elif line.startswith(\"# sent_id\"):\n",
    "            current_id = re.sub(r'\\D', '', line)\n",
    "            id_list.append(f'{current_id}_{str(n_file)}') #per avere id univoco ho aggiunto numero del file\n",
    "    return id_list, text_list, readit_list\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b4cff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Prima Guerra Mondiale, conosciuta anche come la Grande Guerra, fu un conflitto globale che ebbe luogo principalmente in Europa dal 28 luglio 1914 al 11 novembre 1918.\n",
      "Coinvolse le principali potenze mondiali dell'epoca, divise in due alleanze contrapposte:\n",
      "gli Alleati, guidati da Francia, Regno Unito, Russia (successivamente sostituita dall'Impero britannico e dagli Stati Uniti), e l'Intesa Centrale, composta da Germania, Austria-Ungheria, Impero Ottomano e Bulgaria.\n",
      "Le cause della guerra possono essere attribuite a una serie di fattori, tra cui tensioni politiche, rivalità coloniali, nazionalismo, militarismo e sistemi di alleanze che resero il conflitto inevitabile dopo l'assassinio dell'arciduca Francesco Ferdinando d'Austria, erede al trono austro-ungarico, a Sarajevo nel giugno 1914.\n",
      "La guerra fu caratterizzata da una serie di nuove tattiche e tecnologie militari, tra cui trincee, mitragliatrici, gas tossici e bombardamenti aerei, che portarono a un conflitto di logoramento su vasta scala.\n",
      "Le battaglie più significative includono la Battaglia della Marna, la Battaglia di Verdun, la Battaglia di Gallipoli e la Battaglia della Somme.\n",
      "Durante il conflitto, il fronte occidentale si stabilizzò in una linea di trincee che si estendeva dalla Svizzera al Mare del Nord, mentre sul fronte orientale ci furono movimenti più ampi delle truppe.\n",
      "Gli Stati Uniti entrarono in guerra nel 1917 a fianco degli Alleati, contribuendo a sbilanciare ulteriormente il conflitto.\n",
      "La guerra ebbe un costo umano devastante, con milioni di morti e feriti da entrambe le parti, sia militari che civili.\n",
      "Alla fine, la pressione economica, sociale e politica sull'Impero tedesco e sull'Intesa Centrale portò alla sconfitta di quest'ultima.\n",
      "Il 11 novembre 1918, l'Armistizio di Compiègne pose fine alle ostilità, segnando la vittoria degli Alleati.\n",
      "Il Trattato di Versailles, firmato nel 1919, pose fine formalmente al conflitto e impose pesanti riparazioni e restrizioni all'Impero tedesco, segnando l'inizio di un periodo di instabilità politica ed economica che avrebbe contribuito allo scoppio della Seconda Guerra Mondiale due decenni dopo.\n",
      "La Prima Guerra Mondiale è considerata una delle più grandi catastrofi del XX secolo, con conseguenze che hanno plasmato il corso della storia mondiale.\n",
      "Le guerre puniche furono una serie di conflitti tra la Repubblica Romana e l'antica città-stato di Cartagine, situata nell'attuale Tunisia.\n",
      "Questi conflitti ebbero luogo durante il periodo compreso tra il 264 a.C. e il 146 a.C.\n",
      "La Prima Guerra Punica, dal 264 al 241 a.C., fu combattuta principalmente per il controllo della Sicilia.\n",
      "La guerra vide Roma emergere vittoriosa dopo una lunga serie di battaglie navali e terrestri.\n",
      "Una delle battaglie più famose fu la Battaglia delle Isole Lipari nel 260 a.C., dove Roma sconfisse la flotta cartaginese, consolidando il proprio dominio marittimo nel Mediterraneo occidentale.\n",
      "La guerra si concluse con il Trattato di Lutazio nel 241 a.C., che vide Cartagine cedere la Sicilia a Roma.\n",
      "La Seconda Guerra Punica, dal 218 al 201 a.C., fu combattuta principalmente da Roma contro il leggendario generale cartaginese Annibale.\n",
      "Annibale attraversò le Alpi con il suo esercito e inflisse pesanti sconfitte alle forze romane, inclusa la famosa vittoria nella Battaglia di Canne nel 216 a.C. Tuttavia, Roma alla fine prevalse sotto la guida dei generali Scipione l'Africano e Publio Cornelio Scipione, che condussero la guerra in Africa e sconfissero le forze cartaginesi nella Battaglia di Zama nel 202 a.C. Il risultato fu il Trattato di Pace di Siface nel 201 a.C., che pose fine alla Seconda Guerra Punica e vide Cartagine cedere la Spagna e pagare pesanti riparazioni a Roma.\n",
      "La Terza Guerra Punica, dal 149 al 146 a.C., fu provocata dalle crescenti preoccupazioni romane riguardo alla potenza di Cartagine.\n",
      "Roma, guidata dal console Publio Cornelio Scipione Emiliano, assediò e distrusse Cartagine dopo una lunga e devastante campagna militare.\n",
      "La città venne rasa al suolo e la sua popolazione venne ridotta in schiavitù, segnando la fine definitiva della potenza cartaginese nel Mediterraneo.\n",
      "La RAM è una memoria volatile, il che significa che i dati in essa contenuti vengono persi quando il computer viene spento o riavviato.\n",
      "La RAM funge da area di lavoro per il processore del computer, consentendo il caricamento temporaneo di dati e istruzioni utilizzati attivamente durante l'esecuzione dei programmi.\n",
      "Questo include il sistema operativo, le applicazioni software e i dati generati dall'utente.\n",
      "L'agricoltura in Italia è molto importante perché fornisce cibo per le persone e materia prima per molte industrie.\n",
      "In Italia, ci sono diverse regioni che producono vari tipi di cibo grazie a terreni diversi e un clima vario.\n",
      "Nel nord Italia, ci sono molte aree pianeggianti e collinari che sono ottime per la coltivazione di cereali come grano e mais, così come frutta come mele e pere.\n",
      "Alcune zone, come la pianura padana, sono famose per i loro risi, che vengono coltivati in risaie.\n",
      "Nelle regioni centrali e meridionali, dove il clima è più caldo, si coltivano molte verdure come pomodori, zucchine, melanzane e peperoni.\n",
      "In queste zone si trovano anche molti uliveti per la produzione di olio d'oliva, e vigneti per la produzione di vino.\n",
      "L'Italia è famosa per i suoi vini, come il Chianti in Toscana e il Barolo in Piemonte.\n",
      "L'agricoltura in Italia è spesso di tipo familiare, con molte piccole aziende agricole gestite da famiglie.\n",
      "Tuttavia, ci sono anche aziende agricole più grandi che producono cibo su larga scala.\n",
      "Gli esseri umani respirano attraverso un processo chiamato respirazione.\n",
      "La respirazione coinvolge l'assunzione di ossigeno dall'ambiente circostante e l'espulsione di anidride carbonica, un prodotto di scarto del metabolismo, dall'organismo.\n",
      "I Pokémon sono una popolare serie di creature immaginarie introdotte da Nintendo, Game Freak e Creatures Inc. nel 1996.\n",
      "Sono diventati noti attraverso i videogiochi, i cartoni animati, i film, i giocattoli e molti altri prodotti.\n",
      "La parola \"Pokémon\" è una contrazione di \"Pocket Monsters\" (mostri tascabili), poiché i giocatori possono \"catturare\" e \"allenare\" queste creature nel mondo immaginario dei giochi.\n",
      "In breve, i Pokémon sono esseri fantastici che vivono in un mondo immaginario, ognuno con un aspetto, abilità e personalità unici.\n",
      "I giocatori assumono il ruolo di Allenatori Pokémon, il cui obiettivo principale è catturare, allenare e fare combattere i Pokémon tra loro.\n",
      "Ogni Pokémon ha una o più abilità speciali e può apprendere mosse diverse durante il gioco.\n",
      "Ci sono centinaia di specie di Pokémon, ognuna appartenente a uno o più \"tipi\" (come acqua, fuoco, erba, ecc.), che possono avere vantaggi o svantaggi nei confronti di altri tipi.\n",
      "I Pokémon sono diventati una delle franchigie di intrattenimento più famose e influenti al mondo, con milioni di fan in tutto il globo.\n",
      "Oltre ai videogiochi, la serie Pokémon include anche una serie animata televisiva, una vasta gamma di giocattoli e oggetti da collezione, film, fumetti e molto altro ancora.\n",
      "La serie ha contribuito a creare una cultura popolare unica e continua ad avere un impatto significativo sulla cultura di massa.\n",
      "L'allunaggio è la discesa di un veicolo sulla Luna.\n",
      "Si distingue tra allunaggio duro, cioè un impatto che comporta la distruzione del veicolo, e allunaggio morbido, che permette al veicolo di arrivare intatto sulla superficie lunare.\n",
      "Il programma Luna, partito nel 1959 con la sonda Luna 2, inviò il primo veicolo riuscito ad impattare con il satellite.\n",
      "Luna 9, il 3 febbraio 1966, eseguì il primo atterraggio morbido sulla Luna.\n",
      "Il primo allunaggio di un essere umano, il 20 luglio 1969, fu quello di Neil Armstrong, comandante della missione Apollo 11, e di Buzz Aldrin, mentre il loro compagno Michael Collins, rimasto in orbita, controllava il modulo di comando Columbia.\n",
      "La prima missione verso la Luna dopo il periodo aureo, conclusosi nel 1976 con Luna 24, ultima missione automatica sovietica, fu organizzata dal Giappone con la sonda Hiten-Hagoromo lanciata il 24 gennaio 1990, che collaudò una nuova rotta lunare molto più economica ma anche molto più lenta;\n",
      "il rilascio della sonda Hagoromo fallì per l'interruzione dei contatti radio e alla fine Hiten entrò a sua volta in orbita lunare il 2 ottobre 1991;\n",
      "esaurito il combustibile la sonda fu fatta precipitare sul suolo lunare il 10 aprile 1993.\n",
      "La sonda spaziale SMART-1, dell'Agenzia spaziale europea (ESA) fu lanciata il 27 settembre 2003, ed arrivò nei pressi della Luna ad inizio 2005 (il motivo di un tempo così lungo è da trovarsi nel suo motore a ioni, un nuovo tipo di propulsione spaziale molto economico ma piuttosto lento).\n",
      "SMART-1 effettuò una ricognizione completa della Luna e produsse una mappa a raggi X della sua superficie[1].\n",
      "La sonda si schiantò sulla Luna il 3 settembre 2006.\n",
      "L'India ha fatto scendere sul suolo lunare il modulo Aditya (Moon Impact Probe), alle 15:04 UTC del 14 novembre 2008; il modulo era stato sganciato dalla sonda Chandrayaan-1 lanciata il 22 ottobre dalla base di Srihakot ed entrata in orbita intorno alla Luna il 4 novembre.\n",
      "L'India è quindi quinta nella lista dei paesi o enti spaziali che hanno raggiunto la superficie lunare.\n",
      "La Cina ha lanciato verso la Luna la sonda Chang'e 1, che il 1º marzo 2009 ha concluso la missione schiantandosi sul suolo lunare.\n",
      "L'allunaggio è la discesa di un veicolo sulla Luna.\n",
      "Si distingue tra allunaggio duro, cioè un impatto che comporta la distruzione del veicolo, e allunaggio morbido, che permette al veicolo di arrivare intatto sulla superficie lunare.\n",
      "Il programma Luna, partito nel 1959 con la sonda Luna 2, inviò il primo veicolo riuscito ad impattare con il satellite.\n",
      "Luna 9, il 3 febbraio 1966, eseguì il primo atterraggio morbido sulla Luna.\n",
      "Il primo allunaggio di un essere umano, il 20 luglio 1969, fu quello di Neil Armstrong, comandante della missione Apollo 11, e di Buzz Aldrin, mentre il loro compagno Michael Collins, rimasto in orbita, controllava il modulo di comando Columbia.\n",
      "La prima missione verso la Luna dopo il periodo aureo, conclusosi nel 1976 con Luna 24, ultima missione automatica sovietica, fu organizzata dal Giappone con la sonda Hiten-Hagoromo lanciata il 24 gennaio 1990, che collaudò una nuova rotta lunare molto più economica ma anche molto più lenta;\n",
      "il rilascio della sonda Hagoromo fallì per l'interruzione dei contatti radio e alla fine Hiten entrò a sua volta in orbita lunare il 2 ottobre 1991;\n",
      "esaurito il combustibile la sonda fu fatta precipitare sul suolo lunare il 10 aprile 1993.\n",
      "La sonda spaziale SMART-1, dell'Agenzia spaziale europea (ESA) fu lanciata il 27 settembre 2003, ed arrivò nei pressi della Luna ad inizio 2005 (il motivo di un tempo così lungo è da trovarsi nel suo motore a ioni, un nuovo tipo di propulsione spaziale molto economico ma piuttosto lento).\n",
      "SMART-1 effettuò una ricognizione completa della Luna e produsse una mappa a raggi X della sua superficie[1].\n",
      "La sonda si schiantò sulla Luna il 3 settembre 2006.\n",
      "L'India ha fatto scendere sul suolo lunare il modulo Aditya (Moon Impact Probe), alle 15:04 UTC del 14 novembre 2008; il modulo era stato sganciato dalla sonda Chandrayaan-1 lanciata il 22 ottobre dalla base di Srihakot ed entrata in orbita intorno alla Luna il 4 novembre.\n",
      "L'India è quindi quinta nella lista dei paesi o enti spaziali che hanno raggiunto la superficie lunare.\n",
      "La Cina ha lanciato verso la Luna la sonda Chang'e 1, che il 1º marzo 2009 ha concluso la missione schiantandosi sul suolo lunare.\n",
      "Va osservato che tutte queste sonde hanno realizzato un allunaggio distruttivo e non morbido, non disponendo dei retrorazzi necessari per rallentare il veicolo ed evitarne la distruzione.\n",
      "Tuttavia, il 2 dicembre 2013, la Cina ha lanciato la navicella Chang'e 3 contenente la sonda Yutu (il cui nome significa \"coniglio di giada\"), la quale, il 14 dicembre, si è sganciata da Chang'e 3 ed ha effettuato un allunaggio morbido.\n",
      "In questo modo la Cina è divenuta il terzo paese ad aver compiuto questo tipo di allunaggio dopo Unione Sovietica e Stati Uniti.\n",
      "La Russia, in un primo momento, aveva programmato per il 2012 il lancio di una sonda lunare, Luna-Glob 1.\n",
      "Successivamente si è deciso di rimandare al 2024.\n",
      "L'Agenzia spaziale europea e la Repubblica Popolare Cinese hanno entrambe piani per esplorare la Luna, la prima mediante sonde, mentre la seconda con un programma di esplorazione umana.\n",
      "La Cina, oltre all'esplorazione umana, sta considerando la possibilità di sfruttare minerariamente la Luna, in particolare per l'isotopo Elio-3, da usare come possibile futura fonte d'energia per la fusione nucleare sulla Terra.\n",
      "tuttavia, sia Tertulliano[7] sia, più tardi, Papa Leone I[8] attestano il fastidio e la riprovazione dei vertici della Chiesa nei confronti dei cristiani che, perpetuando le usanze pagane, manifestavano una venerazione nei confronti del Sole.\n"
     ]
    }
   ],
   "source": [
    "#si estraggono id e testo tramite le funzioni sopra definite\n",
    "n_file = 1\n",
    "id_list = []\n",
    "text_list = []\n",
    "readit_list = []\n",
    "for item in ds_files:\n",
    "    item_ids, item_texts, item_readit = extract(item, n_file)\n",
    "    id_list = id_list + item_ids\n",
    "    text_list = text_list + item_texts\n",
    "    readit_list = readit_list + item_readit\n",
    "    n_file += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9dedfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readit_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>La Prima Guerra Mondiale, conosciuta anche com...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1</td>\n",
       "      <td>Coinvolse le principali potenze mondiali dell'...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_1</td>\n",
       "      <td>gli Alleati, guidati da Francia, Regno Unito, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_1</td>\n",
       "      <td>Le cause della guerra possono essere attribuit...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_1</td>\n",
       "      <td>La guerra fu caratterizzata da una serie di nu...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  readit_index\n",
       "0  1_1  La Prima Guerra Mondiale, conosciuta anche com...            81\n",
       "1  2_1  Coinvolse le principali potenze mondiali dell'...            14\n",
       "2  3_1  gli Alleati, guidati da Francia, Regno Unito, ...             3\n",
       "3  4_1  Le cause della guerra possono essere attribuit...            94\n",
       "4  5_1  La guerra fu caratterizzata da una serie di nu...            35"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si crea un dataframe con una riga per frase, attributi: id, testo e indice di gulpease\n",
    "ds_df = pd.DataFrame(columns=[\"id\", \"text\", \"readit_index\"])\n",
    "\n",
    "ds_df[\"id\"] = id_list\n",
    "ds_df[\"text\"] = text_list\n",
    "ds_df[\"readit_index\"]  = readit_list\n",
    "\n",
    "ds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7023f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setto il device da usare\n",
    "#torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7563c918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Divido in training e test set\n",
    "dataset = Dataset.from_pandas(ds_df)\n",
    "split_set = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_ds = split_set[\"train\"]\n",
    "test_ds = split_set[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9bd3",
   "metadata": {},
   "source": [
    "### TOKENIZATION\n",
    "\n",
    "In questa sezione si importa il tokenizzatore col quale si tokenizza ciascuna frase nel formato necessario per Bert, alla fine si otterrà un dataset nel formato corretto con tutte le features necessarie per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc991e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0317bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/vocab.txt from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\e386d7030c11abe3c82da83b0aa728f3c09ab3a6728e325fe78bb5a0c67d7c71.83ca512ab51c5bc2809e83002a054b84ab85a200b98d5c0eb036d7611ee4362e\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\534fa05777338ca7e2b068a37beb83688543de270a20252296be3eadd10caca1.6391beef2ceed2cdba47401eb12680200856c97d2f2b56143e515d7c0f36a66a\n",
      "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\4641bcb7c4ac61788587ad50d2f1598c64a1c28a71631929524c234bcf1e422e.6ec690b98e01c56d26601258d2be34c3e5a76b949465ed58983cff81e5f9fa88\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-italian-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#si importa il tokenizzatore già configurato (in questo caso: bert-base-italian-cased)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6a74b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ffc6d76622448385a39fa87b75267c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf0ae4aacd446ecbf3c7bdf09cfdc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#facciamo l'encoding di tutto il dataset tokenizzando frase per frase\n",
    "def encode(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=True, truncation=True, max_length=512, return_special_tokens_mask=True)\n",
    "\n",
    "train_set = train_ds.map(encode, batched=True)\n",
    "test_set = test_ds.map(encode, batched=True)\n",
    "train_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n",
    "test_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "643587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'readit_index', 'input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'],\n",
       "    num_rows: 75\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95290375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'readit_index', 'input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'],\n",
       "    num_rows: 9\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def829e",
   "metadata": {},
   "source": [
    "### TRAINING DI BERT\n",
    "\n",
    "Si procede al training di Bert. Il modello dovrà partire da uno stato iniziale con pesi random, per questo non si importa il modello già addestrato, ma si configura semplicemente l'architettura la sua architettura per poi addestrarlo da zero. Si definisce poi una strategia di training e i suoi argomenti per poi addestrare il modello sul trask di Language Modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93b20d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, TrainerCallback, BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54c37d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"prajjwal1/bert-mini\"\n",
    "model_config = BertConfig.from_pretrained(model_name)\n",
    "\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2348df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(31102, 256)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM(model_config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "abd13ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 31102\n",
       "}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "09353207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usiamo il datacollator per fare le batch per il training\n",
    "datacollator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.2, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc554e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizer(name_or_path='dbmdz/bert-base-italian-cased', vocab_size=31102, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.2, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90322bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza del dataset: 75\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lunghezza del dataset: {len(train_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "95a4059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco una funzione di callback per verificare l'ordinamento dei dati per ogni epoca\n",
    "class check_ds_order(TrainerCallback):\n",
    "    def on_epoch_begin(self, args, state, control, train_dataloader, **kwargs):\n",
    "        f = open(f\"train_check.txt\", \"a\")\n",
    "        f.write(f\"\\n------------------------ ORDINE DEI DATI ALL'INIZI DELL'EPOCA {int(state.epoch+1)} ------------------------\")\n",
    "        f.write(str(train_dataloader.dataset[\"input_ids\"][:5]))\n",
    "        f.write(\"-----------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0a3b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "#argomenti provvisori, da definire meglio\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"my_pretrained_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "662c1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad9e34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('train_check.txt', 'w').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a14c39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=datacollator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    #callbacks=[check_ds_order], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0fc08b00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\bergo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 75\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea4a2de0c54d058b0fe553f086a47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.3229, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3a810800c643eab3823ee524c5512e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-10\n",
      "Configuration saved in my_pretrained_model\\checkpoint-10\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-10\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.305448532104492, 'eval_runtime': 0.2553, 'eval_samples_per_second': 35.253, 'eval_steps_per_second': 3.917, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.1341, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fc8f17796d4b11a7b89d1f5cdcb20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-20\n",
      "Configuration saved in my_pretrained_model\\checkpoint-20\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-20\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.198892593383789, 'eval_runtime': 0.3271, 'eval_samples_per_second': 27.518, 'eval_steps_per_second': 3.058, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, readit_index, text, special_tokens_mask. If id, readit_index, text, special_tokens_mask are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.1146, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cb47731edf45029a3df68b9f57655b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-30\n",
      "Configuration saved in my_pretrained_model\\checkpoint-30\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-30\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.066686630249023, 'eval_runtime': 0.3295, 'eval_samples_per_second': 27.313, 'eval_steps_per_second': 3.035, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-10] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from my_pretrained_model\\checkpoint-30 (score: 10.066686630249023).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 32.7456, 'train_samples_per_second': 6.871, 'train_steps_per_second': 0.916, 'train_loss': 10.190520222981771, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=10.190520222981771, metrics={'train_runtime': 32.7456, 'train_samples_per_second': 6.871, 'train_steps_per_second': 0.916, 'train_loss': 10.190520222981771, 'epoch': 3.0})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8ee48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
