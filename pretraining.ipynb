{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd41ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5916ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7023f7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3a13b",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING\n",
    "\n",
    "Per ottenere un dataset che possa essere utilizzato come training del nostro language model partiamo dai file conllu che contengono i testi annotati di wikipedia italiana. Da questi file vogliamo ottenere una struttura dati che per ogni frase riporti id, testo e indice di Gulpease (per ora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24b16f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\prova.conllu', 'data\\\\prova2.conllu', 'data\\\\text_all.txt']\n"
     ]
    }
   ],
   "source": [
    "#si ottengono i path di ogni file per il pretraining e si salvano in una lista\n",
    "\n",
    "ds_directory = \"data\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(ds_directory):\n",
    "    file_path = os.path.join(ds_directory, file_name)\n",
    "    ds_files.append(file_path)\n",
    "    \n",
    "print(ds_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef03f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_id(file_path, n_file):\n",
    "    id_list = []\n",
    "    current_id = \"\"\n",
    "    for line in open(file_path, 'r',  encoding='utf-8'):\n",
    "        if line.startswith(\"# sent_id\"):\n",
    "            current_id = re.sub(r'\\D', '', line)\n",
    "            id_list.append(current_id + \"_\" + str(n_file))\n",
    "    return id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "413c253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#PROBLEMA: l'id non è univoco se abbiamo un insieme di file che sono stati \"parsati\" singolarmente. \n",
    "#Possibile soluzione: aggiungere un numero identificativo del file. ?! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "716f6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#le preposizioni articolate vanno divise in costituenti o va bene la frase intera? \n",
    "# -> intanto prendo la frase intera in caso cambio\n",
    "def get_text(file_path):\n",
    "    text_list = []\n",
    "    current_sent = \"\"\n",
    "    for line in open(file_path, 'r',  encoding='utf-8'): \n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            text_list.append(current_sent)\n",
    "    return text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8b022a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_gulpease(ns, nw, nl):\n",
    "    g_value = 89 + ((300*ns - 10*nl)/nw) #è corretta questa formula?\n",
    "    return g_value\n",
    "\n",
    "def get_gulpease(file_path):\n",
    "    gulp_list = []\n",
    "    for line in open(file_path, 'r', encoding = \"utf-8\"):  #questa riga la ripeto tre volte meglio ottimizzare in un'unica f\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            words = current_sent.split()\n",
    "            gulp = comp_gulpease(1, len(words), sum(len(word) for word in words))\n",
    "            gulp_list.append(gulp)\n",
    "    return gulp_list\n",
    "\n",
    "#DOMANDA: l'indice di gulpease serve a determinare la difficoltà di un intero testo. Come fare se abbiamo una singola frase?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a84d81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si estraggono id e testo tramite le funzioni sopra definite\n",
    "\n",
    "id_list = []\n",
    "gulpease_list = []\n",
    "text_list = []\n",
    "n_file = 1\n",
    "for item in ds_files:\n",
    "    id_list = id_list + get_id(item, n_file)\n",
    "    n_file += 1\n",
    "    text_list = text_list + get_text(item)\n",
    "    gulpease_list = gulpease_list + get_gulpease(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d5cc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si crea un dataframe con una riga per frase, attributi: id, testo e indice di gulpease\n",
    "\n",
    "ds_df = pd.DataFrame(columns=[\"id\", \"text\", \"gulp_index\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e483037",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df[\"id\"] = id_list\n",
    "ds_df[\"text\"] = text_list\n",
    "ds_df[\"gulp_index\"]  = gulpease_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40a31cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gulp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>L'allunaggio è la discesa di un veicolo sulla ...</td>\n",
       "      <td>74.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1</td>\n",
       "      <td>Si distingue tra allunaggio duro, cioè un impa...</td>\n",
       "      <td>42.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_1</td>\n",
       "      <td>Il programma Luna, partito nel 1959 con la son...</td>\n",
       "      <td>56.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_1</td>\n",
       "      <td>Luna 9, il 3 febbraio 1966, eseguì il primo at...</td>\n",
       "      <td>63.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_1</td>\n",
       "      <td>Il primo allunaggio di un essere umano, il 20 ...</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  gulp_index\n",
       "0  1_1  L'allunaggio è la discesa di un veicolo sulla ...   74.555556\n",
       "1  2_1  Si distingue tra allunaggio duro, cioè un impa...   42.703704\n",
       "2  3_1  Il programma Luna, partito nel 1959 con la son...   56.142857\n",
       "3  4_1  Luna 9, il 3 febbraio 1966, eseguì il primo at...   63.615385\n",
       "4  5_1  Il primo allunaggio di un essere umano, il 20 ...   45.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4af9f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # TO  DO \n",
    "#ottimizzare il codice: il for line in open... farlo in una funzione unica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7563c918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Divido in training e test set\n",
    "ds_df.drop(columns=[\"id\", \"text\", \"gulp_index\"])\n",
    "dataset = Dataset.from_pandas(ds_df)\n",
    "split_set = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_ds = split_set[\"train\"]\n",
    "test_ds = split_set[\"test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9bd3",
   "metadata": {},
   "source": [
    "### TOKENIZATION\n",
    "\n",
    "In questa sezione si importa il tokenizzatore col quale si tokenizza ciascuna frase nel formato necessario per Bert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc991e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b6faab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text = \\'\\n\\'.join(ds_df[\\'text\\'])\\n\\nwith open(\\'data/text_all.txt\\', \\'w\\', encoding=\"utf-8\") as file:\\n    file.write(text)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Per il tokenizer ho bisogno del testo in formato txt\n",
    "\"\"\"text = '\\n'.join(ds_df['text'])\n",
    "\n",
    "with open('data/text_all.txt', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(text)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ff53fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokenizer = tokenizers.BertWordPieceTokenizer()\\n\\nfiles = [\"data/text_all.txt\"]\\n         \\ntokenizer.train(files=files, vocab_size=20000)#argomenti vanno bene? BOH\\ntokenizer.enable_truncation(max_length=256)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dobbiamo fare il pre-training del tokenizer???????????\n",
    "'''\n",
    "tokenizer = tokenizers.BertWordPieceTokenizer()\n",
    "\n",
    "files = [\"data/text_all.txt\"]\n",
    "         \n",
    "tokenizer.train(files=files, vocab_size=20000)#argomenti vanno bene? BOH\n",
    "tokenizer.enable_truncation(max_length=256)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0317bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/vocab.txt from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\e386d7030c11abe3c82da83b0aa728f3c09ab3a6728e325fe78bb5a0c67d7c71.83ca512ab51c5bc2809e83002a054b84ab85a200b98d5c0eb036d7611ee4362e\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\534fa05777338ca7e2b068a37beb83688543de270a20252296be3eadd10caca1.6391beef2ceed2cdba47401eb12680200856c97d2f2b56143e515d7c0f36a66a\n",
      "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-cased/resolve/main/config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\4641bcb7c4ac61788587ad50d2f1598c64a1c28a71631929524c234bcf1e422e.6ec690b98e01c56d26601258d2be34c3e5a76b949465ed58983cff81e5f9fa88\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-italian-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6a74b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d0dc440f1741129e0837a9f179b253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b686125305904ec899deb61bc3810ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#facciamo l'encoding di tutto il dataset tokenizzando frase per frase\n",
    "def encode(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=True, truncation=True, max_length=512, return_special_tokens_mask=True)\n",
    "\n",
    "train_set = train_ds.map(encode, batched=True)\n",
    "test_set = test_ds.map(encode, batched=True)\n",
    "train_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n",
    "test_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def829e",
   "metadata": {},
   "source": [
    "### TRAINING DI BERT\n",
    "\n",
    "Si procede al training di Bert. Il modello dovrà partire da uno stato iniziale con pesi random, per questo non si importa il modello già addestrato, ma si configura semplicemente l'architettura la sua architettura per poi addestrarlo da zero. Si definisce poi una strategia di training e i suoi argomenti per poi addestrare il modello sul trask di Language Modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93b20d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfa1d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizzeremo un bert piccolino per ora: prajjwal1/bert-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54c37d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/prajjwal1/bert-mini/resolve/main/config.json from cache at C:\\Users\\bergo/.cache\\huggingface\\transformers\\a32529b12a03c02e99c269bf68c0c7b8349093f626e860ab9b012e3d9539c539.e6c2a1d71adb3143ecd42222c4604e92ff255a7663c04bb5c4fad770c78e096c\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"prajjwal1/bert-mini\"\n",
    "model_config = BertConfig.from_pretrained(model_name)\n",
    "\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2348df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(31102, 256)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM(model_config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abd13ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 31102\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09353207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usiamo il datacollator per fare le batch per il training\n",
    "datacollator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.2, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc554e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizer(name_or_path='dbmdz/bert-base-italian-cased', vocab_size=31102, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.2, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90322bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0a3b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "#argomenti provvisori, da definire meglio\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"my_pretrained_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ff3cc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e27f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7b7a6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a14c39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=datacollator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0fc08b00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, special_tokens_mask, gulp_index, text. If id, special_tokens_mask, gulp_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\bergo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 194\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e2154bf0d42a2b42f84a8033e16b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, special_tokens_mask, gulp_index, text. If id, special_tokens_mask, gulp_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.3489, 'learning_rate': 4e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac636e6cbbd4533a01550fd774f1600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-10\n",
      "Configuration saved in my_pretrained_model\\checkpoint-10\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-10\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.257750511169434, 'eval_runtime': 0.7091, 'eval_samples_per_second': 31.026, 'eval_steps_per_second': 4.231, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-40] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, special_tokens_mask, gulp_index, text. If id, special_tokens_mask, gulp_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.2097, 'learning_rate': 3e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddc87417b1747ef9ea0b364c1333fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-20\n",
      "Configuration saved in my_pretrained_model\\checkpoint-20\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-20\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.189748764038086, 'eval_runtime': 0.6174, 'eval_samples_per_second': 35.634, 'eval_steps_per_second': 4.859, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-50] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, special_tokens_mask, gulp_index, text. If id, special_tokens_mask, gulp_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.1195, 'learning_rate': 2e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069d0a15140d4fa78f24138b690f404d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-30\n",
      "Configuration saved in my_pretrained_model\\checkpoint-30\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-30\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.046878814697266, 'eval_runtime': 0.6756, 'eval_samples_per_second': 32.565, 'eval_steps_per_second': 4.441, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-10] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, special_tokens_mask, gulp_index, text. If id, special_tokens_mask, gulp_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.0742, 'learning_rate': 1e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb4931afd274a3399656a098e0dc229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-40\n",
      "Configuration saved in my_pretrained_model\\checkpoint-40\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-40\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.092909812927246, 'eval_runtime': 0.6748, 'eval_samples_per_second': 32.604, 'eval_steps_per_second': 4.446, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-20] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: id, special_tokens_mask, gulp_index, text. If id, special_tokens_mask, gulp_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 22\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.0261, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826e9aaf335249209661cb34b2717c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_pretrained_model\\checkpoint-50\n",
      "Configuration saved in my_pretrained_model\\checkpoint-50\\config.json\n",
      "Model weights saved in my_pretrained_model\\checkpoint-50\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.020468711853027, 'eval_runtime': 0.7949, 'eval_samples_per_second': 27.677, 'eval_steps_per_second': 3.774, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [my_pretrained_model\\checkpoint-30] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from my_pretrained_model\\checkpoint-50 (score: 10.020468711853027).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 49.1896, 'train_samples_per_second': 7.888, 'train_steps_per_second': 1.016, 'train_loss': 10.155691833496094, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=10.155691833496094, metrics={'train_runtime': 49.1896, 'train_samples_per_second': 7.888, 'train_steps_per_second': 1.016, 'train_loss': 10.155691833496094, 'epoch': 2.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
