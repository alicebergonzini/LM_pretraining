{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd41ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263daf17",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING\n",
    "\n",
    "Per ottenere un dataset che possa essere utilizzato come training del nostro language model partiamo dai file conllu che contengono i testi annotati di wikipedia italiana. Da questi file vogliamo ottenere una struttura dati che per ogni frase riporti id, testo e indice di Gulpease (per ora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5090422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\prova.conllu', 'data\\\\prova2.conllu', 'data\\\\text_all.txt']\n"
     ]
    }
   ],
   "source": [
    "#si ottengono i path di ogni file per il pretraining e si salvano in una lista\n",
    "ds_directory = \"data\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(ds_directory):\n",
    "    file_path = os.path.join(ds_directory, file_name)\n",
    "    ds_files.append(file_path)\n",
    "print(ds_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a4027dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che calcola gulpease - io in teoria userò read-it\n",
    "'''\n",
    "def comp_gulpease(ns, nw, nl):\n",
    "    g_value = 89 + ((300*ns - 10*nl)/nw) #è corretta questa formula?\n",
    "    return g_value\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46c94a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_readit_scores(file_path):\\n    readit_list = []\\n    for line in open(file_path, \\'r\\', encoding = \"utf-8\"): \\n        print(line)\\n        if line.startswith(\"# text\"):\\n            current_sent = line[9:].rstrip(\\'\\n\\')\\n            sent_id = load_document(current_sent)\\n            r_score = get_sent_readability(sent_id)\\n            readit_list.append(r_score)\\n    return readit_list\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Qui il codice per ottenere l'indicie di leggibilità\n",
    "\n",
    "SERVER_PATH = \"http://api.italianlp.it\"\n",
    "\n",
    "#con una post si carica il documento nel db del server e si caclcola la leggibiità \n",
    "def load_document(text):\n",
    "    r = requests.post(SERVER_PATH + '/documents/',           # carica il documento nel database del server\n",
    "                      data={'text': text,                    # durante il caricamento viene eseguita un'analisi linguistica necessaria per calcolare la leggibilita'\n",
    "                          'lang': 'IT',\n",
    "                          'extra_tasks': [\"readability\"]     # chiede al server di calcolare anche la leggibilità del docuemnto\n",
    "                  })\n",
    "    doc_id = r.json()['id']                                  # id del documento nel database del server, che serve per richiedere i risultati delle analisi\n",
    "    return doc_id\n",
    "\n",
    "#si fa una get per ottenere i risultati, in questo caso siamo interessati solo alla leggibilità globale\n",
    "def get_sent_readability(doc_id):\n",
    "    r = requests.get(SERVER_PATH + '/documents/details/%s' % doc_id)\n",
    "    result = r.json()\n",
    "    sent_dict = result['sentences']['data'][0]\n",
    "    sent_readability = sent_dict[\"readability_score_all\"]        #prendiamo la leggibilità globale\n",
    "    return sent_readability\n",
    "\n",
    "#funzione per iterare su ciascuna frase \n",
    "'''def get_readit_scores(file_path):\n",
    "    readit_list = []\n",
    "    for line in open(file_path, 'r', encoding = \"utf-8\"): \n",
    "        print(line)\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            sent_id = load_document(current_sent)\n",
    "            r_score = get_sent_readability(sent_id)\n",
    "            readit_list.append(r_score)\n",
    "    return readit_list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che legge i file conllu riga per riga, estraendo id, testo e indice di complessità di ciascuna frase \n",
    "def extract(file_path, n_file):\n",
    "    id_list = []\n",
    "    text_list = []\n",
    "    readit_list = []\n",
    "    #gulp_list = []\n",
    "    current_id=\"\"\n",
    "    current_sent=\"\"\n",
    "    for line in open(file_path, 'r', encoding='utf-8'):\n",
    "        if line.startswith(\"# text\"):\n",
    "            current_sent = line[9:].rstrip('\\n')\n",
    "            #gulp = comp_gulpease(1, len(words), sum(len(word) for word in words))\n",
    "            print(current_sent)\n",
    "            sent_id = load_document(current_sent)\n",
    "            r_score = get_sent_readability(sent_id)\n",
    "            readit_list.append(r_score)\n",
    "            text_list.append(current_sent)\n",
    "            #gulp_list.append(gulp)\n",
    "        elif line.startswith(\"# sent_id\"):\n",
    "            current_id = re.sub(r'\\D', '', line)\n",
    "            id_list.append(f'{current_id}_{str(n_file)}') #per avere id univoco ho aggiunto numero del file\n",
    "    return id_list, text_list, readit_list\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4cff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'allunaggio è la discesa di un veicolo sulla Luna.\n",
      "Si distingue tra allunaggio duro, cioè un impatto che comporta la distruzione del veicolo, e allunaggio morbido, che permette al veicolo di arrivare intatto sulla superficie lunare.\n",
      "Il programma Luna, partito nel 1959 con la sonda Luna 2, inviò il primo veicolo riuscito ad impattare con il satellite.\n",
      "Luna 9, il 3 febbraio 1966, eseguì il primo atterraggio morbido sulla Luna.\n",
      "Il primo allunaggio di un essere umano, il 20 luglio 1969, fu quello di Neil Armstrong, comandante della missione Apollo 11, e di Buzz Aldrin, mentre il loro compagno Michael Collins, rimasto in orbita, controllava il modulo di comando Columbia.\n",
      "La prima missione verso la Luna dopo il periodo aureo, conclusosi nel 1976 con Luna 24, ultima missione automatica sovietica, fu organizzata dal Giappone con la sonda Hiten-Hagoromo lanciata il 24 gennaio 1990, che collaudò una nuova rotta lunare molto più economica ma anche molto più lenta;\n",
      "il rilascio della sonda Hagoromo fallì per l'interruzione dei contatti radio e alla fine Hiten entrò a sua volta in orbita lunare il 2 ottobre 1991;\n",
      "esaurito il combustibile la sonda fu fatta precipitare sul suolo lunare il 10 aprile 1993.\n",
      "La sonda spaziale SMART-1, dell'Agenzia spaziale europea (ESA) fu lanciata il 27 settembre 2003, ed arrivò nei pressi della Luna ad inizio 2005 (il motivo di un tempo così lungo è da trovarsi nel suo motore a ioni, un nuovo tipo di propulsione spaziale molto economico ma piuttosto lento).\n",
      "SMART-1 effettuò una ricognizione completa della Luna e produsse una mappa a raggi X della sua superficie[1].\n",
      "La sonda si schiantò sulla Luna il 3 settembre 2006.\n",
      "L'India ha fatto scendere sul suolo lunare il modulo Aditya (Moon Impact Probe), alle 15:04 UTC del 14 novembre 2008; il modulo era stato sganciato dalla sonda Chandrayaan-1 lanciata il 22 ottobre dalla base di Srihakot ed entrata in orbita intorno alla Luna il 4 novembre.\n",
      "L'India è quindi quinta nella lista dei paesi o enti spaziali che hanno raggiunto la superficie lunare.\n",
      "La Cina ha lanciato verso la Luna la sonda Chang'e 1, che il 1º marzo 2009 ha concluso la missione schiantandosi sul suolo lunare.\n",
      "L'allunaggio è la discesa di un veicolo sulla Luna.\n",
      "Si distingue tra allunaggio duro, cioè un impatto che comporta la distruzione del veicolo, e allunaggio morbido, che permette al veicolo di arrivare intatto sulla superficie lunare.\n",
      "Il programma Luna, partito nel 1959 con la sonda Luna 2, inviò il primo veicolo riuscito ad impattare con il satellite.\n",
      "Luna 9, il 3 febbraio 1966, eseguì il primo atterraggio morbido sulla Luna.\n",
      "Il primo allunaggio di un essere umano, il 20 luglio 1969, fu quello di Neil Armstrong, comandante della missione Apollo 11, e di Buzz Aldrin, mentre il loro compagno Michael Collins, rimasto in orbita, controllava il modulo di comando Columbia.\n",
      "La prima missione verso la Luna dopo il periodo aureo, conclusosi nel 1976 con Luna 24, ultima missione automatica sovietica, fu organizzata dal Giappone con la sonda Hiten-Hagoromo lanciata il 24 gennaio 1990, che collaudò una nuova rotta lunare molto più economica ma anche molto più lenta;\n",
      "il rilascio della sonda Hagoromo fallì per l'interruzione dei contatti radio e alla fine Hiten entrò a sua volta in orbita lunare il 2 ottobre 1991;\n",
      "esaurito il combustibile la sonda fu fatta precipitare sul suolo lunare il 10 aprile 1993.\n",
      "La sonda spaziale SMART-1, dell'Agenzia spaziale europea (ESA) fu lanciata il 27 settembre 2003, ed arrivò nei pressi della Luna ad inizio 2005 (il motivo di un tempo così lungo è da trovarsi nel suo motore a ioni, un nuovo tipo di propulsione spaziale molto economico ma piuttosto lento).\n",
      "SMART-1 effettuò una ricognizione completa della Luna e produsse una mappa a raggi X della sua superficie[1].\n",
      "La sonda si schiantò sulla Luna il 3 settembre 2006.\n",
      "L'India ha fatto scendere sul suolo lunare il modulo Aditya (Moon Impact Probe), alle 15:04 UTC del 14 novembre 2008; il modulo era stato sganciato dalla sonda Chandrayaan-1 lanciata il 22 ottobre dalla base di Srihakot ed entrata in orbita intorno alla Luna il 4 novembre.\n",
      "L'India è quindi quinta nella lista dei paesi o enti spaziali che hanno raggiunto la superficie lunare.\n",
      "La Cina ha lanciato verso la Luna la sonda Chang'e 1, che il 1º marzo 2009 ha concluso la missione schiantandosi sul suolo lunare.\n",
      "Va osservato che tutte queste sonde hanno realizzato un allunaggio distruttivo e non morbido, non disponendo dei retrorazzi necessari per rallentare il veicolo ed evitarne la distruzione.\n",
      "Tuttavia, il 2 dicembre 2013, la Cina ha lanciato la navicella Chang'e 3 contenente la sonda Yutu (il cui nome significa \"coniglio di giada\"), la quale, il 14 dicembre, si è sganciata da Chang'e 3 ed ha effettuato un allunaggio morbido.\n",
      "In questo modo la Cina è divenuta il terzo paese ad aver compiuto questo tipo di allunaggio dopo Unione Sovietica e Stati Uniti.\n",
      "La Russia, in un primo momento, aveva programmato per il 2012 il lancio di una sonda lunare, Luna-Glob 1.\n",
      "Successivamente si è deciso di rimandare al 2024.\n",
      "L'Agenzia spaziale europea e la Repubblica Popolare Cinese hanno entrambe piani per esplorare la Luna, la prima mediante sonde, mentre la seconda con un programma di esplorazione umana.\n",
      "La Cina, oltre all'esplorazione umana, sta considerando la possibilità di sfruttare minerariamente la Luna, in particolare per l'isotopo Elio-3, da usare come possibile futura fonte d'energia per la fusione nucleare sulla Terra.\n",
      "tuttavia, sia Tertulliano[7] sia, più tardi, Papa Leone I[8] attestano il fastidio e la riprovazione dei vertici della Chiesa nei confronti dei cristiani che, perpetuando le usanze pagane, manifestavano una venerazione nei confronti del Sole.\n"
     ]
    }
   ],
   "source": [
    "#si estraggono id e testo tramite le funzioni sopra definite\n",
    "n_file = 1\n",
    "id_list = []\n",
    "text_list = []\n",
    "readit_list = []\n",
    "for item in ds_files:\n",
    "    item_ids, item_texts, item_readit = extract(item, n_file)\n",
    "    id_list = id_list + item_ids\n",
    "    text_list = text_list + item_texts\n",
    "    readit_list = readit_list + item_readit\n",
    "    n_file += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dedfb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readit_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>L'allunaggio è la discesa di un veicolo sulla ...</td>\n",
       "      <td>4.228906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_1</td>\n",
       "      <td>Si distingue tra allunaggio duro, cioè un impa...</td>\n",
       "      <td>72.176978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_1</td>\n",
       "      <td>Il programma Luna, partito nel 1959 con la son...</td>\n",
       "      <td>80.940219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_1</td>\n",
       "      <td>Luna 9, il 3 febbraio 1966, eseguì il primo at...</td>\n",
       "      <td>12.844614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_1</td>\n",
       "      <td>Il primo allunaggio di un essere umano, il 20 ...</td>\n",
       "      <td>94.060913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  readit_index\n",
       "0  1_1  L'allunaggio è la discesa di un veicolo sulla ...      4.228906\n",
       "1  2_1  Si distingue tra allunaggio duro, cioè un impa...     72.176978\n",
       "2  3_1  Il programma Luna, partito nel 1959 con la son...     80.940219\n",
       "3  4_1  Luna 9, il 3 febbraio 1966, eseguì il primo at...     12.844614\n",
       "4  5_1  Il primo allunaggio di un essere umano, il 20 ...     94.060913"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si crea un dataframe con una riga per frase, attributi: id, testo e indice di gulpease\n",
    "ds_df = pd.DataFrame(columns=[\"id\", \"text\", \"readit_index\"])\n",
    "\n",
    "ds_df[\"id\"] = id_list\n",
    "ds_df[\"text\"] = text_list\n",
    "ds_df[\"readit_index\"]  = readit_list\n",
    "\n",
    "ds_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7023f7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setto il device da usare\n",
    "#torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7563c918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Divido in training e test set\n",
    "dataset = Dataset.from_pandas(ds_df)\n",
    "split_set = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "train_ds = split_set[\"train\"]\n",
    "test_ds = split_set[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e9bd3",
   "metadata": {},
   "source": [
    "### TOKENIZATION\n",
    "\n",
    "In questa sezione si importa il tokenizzatore col quale si tokenizza ciascuna frase nel formato necessario per Bert, alla fine si otterrà un dataset nel formato corretto con tutte le features necessarie per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc991e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0317bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si importa il tokenizzatore già configurato (in questo caso: bert-base-italian-cased)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dbmdz/bert-base-italian-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a74b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b04cbb419d24437b4c02d7377b6fab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b128db576841c8a077c757d7d3c2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#facciamo l'encoding di tutto il dataset tokenizzando frase per frase\n",
    "def encode(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=True, truncation=True, max_length=512, return_special_tokens_mask=True)\n",
    "\n",
    "train_set = train_ds.map(encode, batched=True)\n",
    "test_set = test_ds.map(encode, batched=True)\n",
    "train_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n",
    "test_set.set_format('torch', columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643587d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'readit_index', 'input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'],\n",
       "    num_rows: 32\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95290375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'readit_index', 'input_ids', 'token_type_ids', 'special_tokens_mask', 'attention_mask'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def829e",
   "metadata": {},
   "source": [
    "### TRAINING DI BERT\n",
    "\n",
    "Si procede al training di Bert. Il modello dovrà partire da uno stato iniziale con pesi random, per questo non si importa il modello già addestrato, ma si configura semplicemente l'architettura la sua architettura per poi addestrarlo da zero. Si definisce poi una strategia di training e i suoi argomenti per poi addestrare il modello sul trask di Language Modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b20d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, TrainerCallback, BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54c37d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"prajjwal1/bert-mini\"\n",
    "model_config = BertConfig.from_pretrained(model_name)\n",
    "\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2348df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(31102, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLM(model_config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abd13ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 31102\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09353207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usiamo il datacollator per fare le batch per il training\n",
    "datacollator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.2, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc554e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizer(name_or_path='dbmdz/bert-base-italian-cased', vocab_size=31102, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.2, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90322bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza del dataset: 32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lunghezza del dataset: {len(train_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a4059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco una funzione di callback per verificare l'ordinamento dei dati per ogni epoca\n",
    "class check_ds_order(TrainerCallback):\n",
    "    def on_epoch_begin(self, args, state, control, train_dataloader, **kwargs):\n",
    "        f = open(f\"train_check.txt\", \"a\")\n",
    "        f.write(f\"\\n------------------------ ORDINE DEI DATI ALL'INIZI DELL'EPOCA {int(state.epoch+1)} ------------------------\")\n",
    "        f.write(str(train_dataloader.dataset[\"input_ids\"][:5]))\n",
    "        f.write(\"-----------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0a3b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#argomenti provvisori, da definire meglio\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"my_pretrained_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "662c1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad9e34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('train_check.txt', 'w').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a14c39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=datacollator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    callbacks=[check_ds_order], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fc08b00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: special_tokens_mask, id, readit_index, text. If special_tokens_mask, id, readit_index, text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\bergo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 32\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e74a6742b54c298862c125fb951e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 9.2413, 'train_samples_per_second': 10.388, 'train_steps_per_second': 0.325, 'train_loss': 10.37182871500651, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=10.37182871500651, metrics={'train_runtime': 9.2413, 'train_samples_per_second': 10.388, 'train_steps_per_second': 0.325, 'train_loss': 10.37182871500651, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8ee48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
