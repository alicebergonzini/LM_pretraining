{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione frasi\n",
    "Estraiamo un campione di frasi a partire dai file conllu di Wikipedia italiana elaborata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(line):\n",
    "    sent_id = re.sub(r'\\D', '', line)\n",
    "    return sent_id\n",
    "\n",
    "def get_text(line):\n",
    "    sent = line[9:].rstrip('\\n')\n",
    "    return sent\n",
    "\n",
    "def get_sentences(file_conllu):\n",
    "    sentences = []\n",
    "    ids = []\n",
    "    with tqdm(total=sum(1 for _ in open(file_conllu, 'r', encoding='utf-8')), desc=f'Progresso estrazione frasi del file {file_conllu}') as pbar:\n",
    "        for line in open(file_conllu, 'r', encoding='utf-8'):\n",
    "            pbar.update(1)  # Aggiorna la barra di avanzamento\n",
    "            if line.startswith(\"# sent_id\"):\n",
    "                current_id = get_id(line)  \n",
    "                ids.append(current_id)\n",
    "            elif line.startswith(\"# text\"):\n",
    "                current_sent = get_text(line)\n",
    "                sentences.append(current_sent)\n",
    "    return ids, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ds_directory = \"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/wiki_conllu\"\\nds_files = []\\nfor file_name in os.listdir(ds_directory):\\n    file_path = os.path.join(ds_directory, file_name)\\n    ds_files.append(file_path)  #ottengo il nome dei diversi file all\\'interno della directory\\nprint(ds_files)'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nel caso in cui dovessimo itereare sui diversi file nella dir\n",
    "\"\"\"ds_directory = \"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/wiki_conllu\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(ds_directory):\n",
    "    file_path = os.path.join(ds_directory, file_name)\n",
    "    ds_files.append(file_path)  #ottengo il nome dei diversi file all'interno della directory\n",
    "print(ds_files)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_df = pd.DataFrame(columns=[\"id\", \"text\"])\\ndata_df[\"id\"], data_df[\"text\"] = get_sentences(ds_files[0])   #per ora lavoro su un singolo file'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_df = pd.DataFrame(columns=[\"id\", \"text\"])\n",
    "data_df[\"id\"], data_df[\"text\"] = get_sentences(ds_files[0])   #per ora lavoro su un singolo file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/csv/sample_rs42.csv\", encoding =\"utf-8\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>gulpease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772665</td>\n",
       "      <td>Il trio non era inizialmente interessato a lav...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499173</td>\n",
       "      <td>La ragazza riesce a convincere Lachlan a lasci...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1346921</td>\n",
       "      <td>In quanto campione del mondo uscente, egli avr...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>532939</td>\n",
       "      <td>Scoperto nel 2000, presenta un'orbita caratter...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363199</td>\n",
       "      <td>Definizione dell'Autorità per l'Energia Elettr...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id                                               text  gulpease\n",
       "0   772665  Il trio non era inizialmente interessato a lav...        52\n",
       "1  1499173  La ragazza riesce a convincere Lachlan a lasci...        47\n",
       "2  1346921  In quanto campione del mondo uscente, egli avr...        34\n",
       "3   532939  Scoperto nel 2000, presenta un'orbita caratter...        40\n",
       "4   363199  Definizione dell'Autorità per l'Energia Elettr...        62"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   sent_id   1000000 non-null  int64 \n",
      " 1   text      1000000 non-null  object\n",
      " 2   gulpease  1000000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = 200000\n",
    "fine = 300000\n",
    "samplino = data_df.iloc[inizio:fine] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 200000 to 299999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   sent_id   100000 non-null  int64 \n",
      " 1   text      100000 non-null  object\n",
      " 2   gulpease  100000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "samplino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_id                                                600248\n",
       "text        Nel 2008 il governo britannico ha annunciato l...\n",
       "gulpease                                                   31\n",
       "Name: 299999, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.iloc[299999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_id                                                600248\n",
       "text        Nel 2008 il governo britannico ha annunciato l...\n",
       "gulpease                                                   31\n",
       "Name: 299999, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplino.iloc[99999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione degli indici di leggibilità per ogni frase\n",
    "\n",
    "Utilizziamo l'API _read-it_ per calcolare gli indici di complessità di ogni frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SERVER_PATH = \"http://api.italianlp.it\"\n",
    "#SERVER_PATH = \"http://itanlp-gpu.ilc.cnr.it:13000\"\n",
    "\n",
    "def load_document(text, i, x):\n",
    "    try:\n",
    "        r = requests.post(SERVER_PATH + '/documents/',           # carica il documento nel database del server\n",
    "                        data={'text': text,                    # durante il caricamento viene eseguita un'analisi linguistica necessaria per calcolare la leggibilità\n",
    "                            'lang': 'IT',\n",
    "                            'extra_tasks': [\"readability\"]     # chiede al server di calcolare anche la leggibilità del docuemnto\n",
    "                    })\n",
    "        r.raise_for_status()  \n",
    "        doc_id = r.json()['id']                           # id del documento nel database del server, che serve per richiedere i risultati delle analisi     \n",
    "        return doc_id\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Errore nel caricamento del documento: {e} \\n ---------- Documento: ----------\\n{text}\")\n",
    "        with open('frasi_saltate.txt', 'a', encoding='utf-8') as frasi_saltate:\n",
    "            frasi_saltate.write(f\"Iterazione saltata: {i+200000} - {(i+200000)+x} DOCUMENTO SALTATO \\n{text}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_doc_score(doc_id, i, x):\n",
    "    try:\n",
    "        r = requests.get(SERVER_PATH + '/documents/details/%s' % doc_id)\n",
    "        r.raise_for_status()\n",
    "        result = r.json()\n",
    "        return result\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Errore nel recupero dei risultati: {e}\\n Iterazione: {i+200000} - {(i+200000)+x}: \")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facciamo una prova con un testo di poche frasi\n",
    "#text = \"Il cielo notturno era illuminato da milioni di stelle scintillanti. La vita è un viaggio, non una destinazione. La musica è il linguaggio universale dell'umanità. Le piccole cose nella vita spesso portano le più grandi gioie. Non esiste un ascensore per il successo; devi prendere le scale. Ogni giorno è una nuova opportunità per essere felici. I fiori non si preoccupano di come sbocceranno; semplicemente lo fanno. La risata è il miglior antidoto contro lo stress. La gentilezza è un linguaggio che i sordi possono sentire e i ciechi possono vedere. Nella semplicità risiede la vera bellezza.\"\n",
    "\n",
    "\n",
    "#doc_id = load_document(text, None, None)\n",
    "#r_score = get_doc_score(doc_id, None, None)\n",
    "\n",
    "#vediamo com'è strutturato l'oggetto che viene restituito dall'API\n",
    "#print(r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qui iteriamo sui risultati ottenuti per un singolo documento\n",
    "def get_sen_scores(doc_scores):\n",
    "    all_sent_rscore = []\n",
    "    all_sent_text = []\n",
    "    for i, sent_results in enumerate(doc_scores['sentences']['data']):\n",
    "        all_sent_rscore.append(sent_results['readability_score_all'])\n",
    "        all_sent_text.append(sent_results['raw_text'])\n",
    "    return all_sent_text, all_sent_rscore\n",
    "\n",
    "#si passa all'api un doc di 1000 frasi per volta.\n",
    "def readability_extraction(sen_list, x): #x è il numero di frasi che si vogliono calcolare per iterazione \n",
    "    for i in tqdm(range(0, len(sen_list), x), desc=f\"Progresso nell'estrazione degli indici di complessità delle frasi (ogni iterazione corrisponde a {x} frasi)\"):\n",
    "        doc = \"\\n\".join(sen_list[i:i+x])\n",
    "        doc_id = load_document(doc, i, x)\n",
    "        r_scores = get_doc_score(doc_id, i, x)\n",
    "        with open(f\"data/readit_scores/200000-300000/json_scores{i+200000}-{(i+200000)+x}.json\", \"w\") as f:\n",
    "            json.dump(r_scores, f)\n",
    "            #if i + x < len(sen_list):\n",
    "            #    f.write(',')  # Aggiungiamo una virgola se non siamo all'ultima iterazione\n",
    "      \n",
    "    #all_scores.append(r_scores)\n",
    "    \n",
    "\n",
    "#qui si ottiene la struttura dati finale dove per ogni frase abbiamo lo score ottenuto da read_it\n",
    "def get_final_data(result_dict):\n",
    "    text_list = []\n",
    "    score_list = []\n",
    "    for doc_scores in result_dict:\n",
    "        text, score = get_sen_scores(doc_scores)\n",
    "        text_list = text_list + text\n",
    "        score_list = score_list + score\n",
    "    return text_list, score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso nell'estrazione degli indici di complessità delle frasi (ogni iterazione corrisponde a 1000 frasi): 100%|██████████| 50/50 [2:17:04<00:00, 164.49s/it]  \n"
     ]
    }
   ],
   "source": [
    "all_results = readability_extraction(samplino[\"text\"].tolist(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrivere codice per estrarre tutti i risultati. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = open(\"json_scores5.json\", encoding=\"utf-8\")\n",
    "results_dict = json.load(all_results)\n",
    "all_sent, all_scores = get_final_data(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione e valutazione del dataset finale\n",
    "\n",
    "Si ottiene una struttura dataframe con _id_, _testo e _leggibilità_ per ogni frase. Dopodiché valutiamo le caratteristiche dei dati ottenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>La stagione 1989/90 iniziò bene per l'Everton,...</td>\n",
       "      <td>92.466578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Non è mai stato tradotto in formato digitale d...</td>\n",
       "      <td>81.356359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nel dicembre 2012 avviene la richiesta di fall...</td>\n",
       "      <td>42.361172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Non è chiaro se il termine Dominazioni usato d...</td>\n",
       "      <td>95.701924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nochlin si è sposata due volte.</td>\n",
       "      <td>1.908955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  readability\n",
       "0   1  La stagione 1989/90 iniziò bene per l'Everton,...    92.466578\n",
       "1   2  Non è mai stato tradotto in formato digitale d...    81.356359\n",
       "2   3  Nel dicembre 2012 avviene la richiesta di fall...    42.361172\n",
       "3   4  Non è chiaro se il termine Dominazioni usato d...    95.701924\n",
       "4   5                    Nochlin si è sposata due volte.     1.908955"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si crea un dataframe con tutte le informazioni che ci interessano\n",
    "data_set = pd.DataFrame(columns=[\"id\", \"text\", \"readability\"])\n",
    "data_set[\"text\"] = all_sent\n",
    "data_set[\"readability\"] = all_scores\n",
    "data_set[\"id\"] = range(1, len(data_set) + 1)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 294 entries, 0 to 301\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           294 non-null    int64  \n",
      " 1   text         294 non-null    object \n",
      " 2   readability  294 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si controlla l'ordine dei dati. Da tenere in considerazione il fatto che \"all_results\" è in forma di lista contenente i dizionari dei risultati dell'API per ogni \"documento\" (ovvero ogni x frasi). Quindi l'indice utilizzato per gli elementi di \"all_results\" per controllare l'ordine sarà sempre compreso tra 0 e x. Mentre quello del nostro dataframe sarà l'equivalente + x*y (dove y, è il numero del documento che stiamo prendendo in considerazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(results_dict[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Nel dataframe finale ----\n",
      " Testo: 'Durante il regno di Ḥasan Kuçek, non tutti i Chupanidi restarono leali.' - R_score: 43.5424813612392\n",
      "\n",
      "\n",
      "---- Nei risultati ottenuti dall'API ----\n",
      " Testo: 'la città non veniva servita da tre anni.' - R_score: 30.9012389143344\n"
     ]
    }
   ],
   "source": [
    "#ora controlliamo che l'ordine sia corretto...\n",
    "tupla = data_set[data_set[\"id\"]==35]\n",
    "da_result = results_dict[0]['sentences']['data'][34] #primo \"documento\"\n",
    "print(f\"---- Nel dataframe finale ----\\n Testo: '{tupla['text'].item()}' - R_score: {tupla['readability'].item()}\\n\\n\") \n",
    "print(f\"---- Nei risultati ottenuti dall'API ----\\n Testo: '{da_result['raw_text']}' - R_score: {da_result['readability_score_all']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Nel dataframe finale ---- \n",
      " Testo: Il verdetto è un film del 1948, diretto dal regista Lewis Allen. - R_score: 39.4039916534288\n",
      "\n",
      "\n",
      "---- Nei risultati ottenuti dall'API ---- \n",
      "  Testo: La nazionale di calcio della Polonia (pol. \"Reprezentacja Polski w piłce nożnej mężczyzn\") è la rappresentativa calcistica della Polonia ed è posta sotto l'egida della federazione calcistica polacca. - R_score: 58.4271426139914\n"
     ]
    }
   ],
   "source": [
    "tupla = data_set[data_set[\"id\"]==49]\n",
    "da_result = results_dict[1]['sentences']['data'][48] #secondo \"documento\"\n",
    "print(f\"---- Nel dataframe finale ---- \\n Testo: {tupla['text'].item()} - R_score: {tupla['readability'].item()}\\n\\n\") \n",
    "print(f\"---- Nei risultati ottenuti dall'API ---- \\n  Testo: {da_result['raw_text']} - R_score: {da_result['readability_score_all']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text, readability]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valori_nulli = data_set[data_set[\"readability\"].isnull()]\n",
    "valori_nulli #vediamo che le frasi troppo corte non restituiscono un valore di leggibilità. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.dropna()\n",
    "data_set.to_csv(\"ds_leggibilita.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
