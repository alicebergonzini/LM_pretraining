{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione frasi da file conllu\n",
    "Nel caso in cui dovessimo partire da i file conllu: estraiamo un campione di frasi a partire dai file conllu di Wikipedia italiana elaborata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(line):\n",
    "    sent_id = re.sub(r'\\D', '', line)\n",
    "    return sent_id\n",
    "\n",
    "def get_text(line):\n",
    "    sent = line[9:].rstrip('\\n')\n",
    "    return sent\n",
    "\n",
    "def get_sentences(file_conllu):\n",
    "    sentences = []\n",
    "    ids = []\n",
    "    with tqdm(total=sum(1 for _ in open(file_conllu, 'r', encoding='utf-8')), desc=f'Progresso estrazione frasi del file {file_conllu}') as pbar:\n",
    "        for line in open(file_conllu, 'r', encoding='utf-8'):\n",
    "            pbar.update(1)  # Aggiorna la barra di avanzamento\n",
    "            if line.startswith(\"# sent_id\"):\n",
    "                current_id = get_id(line)  \n",
    "                ids.append(current_id)\n",
    "            elif line.startswith(\"# text\"):\n",
    "                current_sent = get_text(line)\n",
    "                sentences.append(current_sent)\n",
    "    return ids, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nel caso in cui dovessimo itereare sui diversi file nella dir\n",
    "# ds_directory = \"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/wiki_conllu\"\n",
    "# ds_files = []\n",
    "# for file_name in os.listdir(ds_directory):\n",
    "#     file_path = os.path.join(ds_directory, file_name)\n",
    "#     ds_files.append(file_path)  #ottengo il nome dei diversi file all'interno della directory\n",
    "# print(ds_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = pd.DataFrame(columns=[\"id\", \"text\"])\n",
    "# data_df[\"id\"], data_df[\"text\"] = get_sentences(ds_files[0])   #per ora lavoro su un singolo file\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento dati\n",
    "\n",
    "Nel caso in cui disponessimo già di un dataset si salvano i dati semplicemente in un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/csv/more_frasi.csv\", encoding=\"utf-8\") #caricamento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIZIO = 0\n",
    "fine = len(data_df)\n",
    "samplino = data_df.iloc[INIZIO:fine] #un sample per fare prove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.iloc[19999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplino.iloc[19999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione degli indici di leggibilità per ogni frase\n",
    "\n",
    "Utilizziamo l'API _read-it_ per calcolare gli indici di complessità delle frasi. Si passano all'API come un singolo documento di x frasi, per velocizzare il processo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SERVER_PATH = \"http://api.italianlp.it\"\n",
    "#SERVER_PATH = \"http://itanlp-gpu.ilc.cnr.it:13000\"\n",
    "\n",
    "def load_document(text, i, x):\n",
    "    try:\n",
    "        r = requests.post(SERVER_PATH + '/documents/',           # carica il documento nel database del server\n",
    "                        data={'text': text,                    # durante il caricamento viene eseguita un'analisi linguistica necessaria per calcolare la leggibilità\n",
    "                            'lang': 'IT',\n",
    "                            'extra_tasks': [\"readability\"]     # chiede al server di calcolare anche la leggibilità del docuemnto\n",
    "                    })\n",
    "        r.raise_for_status()  \n",
    "        doc_id = r.json()['id']                           # id del documento nel database del server, che serve per richiedere i risultati delle analisi     \n",
    "        return doc_id\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Errore nel caricamento dei dati: {e}\\n Iterazione: {i+INIZIO} - {(i+INIZIO)+x}: \")\n",
    "        with open('frasi_saltate_val.txt', 'a', encoding='utf-8') as frasi_saltate:\n",
    "            frasi_saltate.write(f\"{i+INIZIO} - {(i+INIZIO)+x} - Documento: \\n{text}\\n\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_doc_score(doc_id, i, x):\n",
    "    try:\n",
    "        r = requests.get(SERVER_PATH + '/documents/details/%s' % doc_id)  #richiesta all'API per ottenere i risultati \n",
    "        r.raise_for_status()  \n",
    "        result = r.json()   \n",
    "        return result\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Errore nel recupero dei risultati: {e}\\n Iterazione: {i+INIZIO} - {(i+INIZIO)+x}: \")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facciamo una prova con un testo di poche frasi\n",
    "text = \"Il cielo notturno era illuminato da milioni di stelle scintillanti. La vita è un viaggio, non una destinazione. La musica è il linguaggio universale dell'umanità. Le piccole cose nella vita spesso portano le più grandi gioie. Non esiste un ascensore per il successo; devi prendere le scale. Ogni giorno è una nuova opportunità per essere felici. I fiori non si preoccupano di come sbocceranno; semplicemente lo fanno. La risata è il miglior antidoto contro lo stress. La gentilezza è un linguaggio che i sordi possono sentire e i ciechi possono vedere. Nella semplicità risiede la vera bellezza.\"\n",
    "\n",
    "\n",
    "doc_id = load_document(text, None, None)\n",
    "r_score = get_doc_score(doc_id, None, None)\n",
    "\n",
    "#vediamo com'è strutturato l'oggetto che viene restituito dall'API\n",
    "print(r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qui iteriamo sui risultati ottenuti per un singolo documento\n",
    "def get_sen_scores(doc_scores):\n",
    "    all_sent_rscore = []\n",
    "    all_sent_text = []\n",
    "    for sent_results in doc_scores['sentences']['data']:\n",
    "        all_sent_rscore.append(sent_results['readability_score_all'])\n",
    "        all_sent_text.append(sent_results['raw_text'])\n",
    "    return all_sent_text, all_sent_rscore\n",
    "\n",
    "#si passa all'api un doc di 1000 frasi per volta.\n",
    "def readability_extraction(sen_list, x): #x è il numero di frasi che si vogliono calcolare per iterazione \n",
    "    for i in tqdm(range(0, len(sen_list), x), desc=f\"Progresso nell'estrazione degli indici di complessità delle frasi (ogni iterazione corrisponde a {x} frasi)\"):\n",
    "        doc = \"\\n\".join(sen_list[i:i+x])\n",
    "        doc_id = load_document(doc, i, x)\n",
    "        r_scores = get_doc_score(doc_id, i, x)\n",
    "        with open(f\"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/readit_scores/more_frasi/{i+INIZIO}-{(i+INIZIO)+x}.json\", \"w\") as f:\n",
    "            json.dump(r_scores, f)          #si salva per ogni \"doc\" di 1000 frasi un file json con i risultati\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = readability_extraction(samplino[\"text\"].tolist(), 1000)  #si passa all'estrazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione da JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codice per estrarre score dai json\n",
    "#iteriamo sui diversi file json nella directory\n",
    "json_dir = \"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/readit_scores/more_frasi\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(json_dir):\n",
    "    file_path = os.path.join(json_dir, file_name)\n",
    "    ds_files.append(file_path) #ottengo il nome dei diversi file all'interno della directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si leggono i file json per ottenere lista di frasi e lista di punteggi read-it\n",
    "all_sent = []\n",
    "all_scores = []\n",
    "for file_name in tqdm(ds_files, desc=\"Processing files\"):\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        result = json.load(json_file)\n",
    "        #print(result[\"sentences\"][\"count\"])\n",
    "    if result != None:\n",
    "        doc_sen, doc_scores = get_sen_scores(result)\n",
    "        all_sent = all_sent + doc_sen\n",
    "        all_scores = all_scores + doc_scores\n",
    "    else: \n",
    "        print(f'File vuoto: {file_name}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione e valutazione del dataset finale\n",
    "\n",
    "Si ottiene una struttura dataframe con _id_, _testo e _leggibilità_ per ogni frase. Dopodiché valutiamo le caratteristiche dei dati ottenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si crea un dataframe con tutte le informazioni che ci interessano\n",
    "data_set = pd.DataFrame(columns=[\"id\", \"text\", \"readability\"])\n",
    "data_set[\"text\"] = all_sent\n",
    "data_set[\"readability\"] = all_scores\n",
    "data_set[\"id\"] = range(1, len(data_set) + 1)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valori_nulli = data_set[data_set[\"readability\"].isnull()]\n",
    "valori_nulli #vediamo che le frasi troppo corte non restituiscono un valore di leggibilità. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le frasi passate all'API sono sottoposte a un ulteriore splitting. Per questo motivo alcune frasi vengono suddivise in più parti rispetto a quelle originali. Tutte quelle frasi vengono rimosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si rimuovono le frasi che non matchano con quelle originali\n",
    "clean_ds = data_set[data_set['text'].isin(data_df['text'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si eliminano anche i restanti elementi che hanno leggibilità NaN\n",
    "clean_ds = data_set.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ds[\"id\"] = range(1, len(clean_ds)+1) #id vengono riassegnati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ds.to_csv(\"more_frasi_ws.csv\", index=False) #una volta pronto salviamo il file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
