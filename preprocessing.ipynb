{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione frasi\n",
    "Estraiamo un campione di frasi a partire dai file conllu di Wikipedia italiana elaborata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(line):\n",
    "    sent_id = re.sub(r'\\D', '', line)\n",
    "    return sent_id\n",
    "\n",
    "def get_text(line):\n",
    "    sent = line[9:].rstrip('\\n')\n",
    "    return sent\n",
    "\n",
    "def get_sentences(file_conllu):\n",
    "    sentences = []\n",
    "    ids = []\n",
    "    with tqdm(total=sum(1 for _ in open(file_conllu, 'r', encoding='utf-8')), desc=f'Progresso estrazione frasi del file {file_conllu}') as pbar:\n",
    "        for line in open(file_conllu, 'r', encoding='utf-8'):\n",
    "            pbar.update(1)  # Aggiorna la barra di avanzamento\n",
    "            if line.startswith(\"# sent_id\"):\n",
    "                current_id = get_id(line)  \n",
    "                ids.append(current_id)\n",
    "            elif line.startswith(\"# text\"):\n",
    "                current_sent = get_text(line)\n",
    "                sentences.append(current_sent)\n",
    "    return ids, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ds_directory = \"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/wiki_conllu\"\\nds_files = []\\nfor file_name in os.listdir(ds_directory):\\n    file_path = os.path.join(ds_directory, file_name)\\n    ds_files.append(file_path)  #ottengo il nome dei diversi file all\\'interno della directory\\nprint(ds_files)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nel caso in cui dovessimo itereare sui diversi file nella dir\n",
    "\"\"\"ds_directory = \"C:/Users/bergo/OneDrive - University of Pisa/Tesi Magistrale/wiki_conllu\"\n",
    "ds_files = []\n",
    "for file_name in os.listdir(ds_directory):\n",
    "    file_path = os.path.join(ds_directory, file_name)\n",
    "    ds_files.append(file_path)  #ottengo il nome dei diversi file all'interno della directory\n",
    "print(ds_files)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_df = pd.DataFrame(columns=[\"id\", \"text\"])\\ndata_df[\"id\"], data_df[\"text\"] = get_sentences(ds_files[0])   #per ora lavoro su un singolo file'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_df = pd.DataFrame(columns=[\"id\", \"text\"])\n",
    "data_df[\"id\"], data_df[\"text\"] = get_sentences(ds_files[0])   #per ora lavoro su un singolo file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/csv/sample_rs42.csv\", encoding =\"utf-8\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>gulpease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>772665</td>\n",
       "      <td>Il trio non era inizialmente interessato a lav...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1499173</td>\n",
       "      <td>La ragazza riesce a convincere Lachlan a lasci...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1346921</td>\n",
       "      <td>In quanto campione del mondo uscente, egli avr...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>532939</td>\n",
       "      <td>Scoperto nel 2000, presenta un'orbita caratter...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>363199</td>\n",
       "      <td>Definizione dell'Autorità per l'Energia Elettr...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id                                               text  gulpease\n",
       "0   772665  Il trio non era inizialmente interessato a lav...        52\n",
       "1  1499173  La ragazza riesce a convincere Lachlan a lasci...        47\n",
       "2  1346921  In quanto campione del mondo uscente, egli avr...        34\n",
       "3   532939  Scoperto nel 2000, presenta un'orbita caratter...        40\n",
       "4   363199  Definizione dell'Autorità per l'Energia Elettr...        62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   sent_id   1000000 non-null  int64 \n",
      " 1   text      1000000 non-null  object\n",
      " 2   gulpease  1000000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplino = data_df.sample(300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300 entries, 540434 to 580271\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sent_id   300 non-null    int64 \n",
      " 1   text      300 non-null    object\n",
      " 2   gulpease  300 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 9.4+ KB\n"
     ]
    }
   ],
   "source": [
    "samplino.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione degli indici di leggibilità per ogni frase\n",
    "\n",
    "Utilizziamo l'API _read-it_ per calcolare gli indici di complessità di ogni frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SERVER_PATH = \"http://api.italianlp.it\"\n",
    "#SERVER_PATH = \"http://itanlp-gpu.ilc.cnr.it:13000\"\n",
    "\n",
    "def load_document(text):\n",
    "    try:\n",
    "        r = requests.post(SERVER_PATH + '/documents/',           # carica il documento nel database del server\n",
    "                        data={'text': text,                    # durante il caricamento viene eseguita un'analisi linguistica necessaria per calcolare la leggibilità\n",
    "                            'lang': 'IT',\n",
    "                            'extra_tasks': [\"readability\"]     # chiede al server di calcolare anche la leggibilità del docuemnto\n",
    "                    })\n",
    "        r.raise_for_status()  \n",
    "        doc_id = r.json()['id']                           # id del documento nel database del server, che serve per richiedere i risultati delle analisi     \n",
    "        return doc_id\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Errore nel caricamento del documento: {e} \\n ---------- Documento: ----------\\n{text}\")\n",
    "        with open('frasi_saltate.txt', 'a', encoding='utf-8') as frasi_saltate:\n",
    "            frasi_saltate.write(f\"DOCUMENTO SALTATO: \\n{text}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_doc_score(doc_id, text):\n",
    "    try:\n",
    "        r = requests.get(SERVER_PATH + '/documents/details/%s' % doc_id)\n",
    "        r.raise_for_status()\n",
    "        result = r.json()\n",
    "        return result\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Errore nel recupero dei risultati: {e}\\n Documento: {text}: \")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'named_entity_executed': False, 'doc_time': '2024-05-22T17:25:43.609487Z', 'readability_executed': True, 'sentences': {'count': 2, 'prev': None, 'data': [{'sentiment_positive_negative_probability': None, 'sentiment_value': None, 'sequence': 1, 'readability_score_all': 61.70159263084, 'sentiment_negative_probability': None, 'sentiment_neutral_probability': None, 'tokens': [{'word': 'Quando', 'ten': None, 'sequence': 1, 'pos': 'CS', 'per': None, 'lemma': 'quando', 'num': None, 'named_entity_instance': None, 'dep_type': 'ROOT', 'dep_parent_sequence': None, 'cpos': 'C', 'gen': None, 'mod': None}, {'word': 'sei', 'ten': None, 'sequence': 2, 'pos': 'N', 'per': None, 'lemma': 'sei', 'num': None, 'named_entity_instance': None, 'dep_type': 'mod', 'dep_parent_sequence': 3, 'cpos': 'N', 'gen': None, 'mod': None}, {'word': 'qui', 'ten': None, 'sequence': 3, 'pos': 'B', 'per': None, 'lemma': 'qui', 'num': None, 'named_entity_instance': None, 'dep_type': 'mod_loc', 'dep_parent_sequence': 4, 'cpos': 'B', 'gen': None, 'mod': None}, {'word': 'con', 'ten': None, 'sequence': 4, 'pos': 'E', 'per': None, 'lemma': 'con', 'num': None, 'named_entity_instance': None, 'dep_type': 'comp', 'dep_parent_sequence': 1, 'cpos': 'E', 'gen': None, 'mod': None}, {'word': 'me', 'ten': None, 'sequence': 5, 'pos': 'PE', 'per': '1', 'lemma': 'me', 'num': 's', 'named_entity_instance': None, 'dep_type': 'prep', 'dep_parent_sequence': 4, 'cpos': 'P', 'gen': 'n', 'mod': None}, {'word': ',', 'ten': None, 'sequence': 6, 'pos': 'FF', 'per': None, 'lemma': ',', 'num': None, 'named_entity_instance': None, 'dep_type': 'punc', 'dep_parent_sequence': 4, 'cpos': 'F', 'gen': None, 'mod': None}, {'word': 'questa', 'ten': None, 'sequence': 7, 'pos': 'DD', 'per': None, 'lemma': 'questo', 'num': 's', 'named_entity_instance': None, 'dep_type': 'mod', 'dep_parent_sequence': 8, 'cpos': 'D', 'gen': 'f', 'mod': None}, {'word': 'stanza', 'ten': None, 'sequence': 8, 'pos': 'S', 'per': None, 'lemma': 'stanza', 'num': 's', 'named_entity_instance': None, 'dep_type': 'subj', 'dep_parent_sequence': 10, 'cpos': 'S', 'gen': 'f', 'mod': None}, {'word': 'non', 'ten': None, 'sequence': 9, 'pos': 'BN', 'per': None, 'lemma': 'non', 'num': None, 'named_entity_instance': None, 'dep_type': 'neg', 'dep_parent_sequence': 10, 'cpos': 'B', 'gen': None, 'mod': None}, {'word': 'ha', 'ten': 'p', 'sequence': 10, 'pos': 'V', 'per': '3', 'lemma': 'avere', 'num': 's', 'named_entity_instance': None, 'dep_type': 'sub', 'dep_parent_sequence': 1, 'cpos': 'V', 'gen': None, 'mod': 'i'}, {'word': 'più', 'ten': None, 'sequence': 11, 'pos': 'B', 'per': None, 'lemma': 'più', 'num': None, 'named_entity_instance': None, 'dep_type': 'mod', 'dep_parent_sequence': 12, 'cpos': 'B', 'gen': None, 'mod': None}, {'word': 'pareti', 'ten': None, 'sequence': 12, 'pos': 'S', 'per': None, 'lemma': 'parete', 'num': 'p', 'named_entity_instance': None, 'dep_type': 'obj', 'dep_parent_sequence': 10, 'cpos': 'S', 'gen': 'f', 'mod': None}, {'word': ',', 'ten': None, 'sequence': 13, 'pos': 'FF', 'per': None, 'lemma': ',', 'num': None, 'named_entity_instance': None, 'dep_type': 'con', 'dep_parent_sequence': 1, 'cpos': 'F', 'gen': None, 'mod': None}, {'word': 'ma', 'ten': None, 'sequence': 14, 'pos': 'CC', 'per': None, 'lemma': 'ma', 'num': None, 'named_entity_instance': None, 'dep_type': 'mod', 'dep_parent_sequence': 15, 'cpos': 'C', 'gen': None, 'mod': None}, {'word': 'alberi', 'ten': None, 'sequence': 15, 'pos': 'S', 'per': None, 'lemma': 'albero', 'num': 'p', 'named_entity_instance': None, 'dep_type': 'conj', 'dep_parent_sequence': 1, 'cpos': 'S', 'gen': 'm', 'mod': None}, {'word': '.', 'ten': None, 'sequence': 16, 'pos': 'FS', 'per': None, 'lemma': '.', 'num': None, 'named_entity_instance': None, 'dep_type': 'punc', 'dep_parent_sequence': 15, 'cpos': 'F', 'gen': None, 'mod': None}], 'sentiment_executed': False, 'readability_score_syntax': 70.2403134390279, 'readability_score_lexical': 40.859030351813, 'raw_text': 'Quando sei qui con me, questa stanza non ha più pareti, ma alberi.', 'sentiment_positive_probability': None, 'readability_score_base': 48.2737908706911}, {'sentiment_positive_negative_probability': None, 'sentiment_value': None, 'sequence': 2, 'readability_score_all': 5.61802294112356, 'sentiment_negative_probability': None, 'sentiment_neutral_probability': None, 'tokens': [{'word': 'La', 'ten': None, 'sequence': 1, 'pos': 'RD', 'per': None, 'lemma': 'il', 'num': 's', 'named_entity_instance': None, 'dep_type': 'det', 'dep_parent_sequence': 2, 'cpos': 'R', 'gen': 'f', 'mod': None}, {'word': 'vita', 'ten': None, 'sequence': 2, 'pos': 'S', 'per': None, 'lemma': 'vita', 'num': 's', 'named_entity_instance': None, 'dep_type': 'subj', 'dep_parent_sequence': 3, 'cpos': 'S', 'gen': 'f', 'mod': None}, {'word': 'è', 'ten': 'p', 'sequence': 3, 'pos': 'V', 'per': '3', 'lemma': 'essere', 'num': 's', 'named_entity_instance': None, 'dep_type': 'ROOT', 'dep_parent_sequence': None, 'cpos': 'V', 'gen': None, 'mod': 'i'}, {'word': 'difficile', 'ten': None, 'sequence': 4, 'pos': 'A', 'per': None, 'lemma': 'difficile', 'num': 's', 'named_entity_instance': None, 'dep_type': 'pred', 'dep_parent_sequence': 3, 'cpos': 'A', 'gen': 'n', 'mod': None}, {'word': 'quando', 'ten': None, 'sequence': 5, 'pos': 'CS', 'per': None, 'lemma': 'quando', 'num': None, 'named_entity_instance': None, 'dep_type': 'mod', 'dep_parent_sequence': 3, 'cpos': 'C', 'gen': None, 'mod': None}, {'word': 'non', 'ten': None, 'sequence': 6, 'pos': 'BN', 'per': None, 'lemma': 'non', 'num': None, 'named_entity_instance': None, 'dep_type': 'neg', 'dep_parent_sequence': 7, 'cpos': 'B', 'gen': None, 'mod': None}, {'word': 'sai', 'ten': 'p', 'sequence': 7, 'pos': 'VM', 'per': '2', 'lemma': 'sapere', 'num': 's', 'named_entity_instance': None, 'dep_type': 'sub', 'dep_parent_sequence': 5, 'cpos': 'V', 'gen': None, 'mod': 'i'}, {'word': 'dove', 'ten': None, 'sequence': 8, 'pos': 'CS', 'per': None, 'lemma': 'dove', 'num': None, 'named_entity_instance': None, 'dep_type': 'arg', 'dep_parent_sequence': 7, 'cpos': 'C', 'gen': None, 'mod': None}, {'word': 'andare', 'ten': None, 'sequence': 9, 'pos': 'V', 'per': None, 'lemma': 'andare', 'num': None, 'named_entity_instance': None, 'dep_type': 'sub', 'dep_parent_sequence': 8, 'cpos': 'V', 'gen': None, 'mod': 'f'}, {'word': 'a', 'ten': None, 'sequence': 10, 'pos': 'E', 'per': None, 'lemma': 'a', 'num': None, 'named_entity_instance': None, 'dep_type': 'arg', 'dep_parent_sequence': 9, 'cpos': 'E', 'gen': None, 'mod': None}, {'word': 'sbattere', 'ten': None, 'sequence': 11, 'pos': 'V', 'per': None, 'lemma': 'sbattere', 'num': None, 'named_entity_instance': None, 'dep_type': 'prep', 'dep_parent_sequence': 10, 'cpos': 'V', 'gen': None, 'mod': 'f'}, {'word': 'la', 'ten': None, 'sequence': 12, 'pos': 'RD', 'per': None, 'lemma': 'il', 'num': 's', 'named_entity_instance': None, 'dep_type': 'det', 'dep_parent_sequence': 13, 'cpos': 'R', 'gen': 'f', 'mod': None}, {'word': 'testa', 'ten': None, 'sequence': 13, 'pos': 'S', 'per': None, 'lemma': 'testa', 'num': 's', 'named_entity_instance': None, 'dep_type': 'obj', 'dep_parent_sequence': 11, 'cpos': 'S', 'gen': 'f', 'mod': None}, {'word': '.', 'ten': None, 'sequence': 14, 'pos': 'FS', 'per': None, 'lemma': '.', 'num': None, 'named_entity_instance': None, 'dep_type': 'punc', 'dep_parent_sequence': 3, 'cpos': 'F', 'gen': None, 'mod': None}], 'sentiment_executed': False, 'readability_score_syntax': 6.57130811941239, 'readability_score_lexical': 45.9363990818212, 'raw_text': 'La vita è difficile quando non sai dove andare a sbattere la testa.', 'sentiment_positive_probability': None, 'readability_score_base': 43.3717662082719}], 'next': None}, 'irony_yes_probability': None, 'sentiment_value_probability': None, 'irony_no_probability': None, 'hate_executed': False, 'sentiment_neutral_probability': None, 'postagging_executed': True, 'readability_score_all': 0.974396122497112, 'parsing_executed': False, 'witness_executed': False, 'readability_score_lexical': 18.9107072161272, 'witness_value': None, 'sentiment_sentence_executed': False, 'hate_no_probability': None, 'sentiment_positive_negative_probability': None, 'sarcasm_yes_probability': None, 'hate_value': None, 'readability_score_base': 38.2117098171726, 'sarcasm_executed': False, 'sentiment_positive_probability': None, 'sentiment_value': None, 'language': 'IT', 'irony_value': None, 'hate_yes_probability': None, 'sentiment_negative_probability': None, 'created_at': '2024-05-22T17:25:43.609438Z', 'irony_executed': False, 'sarcasm_value': None, 'witness_yes_probability': None, 'sentiment_executed': False, 'readability_score_syntax': 1.40467928706896, 'witness_no_probability': None, 'sarcasm_no_probability': None}\n"
     ]
    }
   ],
   "source": [
    "#facciamo una prova con un testo di poche frasi\n",
    "text = \"Quando sei qui con me, questa stanza non ha più pareti, ma alberi. La vita è difficile quando non sai dove andare a sbattere la testa.\"\n",
    "\n",
    "\n",
    "doc_id = load_document(text)\n",
    "r_score = get_doc_score(doc_id, text)\n",
    "\n",
    "#vediamo com'è strutturato l'oggetto che viene restituito dall'API\n",
    "print(r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qui iteriamo sui risultati ottenuti per un singolo documento\n",
    "def get_sen_scores(doc_scores):\n",
    "    all_sent_rscore = []\n",
    "    all_sent_text = []\n",
    "    for i, sent_results in enumerate(doc_scores['sentences']['data']):\n",
    "        all_sent_rscore.append(sent_results['readability_score_all'])\n",
    "        all_sent_text.append(sent_results['raw_text'])\n",
    "    return all_sent_text, all_sent_rscore\n",
    "\n",
    "#si passa all'api un doc di 1000 frasi per volta.\n",
    "def readability_extraction(sen_list, x): #x è il numero di frasi che si vogliono calcolare per iterazione \n",
    "    all_scores = []\n",
    "    with open(\"json_scores5.json\", \"a\") as f:\n",
    "        f.write(\"[\")\n",
    "    for i in tqdm(range(0, len(sen_list), x), desc=f\"Progresso nell'estrazione degli indici di complessità delle frasi (ogni iterazione corrisponde a {x} frasi)\"):\n",
    "        doc = \"\\n\".join(sen_list[i:i+x])\n",
    "        doc_id = load_document(doc)\n",
    "        r_scores = get_doc_score(doc_id, doc)\n",
    "        with open(\"json_scores5.json\", \"a\") as f:\n",
    "            json.dump(r_scores, f)\n",
    "            if i + x < len(sen_list):\n",
    "                f.write(',')  # Aggiungiamo una virgola se non siamo all'ultima iterazione\n",
    "    with open(\"json_scores5.json\", \"a\") as f:\n",
    "        f.write(\"]\")\n",
    "    #all_scores.append(r_scores)\n",
    "    \n",
    "\n",
    "#qui si ottiene la struttura dati finale dove per ogni frase abbiamo lo score ottenuto da read_it\n",
    "def get_final_data(result_dict):\n",
    "    text_list = []\n",
    "    score_list = []\n",
    "    for doc_scores in result_dict:\n",
    "        text, score = get_sen_scores(doc_scores)\n",
    "        text_list = text_list + text\n",
    "        score_list = score_list + score\n",
    "    return text_list, score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progresso nell'estrazione degli indici di complessità delle frasi (ogni iterazione corrisponde a 100 frasi): 100%|██████████| 3/3 [01:01<00:00, 20.35s/it]\n"
     ]
    }
   ],
   "source": [
    "all_results = readability_extraction(samplino[\"text\"].tolist(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = open(\"json_scores5.json\", encoding=\"utf-8\")\n",
    "results_dict = json.load(all_results)\n",
    "all_sent, all_scores = get_final_data(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione e valutazione del dataset finale\n",
    "\n",
    "Si ottiene una struttura dataframe con _id_, _testo e _leggibilità_ per ogni frase. Dopodiché valutiamo le caratteristiche dei dati ottenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>La stagione 1989/90 iniziò bene per l'Everton,...</td>\n",
       "      <td>92.466578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Non è mai stato tradotto in formato digitale d...</td>\n",
       "      <td>81.356359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Nel dicembre 2012 avviene la richiesta di fall...</td>\n",
       "      <td>42.361172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Non è chiaro se il termine Dominazioni usato d...</td>\n",
       "      <td>95.701924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nochlin si è sposata due volte.</td>\n",
       "      <td>1.908955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  readability\n",
       "0   1  La stagione 1989/90 iniziò bene per l'Everton,...    92.466578\n",
       "1   2  Non è mai stato tradotto in formato digitale d...    81.356359\n",
       "2   3  Nel dicembre 2012 avviene la richiesta di fall...    42.361172\n",
       "3   4  Non è chiaro se il termine Dominazioni usato d...    95.701924\n",
       "4   5                    Nochlin si è sposata due volte.     1.908955"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si crea un dataframe con tutte le informazioni che ci interessano\n",
    "data_set = pd.DataFrame(columns=[\"id\", \"text\", \"readability\"])\n",
    "data_set[\"text\"] = all_sent\n",
    "data_set[\"readability\"] = all_scores\n",
    "data_set[\"id\"] = range(1, len(data_set) + 1)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 294 entries, 0 to 301\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           294 non-null    int64  \n",
      " 1   text         294 non-null    object \n",
      " 2   readability  294 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si controlla l'ordine dei dati. Da tenere in considerazione il fatto che \"all_results\" è in forma di lista contenente i dizionari dei risultati dell'API per ogni \"documento\" (ovvero ogni x frasi). Quindi l'indice utilizzato per gli elementi di \"all_results\" per controllare l'ordine sarà sempre compreso tra 0 e x. Mentre quello del nostro dataframe sarà l'equivalente + x*y (dove y, è il numero del documento che stiamo prendendo in considerazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(results_dict[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Nel dataframe finale ----\n",
      " Testo: 'Durante il regno di Ḥasan Kuçek, non tutti i Chupanidi restarono leali.' - R_score: 43.5424813612392\n",
      "\n",
      "\n",
      "---- Nei risultati ottenuti dall'API ----\n",
      " Testo: 'la città non veniva servita da tre anni.' - R_score: 30.9012389143344\n"
     ]
    }
   ],
   "source": [
    "#ora controlliamo che l'ordine sia corretto...\n",
    "tupla = data_set[data_set[\"id\"]==35]\n",
    "da_result = results_dict[0]['sentences']['data'][34] #primo \"documento\"\n",
    "print(f\"---- Nel dataframe finale ----\\n Testo: '{tupla['text'].item()}' - R_score: {tupla['readability'].item()}\\n\\n\") \n",
    "print(f\"---- Nei risultati ottenuti dall'API ----\\n Testo: '{da_result['raw_text']}' - R_score: {da_result['readability_score_all']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Nel dataframe finale ---- \n",
      " Testo: Il verdetto è un film del 1948, diretto dal regista Lewis Allen. - R_score: 39.4039916534288\n",
      "\n",
      "\n",
      "---- Nei risultati ottenuti dall'API ---- \n",
      "  Testo: La nazionale di calcio della Polonia (pol. \"Reprezentacja Polski w piłce nożnej mężczyzn\") è la rappresentativa calcistica della Polonia ed è posta sotto l'egida della federazione calcistica polacca. - R_score: 58.4271426139914\n"
     ]
    }
   ],
   "source": [
    "tupla = data_set[data_set[\"id\"]==49]\n",
    "da_result = results_dict[1]['sentences']['data'][48] #secondo \"documento\"\n",
    "print(f\"---- Nel dataframe finale ---- \\n Testo: {tupla['text'].item()} - R_score: {tupla['readability'].item()}\\n\\n\") \n",
    "print(f\"---- Nei risultati ottenuti dall'API ---- \\n  Testo: {da_result['raw_text']} - R_score: {da_result['readability_score_all']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>readability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text, readability]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valori_nulli = data_set[data_set[\"readability\"].isnull()]\n",
    "valori_nulli #vediamo che le frasi troppo corte non restituiscono un valore di leggibilità. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.dropna()\n",
    "data_set.to_csv(\"ds_leggibilita.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
